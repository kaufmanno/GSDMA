{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "400601b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.project import Project\n",
    "# from utils.orm import boreholes_from_dataframe\n",
    "from definitions import ROOT_DIR\n",
    "from utils.config import DEFAULT_LITHO_LEXICON, DEFAULT_POL_LEXICON, DEFAULT_LITHO_LEGEND\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48dd706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {'lithologies_data': f'{ROOT_DIR}/CF_data/Result_traitem/fusion_finale/Lithologies.csv',\n",
    "             'pollutants_data': f'{ROOT_DIR}/CF_data/Result_traitem/fusion_finale/Samples.csv'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93141869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from core.orm import Base\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import re\n",
    "from utils.config import WARNING_TEXT_CONFIG, DEFAULT_BOREHOLE_DIAMETER, WORDS_WITH_S\n",
    "from utils.utils import striplog_from_dataframe\n",
    "from utils.visual import get_components, legend_from_attributes\n",
    "from core.orm import BoreholeOrm, PositionOrm, LinkIntervalComponentOrm\n",
    "from striplog import Component, Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0010328a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boreholes_from_dataframe(data_dict, symbols=None, attributes=None, id_col='ID',\n",
    "                             diameter_col='Diameter', average_z=None, date_col='Date',\n",
    "                             sample_type_col=None, verbose=False):\n",
    "    \"\"\" Creates a list of BoreholeORM objects from a dataframe\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dict: dict\n",
    "        A dictionary of pandas.DataFrame containing borehole intervals data, based on the type of\n",
    "        these intervals (lithology or samples). e.g: {'lithology': df_1, 'sample': df2}\n",
    "    symbols: dict\n",
    "        A dict e.g. {attribute_1: {'legend': striplog.Legend, 'lexicon': striplog.Lexicon}, ...}\n",
    "    attributes : list\n",
    "        List of dataframe's columns of interest, linked to attributes to represent like 'lithology'\n",
    "    verbose : Bool\n",
    "        allow verbose option if set = True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    boreholes: list\n",
    "        boreholes object\n",
    "    components: dict\n",
    "        dictionary containing ID and component\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    int_id = 0  # interval id\n",
    "    pos_id = 0  # position id\n",
    "    boreholes_orm = []\n",
    "    components_dict = []\n",
    "    comp_id = 0  # component id\n",
    "    component_dict = {}\n",
    "    link_intv_comp_dict = {}  # link between intervals and components (<-> junction table)\n",
    "    contam_names = list(DEFAULT_POL_LEXICON.abbreviations.values())\n",
    "\n",
    "    if len(data_dict.keys()) > 2:\n",
    "        raise(KeyError(\"The data dictionary keys cannot be more than 2 keys\"))\n",
    "    if len(list(filter(re.compile('litho|sample|poll', re.I).match, data_dict.keys()))) < 1:\n",
    "        raise(KeyError(\"data_dict keys must contain at least 'lithology', 'sample' or 'pollutant' as keywords. e.g: {'lithology_data': df_litho, 'sample_data': df_samples}\"))\n",
    "\n",
    "    # data concatenation\n",
    "    df_list = []\n",
    "    for k, v in data_dict.items():\n",
    "        assert isinstance(v, pd.DataFrame)\n",
    "\n",
    "        df = v.copy()\n",
    "        if re.search('litho', k, re.I):\n",
    "            df['_intv'] = 'lithology'\n",
    "        elif re.search('sample|poll', k, re.I):\n",
    "            df['_intv'] = 'sample'\n",
    "\n",
    "        # columns' name standardization\n",
    "        for col in df.columns:\n",
    "            if re.search('top|toit', col, re.I):\n",
    "                df.rename(columns={col: 'Top_intv'}, inplace=True)\n",
    "            elif re.search('base|mur|assise', col, re.I):\n",
    "                df.rename(columns={col: 'Base_intv'}, inplace=True)\n",
    "            elif re.search('thick|epais', col, re.I):\n",
    "                df.rename(columns={col: 'Thick_intv'}, inplace=True)\n",
    "            elif re.search('desc', col, re.I):\n",
    "                df.rename(columns={col: 'Desc_intv'}, inplace=True)\n",
    "\n",
    "        df.insert(0, 'Type_intv', df.pop('_intv'))  #NOTE: Modified where the insertion is made \n",
    "        df_list.append(df)\n",
    "\n",
    "    final_df = df_list[0].append(df_list[1])\n",
    "\n",
    "    # data exploitation\n",
    "    print(f'\\nData Processing...\\n================================')\n",
    "    bh_id_list = []  #\n",
    "    bh_counter = 0\n",
    "    bh_idx = 0  # borehole index in the current dataframe\n",
    "\n",
    "    if diameter_col not in final_df.columns:\n",
    "        print(f\"{WARNING_TEXT_CONFIG['blue']}\"\n",
    "              f\"Warning : -- No borehole diameter column found or check given column's name.\\n\"\n",
    "              f'To continue, default diameter column has been created with value: '\n",
    "              f'{DEFAULT_BOREHOLE_DIAMETER} [m]{WARNING_TEXT_CONFIG[\"off\"]}')\n",
    "        final_df[diameter_col] = pd.Series([DEFAULT_BOREHOLE_DIAMETER] * len(final_df))\n",
    "\n",
    "    top_col, base_col, desc_col = 'Top_intv', 'Base_intv', 'Desc_intv'\n",
    "    thick_col, intv_type_col = 'Thick_intv', 'Type_intv'\n",
    "\n",
    "    for idx, row in final_df.iterrows():\n",
    "        bh_name = row[id_col]\n",
    "        if date_col not in final_df.columns:\n",
    "            bh_date = None\n",
    "        else:\n",
    "            bh_date = row[date_col]\n",
    "\n",
    "        if bh_name not in bh_id_list:\n",
    "            bh_id_list.append(bh_name)\n",
    "            bh_selection = final_df[id_col] == f\"{bh_name}\"\n",
    "            tmp = final_df[bh_selection].copy()\n",
    "            tmp.reset_index(drop=True, inplace=True)\n",
    "            striplog_dict = striplog_from_dataframe(df=tmp, bh_name=bh_name,\n",
    "                                                    attributes=attributes, symbols=symbols,\n",
    "                                                    id_col=id_col, thick_col=thick_col,\n",
    "                                                    top_col=top_col, base_col=base_col,\n",
    "                                                    desc_col=desc_col, intv_type_col=intv_type_col,\n",
    "                                                    query=False, verbose=verbose)\n",
    "\n",
    "            if striplog_dict is not None:\n",
    "                bh_counter += 1\n",
    "                interval_number = 0\n",
    "                boreholes_orm.append(BoreholeOrm(id=bh_name, date=bh_date))\n",
    "\n",
    "                for strip_dict in striplog_dict.values():\n",
    "                    intv_type_dict = {}\n",
    "                    intv_dict = {}  # just for testing\n",
    "                    for iv_type, strip in strip_dict.items():\n",
    "                        for c in get_components(strip):\n",
    "                            c_key = list(c.keys())[0]\n",
    "                            c_type = 'pollutant' if c_key in contam_names else 'lithology'\n",
    "                            c_val = c_key if c_type == 'pollutant' else c[c_key]\n",
    "                            # c_lev = c[c_key] if c_type == 'pollutant' else None\n",
    "\n",
    "                            # remove 's' for plural words\n",
    "                            if c_val not in WORDS_WITH_S:\n",
    "                                c_val = c_val.rstrip('s')\n",
    "                            c = Component({'type': c_type, 'value': c_val})\n",
    "                            # c = Component({c_key: c_val}) #old\n",
    "                            if c not in component_dict.keys():\n",
    "                                component_dict.update({c: comp_id})\n",
    "                                comp_id += 1\n",
    "                                # comp_id = list(component_dict.keys()).index(c)\n",
    "\n",
    "                        # ORM processing\n",
    "                        # TODO : why error occurs when put interval_dict above, before the loop\n",
    "                        interval_dict = {}\n",
    "                        use_def_z = False\n",
    "                        for intv in strip:\n",
    "                            if average_z is not None and (row['Z'] is None or pd.isnull(row['Z'])):\n",
    "                                if isinstance(average_z, int) or isinstance(average_z, float):\n",
    "                                    z_val = average_z  # average Z coordinate of boreholes heads\n",
    "                                    if not use_def_z:\n",
    "                                        print(f\"{WARNING_TEXT_CONFIG['blue']}\"\n",
    "                                              f\"WARNING: Borehole's Z coordinate not found, use\"\n",
    "                                              f\" default one: {average_z} [m]\"\n",
    "                                              f\"{WARNING_TEXT_CONFIG['off']}\")\n",
    "                                        use_def_z = True\n",
    "                                else:\n",
    "                                    raise(TypeError(\"default_Z value must be int or float\"))\n",
    "                            else:\n",
    "                                z_val = row['Z']\n",
    "\n",
    "                            top = PositionOrm(id=pos_id, upper=z_val - intv.top.upper,\n",
    "                                              middle=z_val - intv.top.middle,\n",
    "                                              lower=z_val - intv.top.lower,\n",
    "                                              x=row['X'], y=row['Y']\n",
    "                                              )\n",
    "\n",
    "                            base = PositionOrm(id=pos_id + 1, upper=z_val - intv.base.upper,\n",
    "                                               middle=z_val - intv.base.middle,\n",
    "                                               lower=z_val - intv.base.lower,\n",
    "                                               x=row['X'], y=row['Y']\n",
    "                                               )\n",
    "\n",
    "                            desc = '; '.join([c.json() for c in intv.components])\n",
    "\n",
    "                            interval_dict.update({int_id: {'interval_number': interval_number,\n",
    "                                                    'top': top, 'base': base,\n",
    "                                                    'type': iv_type, 'description': desc}})\n",
    "\n",
    "                            intv_dict.update({int_id: {'interval_number': interval_number,\n",
    "                                                           'top': top, 'base': base,\n",
    "                                                           'type': iv_type, 'description': desc}})\n",
    "\n",
    "                            update_dict(intv_type_dict, {iv_type: interval_dict})\n",
    "\n",
    "                            for cp in intv.components:\n",
    "                                if cp != Component({}):\n",
    "                                    cp_key = list(cp.keys())[0]\n",
    "                                    cp_type = 'pollutant' if cp_key in contam_names else 'lithology'\n",
    "                                    cp_val = cp_key if cp_type == 'pollutant' else cp[cp_key]\n",
    "                                    cp_lev = cp[cp_key] if cp_type == 'pollutant' else None\n",
    "                                    unit = cp['unit'] if hasattr(cp, 'unit') else None\n",
    "                                    pol_conc = cp['concentration'] if hasattr(cp, 'concentration') else None\n",
    "                                    # remove 's' for plural words\n",
    "                                    if cp_val not in WORDS_WITH_S:\n",
    "                                        cp_val = cp_val.rstrip('s')\n",
    "                                    cp = Component({'type': cp_type, 'value': cp_val})\n",
    "\n",
    "                                    link_intv_comp_dict.update({(int_id, component_dict[cp]):\n",
    "                                        {'extra_data': str({'level': cp_lev,\n",
    "                                                            'concentration': pol_conc,\n",
    "                                                            'unit': unit})}\n",
    "                                                                })\n",
    "\n",
    "                            interval_number += 1\n",
    "                            int_id += 1\n",
    "                            pos_id += 2\n",
    "\n",
    "                        if bh_idx < len(boreholes_orm):\n",
    "                            # TODO : find a way to store differents type of intervals in ORM\n",
    "                            boreholes_orm[bh_idx].intervals_values = interval_dict\n",
    "                            # boreholes_orm[bh_idx].intervals_values = intv_dict  # just for testing\n",
    "                            if re.search('litho', iv_type, re.I):\n",
    "                                boreholes_orm[bh_idx].litho_intv_values = intv_type_dict['lithology']\n",
    "                            elif re.search('samp', iv_type, re.I):\n",
    "                                boreholes_orm[bh_idx].sample_intv_values = intv_type_dict['sample']\n",
    "                            else:\n",
    "                                raise(TypeError(f'Unknown interval type: {iv_type}'))\n",
    "\n",
    "                            if thick_col in final_df.columns:\n",
    "                                boreholes_orm[bh_idx].length = tmp[thick_col].cumsum().max()\n",
    "                            elif base_col in final_df.columns:\n",
    "                                boreholes_orm[bh_idx].length = tmp[base_col].max()\n",
    "\n",
    "                            diam_val = tmp[diameter_col][0]\n",
    "                            if diam_val is not None and not pd.isnull(diam_val):\n",
    "                                boreholes_orm[bh_idx].diameter = diam_val\n",
    "                            else:\n",
    "                                boreholes_orm[bh_idx].diameter = DEFAULT_BOREHOLE_DIAMETER\n",
    "                                print(f'No diameter value found, using default: '\n",
    "                                      f'{DEFAULT_BOREHOLE_DIAMETER}')\n",
    "\n",
    "                    bh_idx += 1\n",
    "\n",
    "            components_dict = {v: k for k, v in component_dict.items()}\n",
    "\n",
    "    print(f\"\\nEnd of the process : {bh_counter} boreholes created successfully\")\n",
    "\n",
    "    return boreholes_orm, components_dict, link_intv_comp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f29d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_project(data_dict, db_name, **kwargs):\n",
    "    for k,v in data_dict.items():\n",
    "        data_dict[k] = pd.read_csv(v, sep=',')\n",
    "    verbose = kwargs.pop('verbose', False)\n",
    "    sample_type_col = kwargs.pop('sample_type_col', 'Type_ech')\n",
    "    diameter_col = kwargs.pop('Diam_for', 0.1) \n",
    "    pollutants = kwargs.pop('pollutants', None)\n",
    "    litho_legend = kwargs.pop('litho_legend', DEFAULT_LITHO_LEGEND)\n",
    "    litho_lexicon = kwargs.pop('litho_lexicon', DEFAULT_LITHO_LEXICON)\n",
    "    # pollutants_legend = kwargs.pop('pollutants_legend', DEFAULT_POL_LEGEND)\n",
    "    pollutants_lexicon = kwargs.pop('pollutants_lexicon', DEFAULT_POL_LEXICON)\n",
    "\n",
    "    if pollutants is None:\n",
    "        pollutants = []\n",
    "        for i, c in enumerate(data_dict['pollutants_data'].columns):\n",
    "            if c in pollutants_lexicon.abbreviations.keys() or c in pollutants_lexicon.abbreviations.values():\n",
    "                pollutants.append(c)\n",
    "    average_z = kwargs.pop('average_z', 102) \n",
    "    attributes=kwargs.pop('attributes', ['lithology']+pollutants)\n",
    "    legend_dict = legend_from_attributes([('lithology', litho_legend)]+pollutants)\n",
    "    symbols=kwargs.pop('symbols', {'lithology':{'lexicon': litho_lexicon}})\n",
    "    boreholes, components, link_intv_comp = boreholes_from_dataframe(data_dict, verbose=verbose,\n",
    "                                                sample_type_col=sample_type_col, diameter_col=diameter_col, \n",
    "                                                average_z=average_z, attributes=attributes, \n",
    "                                                symbols=symbols)\n",
    "\n",
    "    if os.path.exists(db_name):\n",
    "        os.remove(db_name)\n",
    "\n",
    "    engine = create_engine(f\"sqlite:///{db_name}\", echo=True)\n",
    "    Base.metadata.create_all(engine)\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "    p = Project(session, name='Memoris_project', legend_dict=legend_dict, lexicon=DEFAULT_LITHO_LEXICON)\n",
    "    p.add_components(components)\n",
    "    for bh in boreholes:\n",
    "        p.add_borehole(bh)\n",
    "    p.add_link_components_intervals(link_intv_comp)\n",
    "    p.commit()\n",
    "    p.refresh()\n",
    "    session.close()\n",
    "    p.update_legend_cmap(compute_all_attrib=True, verbose=False)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56348b08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "Reindexing only valid with uniquely valued Index objects",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21436/3368872362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcreate_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test.db'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_21436/3554674680.py\u001b[0m in \u001b[0;36mcreate_project\u001b[0;34m(data_dict, db_name, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlegend_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlegend_from_attributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lithology'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitho_legend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mpollutants\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msymbols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'symbols'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'lithology'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'lexicon'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlitho_lexicon\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     boreholes, components, link_intv_comp = boreholes_from_dataframe(data_dict, verbose=verbose,\n\u001b[0m\u001b[1;32m     23\u001b[0m                                                 \u001b[0msample_type_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_type_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiameter_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdiameter_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                                 \u001b[0maverage_z\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21436/1758564539.py\u001b[0m in \u001b[0;36mboreholes_from_dataframe\u001b[0;34m(data_dict, symbols, attributes, id_col, diameter_col, average_z, date_col, sample_type_col, verbose)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mdf_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# data exploitation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/GSDMA-DRfwm83x/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8963\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8964\u001b[0m         return (\n\u001b[0;32m-> 8965\u001b[0;31m             concat(\n\u001b[0m\u001b[1;32m   8966\u001b[0m                 \u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8967\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/GSDMA-DRfwm83x/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/GSDMA-DRfwm83x/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/GSDMA-DRfwm83x/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    526\u001b[0m                     \u001b[0mobj_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m                         \u001b[0mindexers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/GSDMA-DRfwm83x/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_indexer\u001b[0;34m(self, target, method, limit, tolerance)\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_index_as_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3442\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_requires_unique_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3444\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_compare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_interval_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: Reindexing only valid with uniquely valued Index objects"
     ]
    }
   ],
   "source": [
    "create_project(data_dict, 'test.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2513e58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
