{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indonesian-alloy",
   "metadata": {},
   "source": [
    "# ORGANISATION DES DONNEES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "demanding-former",
   "metadata": {},
   "source": [
    "config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from utils.config import DEFAULT_POL_LEXICON, POL_NAMES_MODEL\n",
    "from definitions import ROOT_DIR\n",
    "from utils.io import dataframe_viewer, data_merger, data_validation, data_slicer, \\\n",
    "collect_time_data, replicate_values, gen_id_from_ech, na_col_drop, na_line_drop, col_ren, \\\n",
    "dble_col_drop, find_borehole_by_position, compute_borehole_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7feb75",
   "metadata": {},
   "source": [
    "### Creation du répertoire de sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1966c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = ROOT_DIR + '/CF_data/Result_traitem/organisation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a4fb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4014d",
   "metadata": {},
   "source": [
    "### Definition d'entêtes usuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a77803",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAS_NAMES_MODEL = {'Fraction   2000 µm':'Fract_2000µ', 'Fraction   63 µm':'Fract_63µ', 'Fraction   45 µm':'Fract_45µ', 'Fraction   16 µm':'Fract_16µ', \n",
    "                    'Fraction   2 µm':'Fract_2µ', 'Fraction 2 mm':'Fract_2', 'Fraction +2 mm':'Fract_2+', 'Fract_2':'Fract_2', 'Fract_2+':'Fract_2+', \n",
    "                    'Mat. organique':'MO', 'Mat. sèche':'MS', 'Argile':'Fract_arg', 'Fraction argileuse':'Fract_arg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_kw = ['O_diss','Niv_eau', 'temp', '^T$', '^CE$', 'pH$', 'ORP']\n",
    "meas_kw_col = ['O_diss','pH','CE','ORP','Niv_eau_pz','Niv_eau_sol','Temp']\n",
    "sufx = ['sup', 'prof', 'inf', '/\\dM(\\*)?']\n",
    "prefx = ['eau forage ']\n",
    "id_reg = '\\s*(?P<id>(?:^canne |Piezair )*\\w*\\d+\\w*)\\s*'\n",
    "pollutants_names = list(set(list(DEFAULT_POL_LEXICON.abbreviations.keys()) + list(POL_NAMES_MODEL.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16edcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type','Long_for','Long_pz','Sect_crep','Long_pz_sol','Ht_pz_sol',\n",
    "           'Diam_for','Diam_int_pz','Diam_ext_pz','Ht_chbre','Refus','Societe','Zone','Sous_zone','Etude','Method','Resp_chantier',\n",
    "           'Emplacement','Rmq']))\n",
    "\n",
    "mes_cols = list(set(['Date_mes','ID','ID_ech','X','Y','Z','Zsol','pH_H2O', 'Temp_pH_H2O', 'Temp_pH_CaCl2','pH_CaCl2','Temp_pH_KCl',\n",
    "            'pH_KCl','Residu_perte_feu','Fract_arg','Fract_min_2µ','Fract_min_50µ','Fract_min_2','Temp_pH_mes',\n",
    "            'pH_H20', 'Fract_min_2µ', 'Fract_min_50µ', 'Fract_min_2', 'pH_KCl', 'Temp_pH_mes', 'pH_H20', 'sulfures_tot''N_Kjdl','Temp_CE','Temp_pH','Nappe','Rmq','Fract_2000µ','Fract_63µ','Fract_45µ','Fract_16µ',\n",
    "            'Fract_2µ','Temp_ech', 'Periode'] + meas_kw_col + list(MEAS_NAMES_MODEL.values())))\n",
    "\n",
    "eqp_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type_equip','Equip_base','Equip_top',\n",
    "                     'Equip_epais','Rmq']))\n",
    "\n",
    "litho_cols = list(set(['Date_for','ID','ID_ech','X','Y','Z','Zsol','Long_for','Litho_top','Litho_base','Intv_top',\n",
    "                       'Intv_base','Litho_epais','Intv_epais','Description','Rmq']))\n",
    "\n",
    "an_cols = list(set(['ID','X','Y','Z','Zsol','Date_ech','ID_ech','Type_ech','Ech_top','Ech_base','Ech_epais',\n",
    "                    'Intv_top','Intv_base','Description','Nappe','Organo','Intensite', 'Min_organo', 'Max_organo',\n",
    "                    'Polluant','Surnageant','Sousnageant','Caractere','Opacite','Rmq'] + pollutants_names))\n",
    "\n",
    "ukw_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type','Long_for','Method','Societe','Rmq']))\n",
    "\n",
    "cols_dict = {'borehole': bh_cols, 'measure': mes_cols, 'lithology': litho_cols, 'analysis': an_cols, \n",
    " 'equipement': eqp_cols, 'unknown': ukw_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4674736",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_crit = ['ID','X','Y','Z','Zsol','Type','Long_for','Long_pz','Diam_for','Diam_int_pz','Diam_ext_pz']\n",
    "\n",
    "mes_crit = ['Date_mes'] + meas_kw_col + list(MEAS_NAMES_MODEL.values())\n",
    "\n",
    "eqp_crit = ['Type_equip','Equip_base','Equip_top']\n",
    "\n",
    "litho_crit = ['Litho_top','Litho_base','Intv_top','Intv_base','Description']\n",
    "\n",
    "an_crit = ['ID_ech','Type_ech','Organo','Surnageant','Sousnageant'] + list(DEFAULT_POL_LEXICON.abbreviations.keys()) \n",
    "\n",
    "ukw_crit = ['ID','X','Y','Z','Zsol','Long_for','Type']\n",
    "\n",
    "crit_dict = {'borehole': bh_crit, 'measure': mes_crit, 'lithology': litho_crit, 'analysis': an_crit, \n",
    " 'equipement': eqp_crit, 'unknown': ukw_crit}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfd064",
   "metadata": {},
   "source": [
    "variables utilisées par jeu de données\n",
    "================================\n",
    "- bh \t: \tforages (simple ou piezo)\n",
    "- equip\t:\tequipements d'un forage (outils, méthodes utilisés, ...)\n",
    "- ukw\t:\tobjets physiques indéterminés\n",
    "- litho :\tdescriptions lithologiques\n",
    "- an \t: \tanalyses de contaminants sur des échantillons (sol, eau)\n",
    "- mes\t:\tmesures de propriétés sur des échantillons (sol, eau), de paramètres hydrochimiques, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45736216",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-taxation",
   "metadata": {},
   "source": [
    "## 1- Profils sols et données forages.xls\n",
    "* **Sheet : 'Données de forage'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='donnees_forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "referenced-violin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', \n",
    "                   sheet_name='Données de forage')#, skiprows=2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ecdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Date':'Date_for','Profondeur':'Long_for', 'Méthode':'Method', \n",
    "                        'Diamètre forage':'Diam_for','Niv. Eau p/r sol':'Niv_eau_sol',\n",
    "                        'PZ Prof.':'Long_pz', 'PZ Diamètre':'Diam_pz','PZ L.crépinée':'Sect_crep', \n",
    "                        'Société forage':'Societe', 'Resp. chantier':'Resp_chantier'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = df['Long_pz'].apply(lambda x: 'Forage' if pd.isnull(x) else 'Piezo')\n",
    "df['Refus'] = ''\n",
    "\n",
    "for i in range(len(df['Remarque'])):\n",
    "    val = str(df.loc[i,'Remarque'])\n",
    "    if re.search('[Bb]loqué', val) :        \n",
    "        if re.search('[lL]aitier', val):\n",
    "            df.loc[i,'Refus'] = 'Laitier'\n",
    "        elif re.search('[Bb]éton', val):\n",
    "            df.loc[i,'Refus'] = 'Béton'\n",
    "        elif re.search('[Mm]atériaux', val):\n",
    "            df.loc[i,'Refus'] = 'Matériaux indurés' \n",
    "    else: \n",
    "        df.loc[i,'Refus'] = np.nan\n",
    "\n",
    "# convert diameter values unit from mm to m\n",
    "df['Diam_int_pz'] = df['Diam_pz'].apply(lambda x: pd.to_numeric(x.replace(' mm','').split('x')[1].strip(' m'))/1000 \n",
    "                                        if not pd.isnull(x) else x)\n",
    "df['Diam_ext_pz'] = df['Diam_pz'].apply(lambda x: pd.to_numeric(x.replace(' mm','').split('x')[0].strip(' m'))/1000 \n",
    "                                        if not pd.isnull(x) else x)\n",
    "df['Diam_for'] = df['Diam_for'].apply(lambda x: pd.to_numeric(x)/1000 if not pd.isnull(x) else x)\n",
    "\n",
    "df.insert(7, 'Diam_ext_pz', df.pop('Diam_ext_pz')) # move to a specified position\n",
    "df.insert(8, 'Diam_int_pz', df.pop('Diam_int_pz'))\n",
    "df.drop(columns=['Remarque', 'Diam_pz'], axis=1, inplace=True)\n",
    "df.drop(df.query(\"ID!=ID\").index, inplace=True) # delete all ID='NaN' lines\n",
    "df['Date_mes'] = df['Date_for']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b27dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date_for' in df.columns:\n",
    "    df['Date_for'] = df['Date_for'].astype('datetime64')\n",
    "if 'Date_mes' in df.columns:\n",
    "    df['Date_mes'] = df['Date_mes'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dac573f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175471f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes = mes\n",
    "source_bh = bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-crack",
   "metadata": {},
   "source": [
    "* **Sheet : 'Piézométrie'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='piezometrie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "future-israeli",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', sheet_name='Piézométrie', skiprows=1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123702f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf = na_col_drop(df[:12], 3)\n",
    "sdf.rename(columns={'z':'Z'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "for x in df.columns:\n",
    "    if pd.isnull(df.loc[16,x]):\n",
    "        df.loc[16,x]='col'+str(a)\n",
    "    a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bffc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'tmp_df' in vars().keys():\n",
    "    tmp_df = df.copy()\n",
    "    \n",
    "df = tmp_df.copy()\n",
    "df.loc[16]=df.loc[16].apply(lambda x : x if not pd.isnull(x) else '')\n",
    "df.columns = df.loc[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heavy-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[17:]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#df.drop(columns=[df.columns.to_list()[x] for x in range(0,8)\n",
    "#                      if re.compile(r\"col|unnamed\").match(df.columns.to_list()[x])], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'col8':'Date_mes', 'col9':'Nappe', 'col10':'ID', 'NP/piézo [m]':'Niv_eau_pz', \n",
    "                        'dim. piezo hors sol [m]':'Ht_pz_sol', 'NP/sol [m]':'Niv_eau_sol', \n",
    "                        'Prof. piézo/piézo [m]':'Long_pz', 'Prof. piézo/sol [m]':'Long_pz_sol', \n",
    "                        't° [°C]':'Temp', 'Observations':'Rmq'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = na_col_drop(df, 3)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ac3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CE'] = df[['CE [µS/cm]', 'CE [mS/cm]']].apply(lambda x: x[0]/1000 if pd.isnull(x[1]) else x[1], axis=1) # mS/cm\n",
    "df.drop(columns=['CE [µS/cm]', 'CE [mS/cm]'], inplace=True)\n",
    "df['ID'] = df['ID'].apply(lambda x: re.sub('P','F',x) if not pd.isnull(x) else x)\n",
    "df.insert(0, 'ID', df.pop('ID')) # move to first column\n",
    "df['Type'] = 'Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da944937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename_axis(None, inplace=True, axis=1)\n",
    "df.drop(df.query(\"ID!=ID\").index, inplace=True) # supprimer les lignes avec ID='NaN'\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d6af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date_for' in df.columns:\n",
    "    df['Date_for'] = df['Date_for'].astype('datetime64')\n",
    "if 'Date_mes' in df.columns:\n",
    "    df['Date_mes'] = df['Date_mes'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3809a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c923ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d322e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796be255",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddf8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh, conflict_df = data_merger(bh, sdf[['ID', 'Z']], how='outer', on='ID', dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba393a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on='ID', dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5c1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_pz_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID', 'Date_mes'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1d7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_rep = ['X', 'Y', 'Z']\n",
    "source_bh = replicate_values(source_bh, id_col='ID', cols_to_replicate=cols_rep, suffix=['sup', 'inf'], replace_id=True)\n",
    "source_mes = replicate_values(source_mes, id_col='ID', cols_to_replicate=cols_rep, suffix=['sup', 'inf'], replace_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-shanghai",
   "metadata": {},
   "source": [
    "* **Sheet : 'Equipement'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='Equipement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-gentleman",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', \n",
    "                   sheet_name='Equipement')#, skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Déplacement'], inplace=True)\n",
    "name=['ID', 'Equip_top', 'Equip_base', 'Diam_for','Diam_int_pz', 'Type_equip']\n",
    "df=col_ren(df, mode=1, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6099f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'Equip'\n",
    "compute_borehole_length(df, id_col='ID', mode='thickness', length_col=f'{prefix}_epais', \n",
    "                  top_col=f'{prefix}_top', base_col=f'{prefix}_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Diam_for'] = df['Diam_for'].apply(lambda x: pd.to_numeric(x)/1000 if not pd.isnull(x) else x)\n",
    "df['Diam_int_pz'] = df['Diam_int_pz'].apply(lambda x: pd.to_numeric(x)/1000 if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b24521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_ = source_bh[['ID', 'X', 'Y', 'Z']]\n",
    "df, conflict_df = data_merger(bh_, df, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37745b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = na_line_drop(df, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e28acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date_for' in df.columns:\n",
    "    df['Date_for'] = df['Date_for'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bbf2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1729409",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f38fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0abb8",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af86bae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbdeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Diam_for_y':list(conflict_df.index), 'Diam_int_pz_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9395f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = mdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95b0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = source_bh\n",
    "source_bh = replicate_values(data, 'ID', list(data.columns)).drop_duplicates(list(data.columns))\n",
    "source_bh.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_eqp = eqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-darwin",
   "metadata": {},
   "source": [
    "* **Sheets: 'Echantillon' + 'Organoleptique'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='Echant-organo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-groove",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', sheet_name='Echantillon')#, skiprows=1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'De':'Ech_top', 'A':'Ech_base', 'Numéro':'ID_ech'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, conflict_df = data_merger(df, sdf, 'outer', ['ID', 'Ech_top', 'Ech_base'])\n",
    "df['Type_ech']='Sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505738d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date_for' in df.columns:\n",
    "    df['Date_for'] = df['Date_for'].astype('datetime64')\n",
    "if 'Date_mes' in df.columns:\n",
    "    df['Date_mes'] = df['Date_mes'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4dff74",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed205991",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_ = source_bh[['ID', 'X', 'Y', 'Z']]\n",
    "df, conflict_df = data_merger(bh_, df, how='inner', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5768257e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c949db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd6998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf95c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27fb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-california",
   "metadata": {},
   "source": [
    "* **Sheet : 'Log'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='Log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stupid-theater",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', sheet_name='Log')#, skiprows=1)\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'De':'Litho_top', 'A':'Litho_base'}, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c336be3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "q=df.query('Keyword.str.contains(\".ointe\", regex=True)', engine='python').index\n",
    "df.drop(q, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'Litho'\n",
    "compute_borehole_length(df, id_col='ID', mode='thickness', length_col=f'{prefix}_epais', \n",
    "                  top_col=f'{prefix}_top', base_col=f'{prefix}_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbfd506",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_ = source_bh[['ID', 'X', 'Y', 'Z','Long_for']]\n",
    "df, conflict_df = data_merger(bh_, df, how='inner', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4ca304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86ef3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc0b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ab6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a365b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(bh, source_bh, how='outer', on='ID', dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho=litho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de59de",
   "metadata": {},
   "source": [
    "### $\\color{red}{\\textbf{Excel data final merge}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c5ee9cc",
   "metadata": {},
   "source": [
    "# Not really needed here because all source data have XYZ coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4879afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_coords = source_bh[['ID', 'X', 'Y', 'Z','Date_for']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf14e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_eqp, conflict_df = data_merger(bh_coords, source_eqp, how='inner', on='ID', dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fa60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho, conflict_df = data_merger(bh_coords, source_litho, how='inner', on='ID', dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cbe761",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(bh_coords, source_an, how='outer', on='ID', dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88c9e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False)\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False)\n",
    "source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3c0e5",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63c096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-benjamin",
   "metadata": {},
   "source": [
    "## 2-Database MEMORIS3.xlsx\n",
    "* **Sheet : 'PROFILS_SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Profils_sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indirect-korean",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. '+\n",
    "                        'Siterem - 2017/Database MEMORIS3.xlsx', sheet_name='PROFILS_SOL')#, skiprows=2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c808e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = na_col_drop(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "typical-century",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.rename({'Date':'Date_for', 'N°':'Ref', 'Id':'idx', 'Piézo':'Type', 'Unnamed: 6':'Societe',\n",
    "                'MFT Ø145':'MFT_145', 'Gouge Ø75':'Gouge_75', 'Liner Ø60': 'Liner_60'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-infection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(list(set(df['Date_for'].apply(lambda x: x.year if not pd.isnull(x) else x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.fillna('').query(\"Societe.str.contains('x|X')\").index, 'Type']='X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.fillna('').query(\"Gouge_75.str.contains('SBS|SITER')\").index, 'Societe']='SBS Environnement'\n",
    "df.loc[df.fillna('').query(\"Gouge_75.str.contains('SBS|SITER')\").index, 'Gouge_75']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['Date_for'])-1):\n",
    "    if not pd.isnull(df.loc[i, 'Date_for']) and pd.isnull(df.loc[i+1, 'Date_for']):\n",
    "        df.loc[i+1, 'Date_for']=df.loc[i, 'Date_for']\n",
    "        \n",
    "    if not pd.isnull(df.loc[i, 'Societe']) and pd.isnull(df.loc[i+1, 'Societe']):\n",
    "        df.loc[i+1, 'Societe']=df.loc[i, 'Societe']\n",
    "        \n",
    "    if not pd.isnull(df.loc[i, 'Type']) and pd.isnull(df.loc[i+1, 'Type']) and \\\n",
    "       df.loc[i, 'Ref']==df.loc[i+1, 'Ref']:\n",
    "        df.loc[i+1, 'Type']=df.loc[i, 'Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['idx'])-1):    \n",
    "    if df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur'])\\\n",
    "    and re.findall('Forage',df.loc[i, 'Profondeur']):\n",
    "        df.loc[i+1,'idx']=df.loc[i, 'Profondeur'][0]+str(df.loc[i, 'Ref'])\n",
    "        w=df.loc[i, 'Profondeur'][0]\n",
    "    elif df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur']):\n",
    "        df.loc[i+1,'idx']=w+str(df.loc[i, 'Ref'])\n",
    "    \n",
    "    if df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur'])\\\n",
    "    and re.findall('Tranch',df.loc[i, 'Profondeur']):\n",
    "        df.loc[i+1,'idx']=df.loc[i, 'Profondeur'][0]+str(df.loc[i, 'Ref'])\n",
    "        w=df.loc[i, 'Profondeur'][0]\n",
    "    elif df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur']):\n",
    "        df.loc[i+1,'idx']=w+str(df.loc[i, 'Ref'])\n",
    "     \n",
    "   # if df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur'])\\\n",
    "   # and re.findall('Moni',df.loc[i, 'Profondeur']):\n",
    "   #     df.loc[i+1,'idx']=df.loc[i, 'Profondeur'][0]+str(df.loc[i, 'Ref'])\n",
    "   #     w=df.loc[i, 'Profondeur'][0]\n",
    "   # elif df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur']):\n",
    "   #     df.loc[i+1,'idx']=w+str(df.loc[i, 'Ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "noticed-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ref']=df['idx'].apply(lambda x : x if re.findall('F|T', str(x)) else '')\n",
    "df['Ref']=df['idx'].apply(lambda x : x.replace('FMonito ', 'Mon') if re.findall('FMonit', str(x)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type']=df['Type'].apply(lambda x: 'Piezo' if not pd.isnull(x) else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ref']=df['Ref'].apply(lambda x: re.sub(\"\\.1\",\"a\",str(x)) if re.search(r\"\\.1\", str(x)) else x)\n",
    "df['Ref']=df['Ref'].apply(lambda x: re.sub(\"\\.2\",\"b\",str(x)) if re.search(r\"\\.2\", str(x)) else x)\n",
    "df['Ref']=df['Ref'].apply(lambda x: re.sub(\"\\.3\",\"c\",str(x)) if re.search(r\"\\.3\", str(x)) else x)\n",
    "df['Ref']=df['Ref'].apply(lambda x: re.sub(\"\\.4\",\"d\",str(x)) if re.search(r\"\\.4\", str(x)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-state",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.query('Profondeur!=Profondeur' ).index,'Profondeur']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Method']=''\n",
    "            \n",
    "for i in range(len(df['Method'])):\n",
    "    if not pd.isnull(df.loc[i, 'Gouge_75']) : df.loc[i, 'Method']='Gouge_75'\n",
    "    if not pd.isnull(df.loc[i, 'MFT_145']) : df.loc[i, 'Method']='MFT_145'\n",
    "    if not pd.isnull(df.loc[i, 'Liner_60']) : df.loc[i, 'Method']='Liner_60'\n",
    "    if not pd.isnull(df.loc[i, 'carottier']) : df.loc[i, 'Method']='carrotier'\n",
    "    if not pd.isnull(df.loc[i, 'tarrière']) : df.loc[i, 'Method']='tarrière'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.query('Profondeur.str.contains(\"Forage\") and Profondeur!=\"Forage bloqué\"', engine='python').index, inplace=True)\n",
    "df.drop(df.query('Profondeur.str.contains(\"Tranc\") and Profondeur!=\"Tranchée bloqué\"', engine='python').index, inplace=True)\n",
    "df.drop(df.query('Profondeur.str.contains(\".orage|..ranch\", regex=True)', engine='python').index, inplace=True)\n",
    "df.drop(df.fillna('').query('Description.str.contains(\"^.orage bloq|^.ranc.* bloq|^.*efus\", regex=True)', engine='python').index, inplace=True)\n",
    "df.drop(df.query('Ref!=Ref').index, inplace=True)\n",
    "df.drop(columns=['MFT_145','Gouge_75','Liner_60', 'carottier', 'tarrière', 'idx'], axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Litho_top'] = df['Profondeur'].apply(lambda x: x.replace(',','.').split('-')[0].strip(' m'))\n",
    "df['Litho_base'] = df['Profondeur'].apply(lambda x: x.replace(',','.').split('-')[-1].strip(' m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'Ref':'ID'}, axis=1, inplace=True)\n",
    "if 'Profondeur' in df.columns: df.drop(columns=['Profondeur'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5d13bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].apply(lambda x: str(x).strip('\\n') if re.search('\\n',str(x), flags=re.I) else str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dimensional-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1268, 'ID'] = \"F406\"\n",
    "df.loc[df.query('Description.isnull() or Description.str.len()<1').index, 'Description'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-termination",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([x[0] for x in list(set(df.ID)) if isinstance(x,str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minor-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df.query('Litho_top == \"\"').index, inplace=True)\n",
    "df.loc[df.query('ID.str.contains(\"T\")', engine='python').index, 'Type'] = 'Tranchee'\n",
    "df.loc[df.query('Type==\"\"', engine='python').index, 'Type'] = 'Forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df.query('Litho_base.isnull() or Litho_base.str.len()<1').index, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65f78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    if pd.isnull(df.loc[i, 'ID']): print(i, df.loc[i, 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c767b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'Litho'\n",
    "compute_borehole_length(df, id_col='ID', mode='thickness', length_col=f'{prefix}_epais', \n",
    "                  top_col=f'{prefix}_top', base_col=f'{prefix}_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f94f2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16680d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4223bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = bh.loc[bh.query('Type==\"Tranchee\"', engine='python')[list(ukw.columns)].index] # trenches\n",
    "ukw['Type'] = 'Inconnu'\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bh = bh.drop(index=ukw.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "finite-arbor",
   "metadata": {},
   "source": [
    "print(df.loc[802, ['ID','Description','Method','Litho_top', 'Litho_base']])\n",
    "df.query('Description.isnull() or Description.str.contains(\"Bloqu\")', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho = litho\n",
    "source_bh = bh\n",
    "source_ukw = ukw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d71274",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-dress",
   "metadata": {},
   "source": [
    "* **Sheet : 'DONNEES PIEZOS'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "young-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Donnees_piezos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-injection",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. '+\n",
    "                        'Siterem - 2017/Database MEMORIS3.xlsx', sheet_name='DONNEES PIEZOS', skiprows=2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba741e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Ref_id','ID','Societe','Zone','Sous_zone','X','Y','Zsol','Z','Nappe','Long_pz','Sect_crep',\n",
    "         'Diam_int_pz','Niv_eau_pz_27/04/2010','Niv_eau_pz_08/09/2010','Niv_eau_sol_27/04/2010',\n",
    "         'Niv_eau_sol_08/09/2010','Surnageant','Sousnageant','Caractere','Opacite','Rmq']\n",
    "df = col_ren(df, mode=1, name=names)\n",
    "df = na_col_drop(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.query(\"ID==ID\")\n",
    "df.replace('-',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc43f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sousnageant']=df['Sousnageant'].apply(lambda x: x/100 if not pd.isnull(x) else x) #convert unit in [m]\n",
    "df['Surnageant']=df['Surnageant'].apply(lambda x: x/100 if not pd.isnull(x) else x)\n",
    "df['Type']=df['Sect_crep'].apply(lambda x: 'Piezo' if not pd.isnull(x) else 'Inconnu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ID','X','Y','Z','Zsol','Type','Long_pz','Diam_int_pz','Sect_crep','Nappe','Societe','Zone','Sous_zone',\n",
    "         'Niv_eau_pz_27/04/2010','Niv_eau_pz_08/09/2010','Niv_eau_sol_27/04/2010','Niv_eau_sol_08/09/2010',\n",
    "         'Surnageant','Sousnageant','Caractere',\n",
    "      'Opacite','Rmq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = 'ID'\n",
    "df[id_col] = df[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434f61e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collect_time_data(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29f49190",
   "metadata": {},
   "source": [
    "cols = ['X','Y','Z']\n",
    "df = data\n",
    "df = replicate_values(df, 'ID', cols, ['prof', 'sup', 'inf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fc7b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(df, id_ech_col='ID', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)\n",
    "\n",
    "id_col = 'ID_ech'\n",
    "if 'X' in df.columns: \n",
    "    df = df.query(f'{id_col}=={id_col} and X==X')\n",
    "else:\n",
    "    df = df.query(f'{id_col}=={id_col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662396b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028be1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a525e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "an['Type_ech'] = 'Eau'\n",
    "an = an.drop_duplicates('ID_ech').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2259dee",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82670bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc628e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ukw, conflict_df = data_merger(source_ukw, ukw, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a9439",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-collection",
   "metadata": {},
   "source": [
    "* **Sheet : 'DRAINS ET PIEZOS ENEL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visible-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Drains_Pz_ENEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-thomson",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. Siterem - 2017/Database MEMORIS3.xlsx', \n",
    "                        sheet_name='DRAINS ET PIEZOS ENEL', skiprows=1)\n",
    "\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b22a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(5, 'Z', df.pop('PZ absolue (m)'))\n",
    "df.rename(columns={'N°':'ID', 'Date ':'Date_ech','Hauteur de la chambre ':'Ht_chbre','T':'Temp', 'ETUDE':'Etude',\n",
    "                   'Niv_EAU_SOL (m)': 'Niv_eau_sol_01/10/2013', 'Niv_EAU_SOL (m).1':'Niv_eau_sol_14/12/2016', \n",
    "                   'Prof_PZ':'Long_pz','Section_crépinée':'Sect_crep', 'Diamètre_int':'Diam_int_pz', 'Odiss':'O_diss',\n",
    "                   '\\nC5-C8':'C5-C8'}, inplace=True)\n",
    "df = df.query('ID==ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41083ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collect_time_data(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64bb7de9",
   "metadata": {},
   "source": [
    "cols = list(df.columns)[:-2]\n",
    "df = replicate_values(df, 'ID', cols, suffix=['prof', 'sup', 'inf'], replace_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CE']=df['CE'].apply(lambda x: pd.to_numeric(x)/1000 \n",
    "                                  if re.search('^\\d+', str(x)) and not pd.isnull(x) else np.nan) # -> in mS/cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f914cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df.query('ID.str.contains(\"nan\", regex=True)', engine='python').index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846611e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(df, id_ech_col='ID', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7008d5da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = col_ren(df, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "drop = []\n",
    "for c in data.columns:\n",
    "    c = re.sub('\\s+$|\\\\n','', c)\n",
    "    if re.match('\\s*\\w+\\s*-\\s*\\w+\\s*', c):\n",
    "        c_mod = c.replace(' ','')\n",
    "        data.rename(columns={c:c_mod}, inplace=True)\n",
    "        c = c_mod\n",
    "    if re.search('\\w+_<\\d*>', c):\n",
    "        drop.append(c)\n",
    "data.drop(columns=drop, inplace=True)\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be7ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640de751",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2368f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f06097",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh.insert(0, 'Type', 'Piezo')\n",
    "an.insert(0, 'Type_ech', 'Eau')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855e711",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067e6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e756bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID','Date_mes'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3778a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-fifteen",
   "metadata": {},
   "source": [
    "* **Sheet : 'RESULTS_EAU' (F)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Result_eau'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. Siterem - 2017/Database MEMORIS3.xlsx', \n",
    "                        sheet_name='RESULTS_EAU', skiprows=1)\n",
    "\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patent-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Campagne':'Societe','N_piezo.':'ID','Z tête PZ':'Z', 'Prof_PZ':'Long_pz',\n",
    "                   'Niv_EAU_TETE (m)':'Niv_eau_pz_27/04/2010','Niv_EAU_SOL (m)':'Niv_eau_sol_27/04/2010',\n",
    "                   'Unnamed: 13':'Niv_eau_pz_08/09/2010','Unnamed: 15':'Niv_eau_sol_08/09/2010','T':'Temp',\n",
    "                   'Section_crépinée':'Sect_crep','Diamètre_int':'Diam_int_pz','Description éch.':'Opacite',\n",
    "                   'Odiss':'O_diss','Remarques':'Rmq','Aquifère_échantillonné':'Nappe', \n",
    "                   'Caractéristique':'Caractere'}, inplace=True)\n",
    "\n",
    "df=df.query(\"ID ==ID\")\n",
    "df.replace('-',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc48ad2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['Type']=df['Sect_crep'].apply(lambda x: 'Piezo' if not pd.isnull(x) else 'Inconnu')\n",
    "df.insert(8, 'Type', df.pop('Type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1620be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to express value in [m]\n",
    "df['Surnageant']=df['Surnageant'].apply(lambda x: x/100)\n",
    "df['Sousnageant']=df['Sousnageant'].apply(lambda x: x/100)\n",
    "df['CE']=df['CE'].apply(lambda x: pd.to_numeric(x)/1000 \n",
    "                        if re.search('^\\d+', str(x)) and not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e363665",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = collect_time_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71785471",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "drop = []\n",
    "for c in data.columns:\n",
    "    c_mod = re.sub('\\s+$|\\n','', c)\n",
    "    if re.match('\\s*\\w+\\s*-\\s*\\w+\\s*', c_mod):\n",
    "        c_mod = c_mod.replace(' ','')\n",
    "    if re.search('\\w+_<\\d*>', c_mod):\n",
    "        drop.append(c)\n",
    "    data.rename(columns={c:c_mod}, inplace=True)\n",
    "data.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400b8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8548ee37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = col_ren(df, name=POL_NAMES_MODEL, mode=1, cutoff=0.7)#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751cb70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'3,5+2,3-dimethylphénol+4-ethylphénol' : 'DMetPhn_4-EthPhn', 'chrome (VI)': 'Cr_VI',\n",
    "                   '2,4+2,5-dichlorophénol' : '2.4_5-DCPhn', 'sulfites':'Sulfite'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446cec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(df, id_ech_col='ID', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a0d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ecb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8c217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = an\n",
    "data.drop_duplicates(list(data.columns), inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data['Type_ech'] = 'eau'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0178a1c",
   "metadata": {},
   "source": [
    "##### data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e20ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a96db2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b4373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID_ech', 'Z', 'Date_mes'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ukw, conflict_df = data_merger(source_ukw, ukw, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fe0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-house",
   "metadata": {},
   "source": [
    "* **Sheet : 'RESULTS_SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Result_sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-joyce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. Siterem - 2017/'\n",
    "                   'Database MEMORIS3.xlsx', sheet_name='RESULTS_SOL', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 92':'EOX', 'Unnamed: 93':'Idc_phenol','Campagne':'Societe','N_forage':'ID','refus':'Refus',\n",
    "                   'Prof.\\nforage':'Long_for', 'N_ech':'ID_ech', 'Min_Ech':'Ech_top','Max_Ech':'Ech_base',\n",
    "                   'Terrain':'Nappe','Epaisseur remblais':'Ep_remb', 'Epaisseur alluvions':'Ep_alluv',\n",
    "                   'pH H2O':'pH_H2O','T° pH H2O':'Temp_pH_H2O','T° pH CaCl2':'Temp_pH_CaCl2','pH CaCl2':'pH_CaCl2', \n",
    "                   'T° pH KCl':'Temp_pH_KCl', 'pH KCl':'pH_KCl', 'T° CE':'Temp_CE', 'Argile ':'Argile', \n",
    "                   'Résidus chauffage':'Residu_perte_feu','Nature':'Polluant', 'Intensité':'Intensite',\n",
    "                   'Libres':'CN_libre','Fraction   2000 µm':'Fract_2000µ','Fraction   63 µm':'Fract_63µ', \n",
    "                   'Fraction   45 µm':'Fract_45µ','Fraction   16 µm':'Fract_16µ','Fraction   2 µm':'Fract_2µ',\n",
    "                   'Totaux':'CN_tot'\n",
    "                  }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[df.columns.to_list()[x] for x in range(len(df.columns))\n",
    "                      if re.search(r\"Unnamed\",df.columns.to_list()[x])], axis=1, inplace=True) \n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df=df.query('ID==ID')\n",
    "df['ID']=df['ID'].apply(lambda x : x.replace('Monito ', 'Mon') if re.findall('Monit', str(x)) else x)\n",
    "df['ID_ech']=df['ID_ech'].apply(lambda x : x.replace('Monito ', 'Mon') if re.findall('Monit', str(x)) else x)\n",
    "df.replace('-',np.nan, inplace=True)\n",
    "df.insert(5, 'Type', 'Piezo')\n",
    "df.insert(6, 'Type_ech', 'Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    #r=re.search('(\\w+)/.+',str(df.loc[i, 'ID_ech']))\n",
    "    #if r : df.loc[i, 'ID']=r.group(1)\n",
    "    r=re.search('^\\d+',str(df.loc[i, 'ID']))\n",
    "    if r : df.loc[i, 'ID']='F'+str(df.loc[i, 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Refus']=df['Refus'].apply(lambda x: 'x' if not pd.isnull(x) else '')\n",
    "df.replace('#',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    x=df.loc[i,'Nappe']\n",
    "    if not re.search('^F|^Mo', str(df.loc[i,'ID'])) : df.loc[i,'Type']='Inconnu'\n",
    "        \n",
    "    if re.search('[R|r]em', str(x)) : df.loc[i,'Nappe']='Remblais'\n",
    "    elif re.search('[A|a]ll', str(x)) : df.loc[i,'Nappe']='Alluvions'\n",
    "    elif re.search('[S|s]oc', str(x)) : df.loc[i,'Nappe']='Socle'\n",
    "    elif re.search('[A|a]rg', str(x)) : df.loc[i,'Nappe']='Argile'\n",
    "    else : df.loc[i,'Nappe']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2cec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_mes'] = '2050-01-01' # watch out !\n",
    "#df['Date_mes'] = df['Date_mes'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b643100e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = col_ren(df, name=POL_NAMES_MODEL, mode=1, cutoff=0.7)#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    x = df.loc[i,'X']\n",
    "    y = df.loc[i,'Y']\n",
    "    if isinstance(x, str): \n",
    "        df.loc[i,'X'] = float(x.replace(',','.'))\n",
    "        df.loc[i,'Y'] = float(y.replace(',','.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ec2437",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7bf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Argile':'Fract_arg'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11831e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b8d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5c8a7",
   "metadata": {},
   "source": [
    "##### data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c1d0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689e2d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',\n",
    "                valid_dict={'Societe_x':list(conflict_df.index), 'Type_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9383b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fa1997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4060b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID','Date_mes'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_mes\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)\n",
    "source_mes = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484a7068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_ukw, conflict_df = data_merger(source_ukw, ukw, how='outer', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd86a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737593b",
   "metadata": {},
   "source": [
    "### $\\color{red}{\\textbf{Excel data final merge}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84f7589c",
   "metadata": {},
   "source": [
    "source_dict = {'bh':bh.copy(),'eqp':eqp.copy(),'ukw':ukw.copy(),'litho':litho.copy(),'an':an.copy(),'mes':mes.copy()}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34d188b5",
   "metadata": {},
   "source": [
    "# Not really needed here because all source data have XYZ coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43831f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_coords = source_bh[['ID', 'X', 'Y', 'Z','Date_for']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a2d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, bh_coords, how='left', on='ID', dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fd3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho, conflict_df = data_merger(source_litho, bh_coords, how='left', on='ID', dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_litho\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Date_for_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)\n",
    "source_litho = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb4bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, bh_coords, how='left', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f21163",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ukw, conflict_df = data_merger(source_ukw, bh_coords, how='left', on=['ID'], dist_max=1, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c72bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False)\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False)\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187304e",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029bdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-rwanda",
   "metadata": {},
   "source": [
    "## 3-obsrevations terrain et mesures piézos phase 2.xlsx\n",
    "\n",
    "* **Sheet : 'Piézométrie'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'observ_terrain/'\n",
    "sheet='Piezometrie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/résultats phase 2/'\n",
    "                   'obsrevations terrain et mesures piézos phase 2.xlsx', sheet_name='Piézométrie', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf=df[df.columns.to_list()[:3]]\n",
    "sdf=na_line_drop(sdf,0)\n",
    "sdf.rename(columns={'Niveau \\npiézométrique':'Niv_eau_sol', 'Commentaires ':'Date_ech'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf2=df.loc[:11, df.columns.to_list()[3:-1]]\n",
    "sdf2.rename(columns={'Unnamed: 7':'Date_mes', 'Unnamed: 8':'Nappe', 'Unnamed: 9':'ID', 'NP/piézo [m]':'Niv_eau_pz',\n",
    "       'dim. piezo hors sol [m]':'Ht_pz_sol', 'NP/sol [m]':'Niv_eau_sol', 'Prof. piézo/piézo [m]':'Long_pz',\n",
    "       'Prof. piézo/sol [m]':'Long_pz_sol', 'CE [mS/cm]':'CE','t° [°C]':'Temp','O2 dissous\\n[%]':'O_diss', \n",
    "        'Observations':'Rmq'}, \n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sdf2['ID'])):\n",
    "    sdf2.loc[i,'ID']=re.sub(r'^P','F', sdf2.loc[i,'ID'])\n",
    "    \n",
    "    if pd.isnull(sdf2.loc[i,'CE']) and not pd.isnull(sdf2.loc[i,'CE [µS/cm]']):\n",
    "        sdf2.loc[i,'CE']=sdf2.loc[i,'CE [µS/cm]']/1000\n",
    "\n",
    "sdf2.drop(['CE [µS/cm]'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[14:, df.columns.to_list()[3:-1]]\n",
    "df.rename(columns={'Unnamed: 7':'Date_mes', 'Unnamed: 8':'Nappe', 'Unnamed: 9':'ID', 'NP/piézo [m]':'Niv_eau_pz',\n",
    "       'dim. piezo hors sol [m]':'Ht_pz_sol', 'NP/sol [m]':'Niv_eau_sol', 'Prof. piézo/piézo [m]':'Long_pz',\n",
    "       'Prof. piézo/sol [m]':'Long_pz_sol', 'CE [mS/cm]':'CE','t° [°C]':'Temp','O2 dissous\\n[%]':'O_diss', \n",
    "        'Observations':'Rmq'}, \n",
    "           inplace=True)\n",
    "df.drop([19,20], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['ID'])):\n",
    "    df.loc[i,'ID']=re.sub(r'^P','F', df.loc[i,'ID'])\n",
    "    \n",
    "    if pd.isnull(df.loc[i,'CE']) and not pd.isnull(df.loc[i,'CE [µS/cm]']):\n",
    "        df.loc[i,'CE']=df.loc[i,'CE [µS/cm]']/1000\n",
    "        \n",
    "df.drop(['CE [µS/cm]', 'O_diss'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, conflict_df=data_merger(sdf2, df, how='outer', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = na_col_drop(df, 5)\n",
    "df['Type'] = 'Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff8a7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c1420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31572ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = bh\n",
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b901e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
