{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indonesian-alloy",
   "metadata": {},
   "source": [
    "# ORGANISATION DES DONNEES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "demanding-former",
   "metadata": {},
   "source": [
    "config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "naughty-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import update_dict, gen_dated_id, dataframe_viewer, gen_geodf_geom, data_merger, data_validation, \\\n",
    "data_slicer, replicate_values, collect_measure, collect_time_data, gen_id_from_ech, na_col_drop, na_line_drop, col_ren, \\\n",
    "dble_col_drop, dict_viewer\n",
    "\n",
    "from utils.config import DEFAULT_POL_LEXICON, POL_NAMES_MODEL \n",
    "from difflib import get_close_matches\n",
    "\n",
    "import re, os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import datetime as dtm\n",
    "import matplotlib.pyplot as plt\n",
    "from definitions import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "limiting-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_BH_length(df, id_col='ID', length_col_name='Long_for', top_col='Intv_top', base_col='Intv_base', verbose=False):\n",
    "    \n",
    "    if length_col_name in df.columns:\n",
    "        raise(NameError(f'{length_col_name} is already in columns. Give another name'))\n",
    "    \n",
    "    for i in df.index:\n",
    "        try:\n",
    "            float(df.loc[i, top_col])\n",
    "        except ValueError:\n",
    "            df.loc[i, top_col] = np.nan\n",
    "\n",
    "        try:\n",
    "            float(df.loc[i, base_col])\n",
    "        except ValueError:\n",
    "            df.loc[i, base_col] = np.nan\n",
    "\n",
    "    df[top_col] = df[top_col].astype('float64')\n",
    "    df[base_col] = df[base_col].astype('float64')\n",
    "\n",
    "    # compute length based on litho_top and litho_base\n",
    "    id_list = []\n",
    "\n",
    "    for i in df.index:\n",
    "        id_ = df.loc[i,id_col]\n",
    "        \n",
    "        if verbose : print(i, id_, df.loc[i, top_col], df.loc[i, base_col])\n",
    "        if id_ not in id_list:\n",
    "            id_list.append(id_)\n",
    "            if isinstance(id_, str):\n",
    "                sql_id = f\"{id_}\"\n",
    "            elif isinstance(id_, float) or isinstance(id_, int):\n",
    "                sql_id = id_\n",
    "                \n",
    "            tmp = df[df[id_col] == sql_id]\n",
    "            \n",
    "            if verbose : print(len(tmp))\n",
    "            #if len(tmp) > 0:\n",
    "            df.loc[tmp.index, length_col_name] = float(max(tmp[base_col])) - float(min(tmp[top_col]))\n",
    "    \n",
    "    df.drop(index=df.query(f'{base_col}.isnull() and {top_col}.isnull()').index, inplace=True)\n",
    "    df.insert(df.columns.to_list().index(id_col)+1, length_col_name, df.pop(length_col_name))\n",
    "    #df.reset_index(drop=True, inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7feb75",
   "metadata": {},
   "source": [
    "### Creation du répertoire de sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1966c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = ROOT_DIR + '/CF_data/Result_traitem/organisation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "92ea68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4014d",
   "metadata": {},
   "source": [
    "### Definition de variables usuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20a77803",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAS_NAMES_MODEL = {'Fraction   2000 µm':'Fract_2000µ', 'Fraction   63 µm':'Fract_63µ', 'Fraction   45 µm':'Fract_45µ', 'Fraction   16 µm':'Fract_16µ', \n",
    "                    'Fraction   2 µm':'Fract_2µ', 'Fraction 2 mm':'Fract_2', 'Fraction +2 mm':'Fract_2+', 'Fract_2':'Fract_2', 'Fract_2+':'Fract_2+', \n",
    "                    'Mat. organique':'MO', 'Mat. sèche':'MS', 'Argile':'Fract_arg', 'Fraction argileuse':'Fract_arg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41959670",
   "metadata": {},
   "outputs": [],
   "source": [
    "POL_NAMES_MODEL = {**POL_NAMES_MODEL, **MEAS_NAMES_MODEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4e08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_kw = ['O_diss','Niv_eau', 'temp', '^T$', '^CE$', 'pH$', 'ORP']\n",
    "meas_kw_col = ['O_diss','pH','CE','ORP','Niv_eau_pz','Niv_eau_sol','Temp']\n",
    "sufx = ['sup', 'prof', 'inf', '/\\dM(\\*)?']\n",
    "prefx = ['eau forage ']\n",
    "id_reg = '\\s*(?P<id>(?:^canne |Piezair )*\\w*\\d+\\w*)\\s*'\n",
    "pollutants_names = list(set(list(DEFAULT_POL_LEXICON.abbreviations.keys()) + list(POL_NAMES_MODEL.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c16edcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type','Long_for','Long_pz','Sect_crep','Long_pz_sol','Ht_pz_sol',\n",
    "           'Diam_for','Diam_int_pz','Diam_ext_pz','Ht_chbre','Refus','Societe','Zone','Sous_zone','Etude','Method','Resp_chantier',\n",
    "           'Emplacement','ID_date','Rmq']))\n",
    "\n",
    "mes_cols = list(set(['Date_mes','ID','ID_ech','X','Y','Z','Zsol','pH_H2O', 'Temp_pH_H2O', 'Temp_pH_CaCl2','pH_CaCl2','Temp_pH_KCl',\n",
    "            'pH_KCl','Residu_perte_feu','Fract_arg','Fract_min_2µ','Fract_min_50µ','Fract_min_2','Temp_pH_mes',\n",
    "            'pH_H20', 'Fract_min_2µ', 'Fract_min_50µ', 'Fract_min_2', 'pH_KCl', 'Temp_pH_mes', 'pH_H20', 'sulfures_tot''N_Kjdl','Temp_CE','Temp_pH','Nappe','Rmq','Fract_2000µ','Fract_63µ','Fract_45µ','Fract_16µ',\n",
    "            'Fract_2µ','Temp_ech', 'Periode'] + meas_kw_col + list(MEAS_NAMES_MODEL.values())))\n",
    "\n",
    "eqp_cols = list(set(list(set(['Date_for','ID','X','Y','Z','Zsol','Type_equip','Equip_base','Equip_top','Rmq']))))\n",
    "\n",
    "litho_cols = list(set(['Date_for','ID','ID_ech','X','Y','Z','Zsol','Long_for','Litho_top','Litho_base','Intv_top','Intv_base',\n",
    "              'Description','Rmq']))\n",
    "\n",
    "an_cols = list(set(['ID','X','Y','Z','Zsol','Date_ech','ID_ech','Type_ech','Ech_top','Ech_base','Intv_top','Intv_base',\n",
    "           'Description','Nappe','Organo','Intensite', 'Min_organo', 'Max_organo', 'Polluant',\n",
    "           'Surnageant','Sousnageant','Caractere','Opacite','Rmq'] + pollutants_names))\n",
    "\n",
    "ukw_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type','Long_for','Method','Societe','Rmq']))\n",
    "\n",
    "cols_dict = {'borehole': bh_cols, 'measure': mes_cols, 'lithology': litho_cols, 'analysis': an_cols, \n",
    " 'equipement': eqp_cols, 'unknown': ukw_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4674736",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_crit = ['ID','X','Y','Z','Zsol','Type','Long_for','Long_pz','Diam_for','Diam_int_pz','Diam_ext_pz']\n",
    "\n",
    "mes_crit = ['ID','ID_ech','Date_mes'] + meas_kw_col\n",
    "\n",
    "eqp_crit = ['Type_equip','Equip_base','Equip_top']\n",
    "\n",
    "litho_crit = ['Litho_top','Litho_base','Intv_top','Intv_base','Description']\n",
    "\n",
    "an_crit = ['ID_ech','Type_ech','Organo','Surnageant','Sousnageant'] + list(DEFAULT_POL_LEXICON.abbreviations.keys()) \n",
    "\n",
    "ukw_crit = ['ID','X','Y','Z','Zsol','Long_for','Type']\n",
    "\n",
    "crit_dict = {'borehole': bh_crit, 'measure': mes_crit, 'lithology': litho_crit, 'analysis': an_crit, \n",
    " 'equipement': eqp_crit, 'unknown': ukw_crit}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfd064",
   "metadata": {},
   "source": [
    "variables utilisées par jeu de données\n",
    "================================\n",
    "- bh \t: \tforages (simple ou piezo)\n",
    "- equip\t:\tequipements d'un forage (outils, méthodes utilisés, ...)\n",
    "- ukw\t:\tobjets physiques indéterminés\n",
    "- litho :\tdescriptions lithologiques\n",
    "- an \t: \tanalyses de contaminants sur des échantillons (sol, eau)\n",
    "- mes\t:\tmesures de propriétés sur des échantillons (sol, eau), de paramètres hydrochimiques, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45736216",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flying-disabled",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 0 ; source_eqp: 0 ; source_uknw: 0 ; source_litho: 0 ; source_an: 0 ; source_mes: 0\n"
     ]
    }
   ],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-taxation",
   "metadata": {},
   "source": [
    "## 1- Profils sols et données forages.xls\n",
    "* **Sheet : 'Données de forage'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "emerging-dylan",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='donnees_forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "referenced-violin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 25, columns : 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370080bd46e84925b10d6b78ae7e5a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='rows', max=25, min=5, readout=False), IntSlider(value=12…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', \n",
    "                   sheet_name='Données de forage')#, skiprows=2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5ecdf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Date':'Date_for','Profondeur':'Long_for', 'Méthode':'Method', \n",
    "                        'Diamètre forage':'Diam_for','Niv. Eau p/r sol':'Niv_eau_sol',\n",
    "                        'PZ Prof.':'Long_pz', 'PZ Diamètre':'Diam_pz','PZ L.crépinée':'Sect_crep', \n",
    "                        'Société forage':'Societe', 'Resp. chantier':'Resp_chantier'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "furnished-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = df['Long_pz'].apply(lambda x: 'Forage' if pd.isnull(x) else 'Piezo')\n",
    "df['Refus'] = ''\n",
    "\n",
    "for i in range(len(df['Remarque'])):\n",
    "    val = str(df.loc[i,'Remarque'])\n",
    "    if re.search('[Bb]loqué', val) :        \n",
    "        if re.search('[lL]aitier', val):\n",
    "            df.loc[i,'Refus'] = 'Laitier'\n",
    "        elif re.search('[Bb]éton', val):\n",
    "            df.loc[i,'Refus'] = 'Béton'\n",
    "        elif re.search('[Mm]atériaux', val):\n",
    "            df.loc[i,'Refus'] = 'Matériaux indurés' \n",
    "    else: \n",
    "        df.loc[i,'Refus'] = np.nan\n",
    "\n",
    "# convert diameter values unit from mm to m\n",
    "df['Diam_int_pz'] = df['Diam_pz'].apply(lambda x: pd.to_numeric(x.replace(' mm','').split('x')[1].strip(' m'))/1000 \n",
    "                                        if not pd.isnull(x) else x)\n",
    "df['Diam_ext_pz'] = df['Diam_pz'].apply(lambda x: pd.to_numeric(x.replace(' mm','').split('x')[0].strip(' m'))/1000 \n",
    "                                        if not pd.isnull(x) else x)\n",
    "df['Diam_for'] = df['Diam_for'].apply(lambda x: pd.to_numeric(x)/1000 if not pd.isnull(x) else x)\n",
    "\n",
    "df.insert(7, 'Diam_ext_pz', df.pop('Diam_ext_pz')) # move to a specified position\n",
    "df.insert(8, 'Diam_int_pz', df.pop('Diam_int_pz'))\n",
    "df.drop(columns=['Remarque', 'Diam_pz'], axis=1, inplace=True)\n",
    "df.drop(df.query(\"ID!=ID\").index, inplace=True) # delete all ID='NaN' lines\n",
    "df['Date_mes'] = df['Date_for']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0b27dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date_for' in df.columns:\n",
    "    df['Date_for'] = df['Date_for'].astype('datetime64')\n",
    "if 'Date_mes' in df.columns:\n",
    "    df['Date_mes'] = df['Date_mes'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7175471f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 25 ; measure: 25 ; lithology: 0 ; analysis: 0 ; equipement: 0 ; unknown: 0 ; \n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe35e616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 25 ; measure: 25 ; lithology: 0 ; analysis: 0 ;equipement: 0 ; unknown: 0\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "chief-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes = mes\n",
    "source_bh = bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "becoming-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 25 ; source_eqp: 0 ; source_uknw: 0 ; source_litho: 0 ; source_an: 0 ; source_mes: 25\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-crack",
   "metadata": {},
   "source": [
    "* **Sheet : 'Piézométrie'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "pregnant-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='piezometrie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "future-israeli",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 37, columns : 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8457e073ca476f84c67e263466ae85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='rows', max=37, min=5, readout=False), IntSlider(value=12…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', sheet_name='Piézométrie', skiprows=1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "123702f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped :['Label', 'Commentaires ', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = na_col_drop(df[:12], 3)\n",
    "sdf.rename(columns={'z':'Z'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "recognized-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0\n",
    "for x in df.columns:\n",
    "    if pd.isnull(df.loc[16,x]):\n",
    "        df.loc[16,x]='col'+str(a)\n",
    "    a+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9bffc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 'tmp_df' in vars().keys():\n",
    "    tmp_df = df.copy()\n",
    "    \n",
    "df = tmp_df.copy()\n",
    "df.loc[16]=df.loc[16].apply(lambda x : x if not pd.isnull(x) else '')\n",
    "df.columns = df.loc[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "heavy-market",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[17:]\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#df.drop(columns=[df.columns.to_list()[x] for x in range(0,8)\n",
    "#                      if re.compile(r\"col|unnamed\").match(df.columns.to_list()[x])], axis=1, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "english-television",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'col8':'Date_mes', 'col9':'Nappe', 'col10':'ID', 'NP/piézo [m]':'Niv_eau_pz', \n",
    "                        'dim. piezo hors sol [m]':'Ht_pz_sol', 'NP/sol [m]':'Niv_eau_sol', \n",
    "                        'Prof. piézo/piézo [m]':'Long_pz', 'Prof. piézo/sol [m]':'Long_pz_sol', \n",
    "                        't° [°C]':'Temp', 'Observations':'Rmq'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e839d943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped :['col0', 'col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = na_col_drop(df, 3)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "115ac3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CE'] = df[['CE [µS/cm]', 'CE [mS/cm]']].apply(lambda x: x[0]/1000 if pd.isnull(x[1]) else x[1], axis=1) # mS/cm\n",
    "df.drop(columns=['CE [µS/cm]', 'CE [mS/cm]'], inplace=True)\n",
    "df['ID'] = df['ID'].apply(lambda x: re.sub('P','F',x) if not pd.isnull(x) else x)\n",
    "df.insert(0, 'ID', df.pop('ID')) # move to first column\n",
    "df['Type'] = 'Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da944937",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename_axis(None, inplace=True, axis=1)\n",
    "df.drop(df.query(\"ID!=ID\").index, inplace=True) # supprimer les lignes avec ID='NaN'\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45d6af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date_for' in df.columns:\n",
    "    df['Date_for'] = df['Date_for'].astype('datetime64')\n",
    "if 'Date_mes' in df.columns:\n",
    "    df['Date_mes'] = df['Date_mes'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c923ec4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 17 ; measure: 17 ; lithology: 0 ; analysis: 0 ; equipement: 0 ; unknown: 0 ; \n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d322e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 17 ; measure: 17 ; lithology: 0 ; analysis: 0 ;equipement: 0 ; unknown: 0\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796be255",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ddf8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh, conflict_df = data_merger(bh, sdf[['ID', 'Z']], how='outer', on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bba393a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflict values present. Please resolve this manually !\n"
     ]
    }
   ],
   "source": [
    "mdf, conflict_df = data_merger(source_bh, bh, how='outer', on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6d5c1664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all conflicts have been fixed!\n"
     ]
    }
   ],
   "source": [
    "dataset = mdf\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_pz_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac7cec3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a86e331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID', 'Date_mes'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a1d7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_rep = ['X', 'Y', 'Z']\n",
    "source_bh = replicate_values(source_bh, id_col='ID', cols_to_replicate=cols_rep, suffix=['sup', 'inf'], replace_id=True)\n",
    "source_mes = replicate_values(source_mes, id_col='ID', cols_to_replicate=cols_rep, suffix=['sup', 'inf'], replace_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7fe5bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 30 ; source_eqp: 0 ; source_uknw: 0 ; source_litho: 0 ; source_an: 0 ; source_mes: 42\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-shanghai",
   "metadata": {},
   "source": [
    "* **Sheet : 'Equipement'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aquatic-distance",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='Equipement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dying-gentleman",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 36, columns : 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0b1e1afe634cd5b6db7f5d9173343c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='rows', max=36, min=5, readout=False), IntSlider(value=7,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', \n",
    "                   sheet_name='Equipement')#, skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "speaking-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Déplacement'], inplace=True)\n",
    "name=['ID', 'Equip_top', 'Equip_base', 'Diam_for','Diam_int_pz', 'Type_equip']\n",
    "df=col_ren(df, mode=1, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "thermal-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_BH_length(df, id_col='ID', length_col_name='Long_pz', top_col='Equip_top', base_col='Equip_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0ebc436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Diam_for'] = df['Diam_for'].apply(lambda x: pd.to_numeric(x)/1000 if not pd.isnull(x) else x)\n",
    "df['Diam_int_pz'] = df['Diam_int_pz'].apply(lambda x: pd.to_numeric(x)/1000 if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b24521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_ = source_bh[['ID', 'X', 'Y', 'Z']]\n",
    "df, conflict_df = data_merger(bh_, df, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37745b8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 NaN lines dropped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanathan/.local/share/virtualenvs/GSDMA-DRfwm83x/lib/python3.8/site-packages/pandas/core/frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df = na_line_drop(df, 3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e28acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date_for' in df.columns:\n",
    "    df['Date_for'] = df['Date_for'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c1729409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 36 ; measure: 0 ; lithology: 0 ; analysis: 0 ; equipement: 36 ; unknown: 0 ; \n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36f38fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 12 ; measure: 0 ; lithology: 0 ; analysis: 0 ;equipement: 36 ; unknown: 0\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be0abb8",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af86bae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflict values present. Please resolve this manually !\n"
     ]
    }
   ],
   "source": [
    "mdf, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea80f316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all conflicts have been fixed!\n"
     ]
    }
   ],
   "source": [
    "data_validation(overall_data=mdf, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_pz_x':list(conflict_df.index), 'Diam_for_y':list(conflict_df.index), \n",
    "                           'Diam_int_pz_y':list(conflict_df.index)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "edbdeeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9395f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = mdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d95b0615",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = source_bh\n",
    "source_bh = replicate_values(data, 'ID', list(data.columns)).drop_duplicates(list(data.columns))\n",
    "source_bh.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "arbitrary-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_eqp = eqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "sixth-character",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 27 ; source_eqp: 36 ; source_uknw: 0 ; source_litho: 0 ; source_an: 0 ; source_mes: 42\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expensive-darwin",
   "metadata": {},
   "source": [
    "* **Sheets: 'Echantillon' + 'Organoleptique'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "altered-watershed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='Echant-organo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "electoral-groove",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 29, columns : 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54bbe6a053824e1a9f8e5143afcc5f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='rows', max=29, min=5, readout=False), IntSlider(value=4,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', sheet_name='Echantillon')#, skiprows=1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "assured-melbourne",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'De':'Ech_top', 'A':'Ech_base', 'Numéro':'ID_ech'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2326d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df, conflict_df = data_merger(df, sdf, 'outer', ['ID', 'Ech_top', 'Ech_base'])\n",
    "df['Type_ech']='Sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "505738d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Date_for' in df.columns:\n",
    "    df['Date_for'] = df['Date_for'].astype('datetime64')\n",
    "if 'Date_mes' in df.columns:\n",
    "    df['Date_mes'] = df['Date_mes'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2e54099a",
   "metadata": {},
   "source": [
    "cnt = 0\n",
    "for i in df.index:\n",
    "    if pd.isnull(df.loc[i, 'ID_ech']):\n",
    "        cnt +=1\n",
    "        df.loc[i, 'ID_ech'] = df.loc[i, 'ID'] + '_org_' + str(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4dff74",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed205991",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_ = source_bh[['ID', 'X', 'Y', 'Z']]\n",
    "df, conflict_df = data_merger(bh_, df, how='inner', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5768257e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 29 ; measure: 29 ; lithology: 0 ; analysis: 29 ; equipement: 0 ; unknown: 0 ; \n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c949db23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 15 ; measure: 29 ; lithology: 0 ; analysis: 29 ;equipement: 0 ; unknown: 0\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9bf95c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d27fb423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 27 ; source_eqp: 36 ; source_uknw: 0 ; source_litho: 0 ; source_an: 29 ; source_mes: 42\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Samples.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-california",
   "metadata": {},
   "source": [
    "* **Sheet : 'Log'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "loaded-house",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'profils_sols_donnees_forages/'\n",
    "sheet='Log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "stupid-theater",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 55, columns : 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3ae844d3084c68b614f0a731be62d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='rows', max=55, min=5, readout=False), IntSlider(value=5,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/Profils sols et données forages.xls', sheet_name='Log')#, skiprows=1)\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aerial-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'De':'Litho_top', 'A':'Litho_base'}, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c336be3",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "q=df.query('Keyword.str.contains(\".ointe\", regex=True)', engine='python').index\n",
    "df.drop(q, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "burning-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_BH_length(df, id_col='ID', length_col_name='Long_for', top_col='Litho_top', base_col='Litho_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1cbfd506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflict values present. Please resolve this manually !\n"
     ]
    }
   ],
   "source": [
    "bh_ = source_bh[['ID', 'X', 'Y', 'Z','Long_for']]\n",
    "df, conflict_df = data_merger(bh_, df, how='inner', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c10f3165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all conflicts have been fixed!\n"
     ]
    }
   ],
   "source": [
    "data_validation(overall_data=df, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_for_x':list(conflict_df.index)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e4ca304",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "edbc0b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 55 ; measure: 0 ; lithology: 55 ; analysis: 0 ; equipement: 0 ; unknown: 0 ; \n",
      "\n",
      "\u001b[1;32mNot used columns:\u001b[0;0m\n",
      " ['Keyword']\n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e629ffdd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 55, columns : 9, Unique values on cols: {'ID': 25, 'ID_ech': 'NA'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea141a46801c452598203514642deceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='rows', max=55, min=10, readout=False), IntSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataframe_viewer(df, rows=10, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "56849fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 25 ; measure: 0 ; lithology: 55 ; analysis: 0 ;equipement: 0 ; unknown: 0\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a365b81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(bh, source_bh, how='outer', on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cheap-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho=litho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1fc0bc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 27 ; source_eqp: 36 ; source_uknw: 0 ; source_litho: 55 ; source_an: 29 ; source_mes: 42\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Samples.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de59de",
   "metadata": {},
   "source": [
    "### $\\color{red}{\\textbf{Excel data final merge}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c5ee9cc",
   "metadata": {},
   "source": [
    "# Not really needed here because all source data have XYZ coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a4879afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_coords = source_bh[['ID', 'X', 'Y', 'Z','Date_for']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bf14e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_eqp, conflict_df = data_merger(bh_coords, source_eqp, how='inner', on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90fa60e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho, conflict_df = data_merger(bh_coords, source_litho, how='inner', on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "68cbe761",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(bh_coords, source_an, how='outer', on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f88c9e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 27 ; source_eqp: 36 ; source_uknw: 0 ; source_litho: 55 ; source_an: 41 ; source_mes: 42\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False)\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False)\n",
    "source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e3c0e5",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e63c096d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 0 ; source_eqp: 0 ; source_uknw: 0 ; source_litho: 0 ; source_an: 0 ; source_mes: 0\n"
     ]
    }
   ],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-benjamin",
   "metadata": {},
   "source": [
    "## 2-Database MEMORIS3.xlsx\n",
    "* **Sheet : 'PROFILS_SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "metropolitan-juvenile",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Profils_sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "indirect-korean",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 2041, columns : 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3292e48a8964e6d87ef81024cdfef57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='rows', max=2041, min=3, readout=False), IntSlider(value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. '+\n",
    "                        'Siterem - 2017/Database MEMORIS3.xlsx', sheet_name='PROFILS_SOL')#, skiprows=2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0c808e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped :['Unnamed: 12', 1927, 'Unnamed: 14', 'Unnamed: 15']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = na_col_drop(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "typical-century",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.rename({'Date':'Date_for', 'N°':'Ref', 'Id':'idx', 'Piézo':'Type', 'Unnamed: 6':'Societe',\n",
    "                'MFT Ø145':'MFT_145', 'Gouge Ø75':'Gouge_75', 'Liner Ø60': 'Liner_60'}, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "durable-infection",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NaT, 2009, 2010, 2015]\n"
     ]
    }
   ],
   "source": [
    "print(list(set(df['Date_for'].apply(lambda x: x.year if not pd.isnull(x) else x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "supreme-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.fillna('').query(\"Societe.str.contains('x|X')\").index, 'Type']='X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "legislative-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.fillna('').query(\"Gouge_75.str.contains('SBS|SITER')\").index, 'Societe']='SBS Environnement'\n",
    "df.loc[df.fillna('').query(\"Gouge_75.str.contains('SBS|SITER')\").index, 'Gouge_75']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "creative-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['Date_for'])-1):\n",
    "    if not pd.isnull(df.loc[i, 'Date_for']) and pd.isnull(df.loc[i+1, 'Date_for']):\n",
    "        df.loc[i+1, 'Date_for']=df.loc[i, 'Date_for']\n",
    "        \n",
    "    if not pd.isnull(df.loc[i, 'Societe']) and pd.isnull(df.loc[i+1, 'Societe']):\n",
    "        df.loc[i+1, 'Societe']=df.loc[i, 'Societe']\n",
    "        \n",
    "    if not pd.isnull(df.loc[i, 'Type']) and pd.isnull(df.loc[i+1, 'Type']) and \\\n",
    "       df.loc[i, 'Ref']==df.loc[i+1, 'Ref']:\n",
    "        df.loc[i+1, 'Type']=df.loc[i, 'Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "upper-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['idx'])-1):    \n",
    "    if df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur'])\\\n",
    "    and re.findall('Forage',df.loc[i, 'Profondeur']):\n",
    "        df.loc[i+1,'idx']=df.loc[i, 'Profondeur'][0]+str(df.loc[i, 'Ref'])\n",
    "        w=df.loc[i, 'Profondeur'][0]\n",
    "    elif df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur']):\n",
    "        df.loc[i+1,'idx']=w+str(df.loc[i, 'Ref'])\n",
    "    \n",
    "    if df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur'])\\\n",
    "    and re.findall('Tranch',df.loc[i, 'Profondeur']):\n",
    "        df.loc[i+1,'idx']=df.loc[i, 'Profondeur'][0]+str(df.loc[i, 'Ref'])\n",
    "        w=df.loc[i, 'Profondeur'][0]\n",
    "    elif df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur']):\n",
    "        df.loc[i+1,'idx']=w+str(df.loc[i, 'Ref'])\n",
    "     \n",
    "   # if df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur'])\\\n",
    "   # and re.findall('Moni',df.loc[i, 'Profondeur']):\n",
    "   #     df.loc[i+1,'idx']=df.loc[i, 'Profondeur'][0]+str(df.loc[i, 'Ref'])\n",
    "   #     w=df.loc[i, 'Profondeur'][0]\n",
    "   # elif df.loc[i,'Ref']==df.loc[i+1,'Ref'] and not pd.isnull(df.loc[i, 'Profondeur']):\n",
    "   #     df.loc[i+1,'idx']=w+str(df.loc[i, 'Ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "noticed-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ref']=df['idx'].apply(lambda x : x if re.findall('F|T', str(x)) else '')\n",
    "df['Ref']=df['idx'].apply(lambda x : x.replace('Monito ', 'Mon') if re.findall('Monit', str(x)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ignored-community",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type']=df['Type'].apply(lambda x: 'Piezo' if not pd.isnull(x) else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "thrown-parent",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Ref']=df['Ref'].apply(lambda x: re.sub(\"\\.1\",\"a\",str(x)) if re.search(r\"\\.1\", str(x)) else x)\n",
    "df['Ref']=df['Ref'].apply(lambda x: re.sub(\"\\.2\",\"b\",str(x)) if re.search(r\"\\.2\", str(x)) else x)\n",
    "df['Ref']=df['Ref'].apply(lambda x: re.sub(\"\\.3\",\"c\",str(x)) if re.search(r\"\\.3\", str(x)) else x)\n",
    "df['Ref']=df['Ref'].apply(lambda x: re.sub(\"\\.4\",\"d\",str(x)) if re.search(r\"\\.4\", str(x)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "photographic-speaking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation of ID-dated...\n",
      "Using column ' Date_for ' in the (geo)dataframe !\n",
      "Process ended, check the (geo)dataframe\n"
     ]
    }
   ],
   "source": [
    "gen_dated_id(df, ref_col='Ref', date_col='Date_for')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "utility-state",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.query('Profondeur!=Profondeur' ).index,'Profondeur']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "impaired-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Method']=''\n",
    "            \n",
    "for i in range(len(df['Method'])):\n",
    "    if not pd.isnull(df.loc[i, 'Gouge_75']) : df.loc[i, 'Method']='Gouge_75'\n",
    "    if not pd.isnull(df.loc[i, 'MFT_145']) : df.loc[i, 'Method']='MFT_145'\n",
    "    if not pd.isnull(df.loc[i, 'Liner_60']) : df.loc[i, 'Method']='Liner_60'\n",
    "    if not pd.isnull(df.loc[i, 'carottier']) : df.loc[i, 'Method']='carrotier'\n",
    "    if not pd.isnull(df.loc[i, 'tarrière']) : df.loc[i, 'Method']='tarrière'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "relevant-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.query('Profondeur.str.contains(\"Forage\") and Profondeur!=\"Forage bloqué\"', engine='python').index, inplace=True)\n",
    "df.drop(df.query('Profondeur.str.contains(\"Tranc\") and Profondeur!=\"Tranchée bloqué\"', engine='python').index, inplace=True)\n",
    "df.drop(df.query('Profondeur.str.contains(\".orage|..ranch\", regex=True)', engine='python').index, inplace=True)\n",
    "df.drop(df.fillna('').query('Description.str.contains(\"^.orage bloq|^.ranc.* bloq|^.*efus\", regex=True)', engine='python').index, inplace=True)\n",
    "df.drop(df.query('Ref!=Ref').index, inplace=True)\n",
    "df.drop(columns=['MFT_145','Gouge_75','Liner_60', 'carottier', 'tarrière', 'idx'], axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "satisfied-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Litho_top'] = df['Profondeur'].apply(lambda x: x.replace(',','.').split('-')[0].strip(' m'))\n",
    "df['Litho_base'] = df['Profondeur'].apply(lambda x: x.replace(',','.').split('-')[-1].strip(' m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "human-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename({'Ref':'ID'}, axis=1, inplace=True)\n",
    "if 'Profondeur' in df.columns: df.drop(columns=['Profondeur'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "appreciated-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F', 'T'}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([x[0] for x in list(set(df.ID)) if isinstance(x,str)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "minor-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.query('ID_date.str.contains(\"T\")', engine='python').index, 'Type'] = 'Tranchee'\n",
    "df.loc[df.query('Type==\"\"', engine='python').index, 'Type'] = 'Forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dimensional-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1268, ['ID_date','ID']] = df.loc[1267, ['ID_date','ID']]\n",
    "df.loc[df.query('Description.isnull() or Description.str.len()<1').index, 'Description'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "planned-going",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df.query('Litho_base.isnull() or Litho_base.str.len()<1').index, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ongoing-electron",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_BH_length(df, id_col='ID', length_col_name='Long_for', top_col='Litho_top', base_col='Litho_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "df16680d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 1628 ; measure: 0 ; lithology: 1628 ; analysis: 0 ; equipement: 0 ; unknown: 0 ; \n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4223bab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 298 ; measure: 0 ; lithology: 1628 ; analysis: 0 ;equipement: 0 ; unknown: 0\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "equivalent-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = bh.loc[bh.query('Type==\"Tranchee\"', engine='python')[list(ukw.columns)].index] # trenches\n",
    "ukw['Type'] = 'Inconnu'\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "\n",
    "bh = bh.drop(index=ukw.index).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "finite-arbor",
   "metadata": {},
   "source": [
    "print(df.loc[802, ['ID','Description','Method','Litho_top', 'Litho_base']])\n",
    "df.query('Description.isnull() or Description.str.contains(\"Bloqu\")', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "pressing-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho = litho\n",
    "source_bh = bh\n",
    "source_ukw = ukw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "31d71274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 281 ; source_eqp: 0 ; source_uknw: 17 ; source_litho: 1628 ; source_an: 0 ; source_mes: 0\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Samples.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-dress",
   "metadata": {},
   "source": [
    "* **Sheet : 'DONNEES PIEZOS'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "young-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Donnees_piezos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "comfortable-injection",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 130, columns : 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae59e11f1e9d474b95b6da804215165d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='rows', max=130, min=3, readout=False), IntSlider(value=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. '+\n",
    "                        'Siterem - 2017/Database MEMORIS3.xlsx', sheet_name='DONNEES PIEZOS', skiprows=2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "eba741e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Ref_id','ID','Societe','Zone','Sous_zone','X','Y','Zsol','Z','Nappe','Long_pz','Sect_crep',\n",
    "         'Diam_int_pz','Niv_eau_pz_27/04/2010','Niv_eau_pz_08/09/2010','Niv_eau_sol_27/04/2010',\n",
    "         'Niv_eau_sol_08/09/2010','Surnageant','Sousnageant','Caractere','Opacite','Rmq']\n",
    "df = col_ren(df, mode=1, name=names)\n",
    "df = na_col_drop(df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "catholic-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.query(\"ID==ID\")\n",
    "df.replace('-',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "dc43f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sousnageant']=df['Sousnageant'].apply(lambda x: x/100 if not pd.isnull(x) else x) #convert unit in [m]\n",
    "df['Surnageant']=df['Surnageant'].apply(lambda x: x/100 if not pd.isnull(x) else x)\n",
    "df['Type']=df['Sect_crep'].apply(lambda x: 'Piezo' if not pd.isnull(x) else 'Inconnu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fiscal-triple",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ID','X','Y','Z','Zsol','Type','Long_pz','Diam_int_pz','Sect_crep','Nappe','Societe','Zone','Sous_zone',\n",
    "         'Niv_eau_pz_27/04/2010','Niv_eau_pz_08/09/2010','Niv_eau_sol_27/04/2010','Niv_eau_sol_08/09/2010',\n",
    "         'Surnageant','Sousnageant','Caractere',\n",
    "      'Opacite','Rmq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "434f61e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates found: ['27/04/2010', '08/09/2010']\n"
     ]
    }
   ],
   "source": [
    "df = collect_time_data(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29f49190",
   "metadata": {},
   "source": [
    "cols = ['X','Y','Z']\n",
    "df = data\n",
    "df = replicate_values(df, 'ID', cols, ['prof', 'sup', 'inf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f86fc7b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(df, id_ech_col='ID', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)\n",
    "\n",
    "id_col = 'ID_ech'\n",
    "if 'X' in df.columns: \n",
    "    df = df.query(f'{id_col}=={id_col} and X==X')\n",
    "else:\n",
    "    df = df.query(f'{id_col}=={id_col}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b6aa7ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 260 ; measure: 260 ; lithology: 0 ; analysis: 260 ; equipement: 0 ; unknown: 26 ; \n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "028be1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 111 ; measure: 260 ; lithology: 0 ; analysis: 260 ;equipement: 0 ; unknown: 13\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "67a525e3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "an['Type_ech'] = 'Eau'\n",
    "an = an.drop_duplicates('ID_ech').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb7662b4",
   "metadata": {},
   "source": [
    "mes = collect_measure(mes, ['niv'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2259dee",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7757261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a5c3f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "82670bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fc628e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ukw, conflict_df = data_merger(source_ukw, ukw, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "814a9439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 392 ; source_eqp: 0 ; source_uknw: 30 ; source_litho: 1628 ; source_an: 130 ; source_mes: 260\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Samples.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-collection",
   "metadata": {},
   "source": [
    "* **Sheet : 'DRAINS ET PIEZOS ENEL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "visible-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Drains_Pz_ENEL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "sublime-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 21, columns : 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51906fcbce3b48e2b58846af95764ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=3, description='rows', max=21, min=3, readout=False), IntSlider(value=12…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. Siterem - 2017/Database MEMORIS3.xlsx', \n",
    "                        sheet_name='DRAINS ET PIEZOS ENEL', skiprows=1)\n",
    "\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0b22a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(5, 'Z', df.pop('PZ absolue (m)'))\n",
    "df.rename(columns={'N°':'ID', 'Date ':'Date_ech','Hauteur de la chambre ':'Ht_chbre','T':'Temp', 'ETUDE':'Etude',\n",
    "                   'Niv_EAU_SOL (m)': 'Niv_eau_sol_01/10/2013', 'Niv_EAU_SOL (m).1':'Niv_eau_sol_14/12/2016', \n",
    "                   'Prof_PZ':'Long_pz','Section_crépinée':'Sect_crep', 'Diamètre_int':'Diam_int_pz', 'Odiss':'O_diss',\n",
    "                   '\\nC5-C8':'C5-C8'}, inplace=True)\n",
    "df = df.query('ID==ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "41083ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates found: ['14/12/2016', '01/10/2013']\n"
     ]
    }
   ],
   "source": [
    "df = collect_time_data(df)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64bb7de9",
   "metadata": {},
   "source": [
    "cols = list(df.columns)[:-2]\n",
    "df = replicate_values(df, 'ID', cols, suffix=['prof', 'sup', 'inf'], replace_id=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "373f4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CE']=df['CE'].apply(lambda x: pd.to_numeric(x)/1000 \n",
    "                                  if re.search('^\\d+', str(x)) and not pd.isnull(x) else np.nan) # -> in mS/cm"
   ]
  },
  {
   "cell_type": "raw",
   "id": "24857fb4",
   "metadata": {},
   "source": [
    "df = collect_measure(df, params_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f2f914cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df.query('ID.str.contains(\"nan\", regex=True)', engine='python').index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "846611e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(df, id_ech_col='ID', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7008d5da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;34mPossible new pollutants names:\u001b[0;0m\n",
      "['ID_ech', 'Date_ech', 'Etude', 'X', 'Y', 'Z', 'Zsol', 'Ht_chbre', 'Long_pz', 'Sect_crep', 'Diam_int_pz', 'PZ relative (m)', 'pH', 'CE', 'Temp', 'ORP', 'O_diss', 'CN_libre', 'CN_totaux.1', 'CN_totaux.2', 'BTEX total', 'C5-C8', 'C8-C10', 'C10-C12', 'C12-C16', ' C16 - C21', 'C10-C12.1', 'C12-C22', 'C22-C30', 'C30-C40', 'Date_mes', 'Niv_eau_sol', 'ID']\n"
     ]
    }
   ],
   "source": [
    "df = col_ren(df, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "90f3dc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "drop = []\n",
    "for c in data.columns:\n",
    "    c = re.sub('\\s+$|\\\\n','', c)\n",
    "    if re.match('\\s*\\w+\\s*-\\s*\\w+\\s*', c):\n",
    "        c_mod = c.replace(' ','')\n",
    "        data.rename(columns={c:c_mod}, inplace=True)\n",
    "        c = c_mod\n",
    "    if re.search('\\w+_<\\d*>', c):\n",
    "        drop.append(c)\n",
    "data.drop(columns=drop, inplace=True)\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "640de751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 38 ; measure: 38 ; lithology: 0 ; analysis: 38 ; equipement: 0 ; unknown: 0 ; \n",
      "\n",
      "\u001b[1;32mNot used columns:\u001b[0;0m\n",
      " ['PZ relative (m)']\n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c2368f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 15 ; measure: 38 ; lithology: 0 ; analysis: 38 ;equipement: 0 ; unknown: 0\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "01f06097",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh.insert(0, 'Type', 'Piezo')\n",
    "an.insert(0, 'Type_ech', 'Eau')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e855e711",
   "metadata": {},
   "source": [
    "##### Data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "067e6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9e756bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e76e919d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID','Date_mes'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3778a182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 407 ; source_eqp: 0 ; source_uknw: 30 ; source_litho: 1628 ; source_an: 149 ; source_mes: 298\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Samples.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-fifteen",
   "metadata": {},
   "source": [
    "* **Sheet : 'RESULTS_EAU' (F)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "working-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Result_eau'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "pressing-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 131, columns : 185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a3c5d93f6d45a2808ac49edd10dd67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=5, description='rows', max=131, min=5, readout=False), IntSlider(value=1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. Siterem - 2017/Database MEMORIS3.xlsx', \n",
    "                        sheet_name='RESULTS_EAU', skiprows=1)\n",
    "\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "patent-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanathan/.local/share/virtualenvs/GSDMA-DRfwm83x/lib/python3.8/site-packages/pandas/core/frame.py:5238: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'Campagne':'Societe','N_piezo.':'ID','Z tête PZ':'Z', 'Prof_PZ':'Long_pz',\n",
    "                   'Niv_EAU_TETE (m)':'Niv_eau_pz_27/04/2010','Niv_EAU_SOL (m)':'Niv_eau_sol_27/04/2010',\n",
    "                   'Unnamed: 13':'Niv_eau_pz_08/09/2010','Unnamed: 15':'Niv_eau_sol_08/09/2010','T':'Temp',\n",
    "                   'Section_crépinée':'Sect_crep','Diamètre_int':'Diam_int_pz','Description éch.':'Opacite',\n",
    "                   'Odiss':'O_diss','Remarques':'Rmq','Aquifère_échantillonné':'Nappe', \n",
    "                   'Caractéristique':'Caractere'}, inplace=True)\n",
    "\n",
    "df=df.query(\"ID ==ID\")\n",
    "df.replace('-',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "cc48ad2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28594/260021800.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Type']=df['Sect_crep'].apply(lambda x: 'Piezo' if not pd.isnull(x) else 'Inconnu')\n"
     ]
    }
   ],
   "source": [
    "df['Type']=df['Sect_crep'].apply(lambda x: 'Piezo' if not pd.isnull(x) else 'Inconnu')\n",
    "df.insert(8, 'Type', df.pop('Type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ab1620be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_28594/3722196056.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Surnageant']=df['Surnageant'].apply(lambda x: x/100)\n",
      "/tmp/ipykernel_28594/3722196056.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Sousnageant']=df['Sousnageant'].apply(lambda x: x/100)\n",
      "/tmp/ipykernel_28594/3722196056.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['CE']=df['CE'].apply(lambda x: pd.to_numeric(x)/1000\n"
     ]
    }
   ],
   "source": [
    "# to express value in [m]\n",
    "df['Surnageant']=df['Surnageant'].apply(lambda x: x/100)\n",
    "df['Sousnageant']=df['Sousnageant'].apply(lambda x: x/100)\n",
    "df['CE']=df['CE'].apply(lambda x: pd.to_numeric(x)/1000 \n",
    "                        if re.search('^\\d+', str(x)) and not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "9e363665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dates found: ['27/04/2010', '08/09/2010']\n"
     ]
    }
   ],
   "source": [
    "df = collect_time_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "71785471",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "drop = []\n",
    "for c in data.columns:\n",
    "    c_mod = re.sub('\\s+$|\\n','', c)\n",
    "    if re.match('\\s*\\w+\\s*-\\s*\\w+\\s*', c_mod):\n",
    "        c_mod = c_mod.replace(' ','')\n",
    "    if re.search('\\w+_<\\d*>', c_mod):\n",
    "        drop.append(c)\n",
    "    data.rename(columns={c:c_mod}, inplace=True)\n",
    "data.drop(columns=drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "400b8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "8548ee37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;34mPossible new pollutants names:\u001b[0;0m\n",
      "['ID', 'Societe', 'Zone', 'Sous_zone', 'X', 'Y', 'Zsol', 'Z', 'Type', 'Long_pz', 'Sect_crep', 'Diam_int_pz', 'Nappe', 'Surnageant', 'Sousnageant', 'Caractere', 'Opacite', 'Rmq', 'pH', 'CE', 'Temp', 'ORP', 'O_diss', 'CN_libre', 'para-etmétaxylène', 'BTEX total', 'PCB totaux (7)', 'C5-C8', 'C8-C10', 'C10-C12', 'C12-C16', 'C16-C21', 'C21-C35', 'C35-C40', 'C30-C40', 'sulfites', 'sulfate', 'Date_mes', 'Niv_eau_pz', 'Niv_eau_sol']\n"
     ]
    }
   ],
   "source": [
    "df = col_ren(df, name=POL_NAMES_MODEL, mode=1, cutoff=0.7)#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "751cb70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'3,5+2,3-dimethylphénol+4-ethylphénol' : 'DMetPhn_4-EthPhn', 'chrome (VI)': 'Cr_VI',\n",
    "                   '2,4+2,5-dichlorophénol' : '2.4_5-DCPhn', 'sulfites':'Sulfite'}, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "afa501e4",
   "metadata": {},
   "source": [
    "df = collect_measure(df, params_kw, params_col='Params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "446cec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(df, id_ech_col='ID', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "505b837e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 260 ; measure: 260 ; lithology: 0 ; analysis: 260 ; equipement: 0 ; unknown: 26 ; \n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "348ecb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 111 ; measure: 260 ; lithology: 0 ; analysis: 260 ;equipement: 0 ; unknown: 13\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "dd8c217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = an\n",
    "data.drop_duplicates(list(data.columns), inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data['Type_ech'] = 'eau'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "faef42e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0178a1c",
   "metadata": {},
   "source": [
    "##### data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "40e20ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "6a96db2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "74b4373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID_ech', 'Z', 'Date_mes'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ea9d88d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ukw, conflict_df = data_merger(source_ukw, ukw, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f86fe0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 409 ; source_eqp: 0 ; source_uknw: 30 ; source_litho: 1628 ; source_an: 149 ; source_mes: 298\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Samples.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "permanent-house",
   "metadata": {},
   "source": [
    "* **Sheet : 'RESULTS_SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "coordinated-rolling",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'database_Memoris3/'\n",
    "sheet='Result_sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "green-joyce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanathan/.local/share/virtualenvs/GSDMA-DRfwm83x/lib/python3.8/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows : 1423, columns : 94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5262caef201e43b0ab1eceb4f0dfb828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=10, description='rows', max=1423, min=10, readout=False), IntSlider(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Rapport de synthèse des études de sol et des eaux souterraines. Siterem - 2017/'\n",
    "                   'Database MEMORIS3.xlsx', sheet_name='RESULTS_SOL', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "amateur-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Unnamed: 92':'EOX', 'Unnamed: 93':'Idc_phenol','Campagne':'Societe','N_forage':'ID','refus':'Refus',\n",
    "                   'Prof.\\nforage':'Long_for', 'N_ech':'ID_ech', 'Min_Ech':'Ech_top','Max_Ech':'Ech_base',\n",
    "                   'Terrain':'Nappe','Epaisseur remblais':'Ep_remb', 'Epaisseur alluvions':'Ep_alluv',\n",
    "                   'pH H2O':'pH_H2O','T° pH H2O':'Temp_pH_H2O','T° pH CaCl2':'Temp_pH_CaCl2','pH CaCl2':'pH_CaCl2', \n",
    "                   'T° pH KCl':'Temp_pH_KCl', 'pH KCl':'pH_KCl', 'T° CE':'Temp_CE', 'Argile ':'Argile', \n",
    "                   'Résidus chauffage':'Residu_perte_feu','Nature':'Polluant', 'Intensité':'Intensite',\n",
    "                   'Libres':'CN_libre','Fraction   2000 µm':'Fract_2000µ','Fraction   63 µm':'Fract_63µ', \n",
    "                   'Fraction   45 µm':'Fract_45µ','Fraction   16 µm':'Fract_16µ','Fraction   2 µm':'Fract_2µ',\n",
    "                   'Totaux':'CN_tot'\n",
    "                  }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "disturbed-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[df.columns.to_list()[x] for x in range(len(df.columns))\n",
    "                      if re.search(r\"Unnamed\",df.columns.to_list()[x])], axis=1, inplace=True) \n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df=df.query('ID==ID')\n",
    "df['ID']=df['ID'].apply(lambda x : x.replace('Monito ', 'Mon') if re.findall('Monit', str(x)) else x)\n",
    "df['ID_ech']=df['ID_ech'].apply(lambda x : x.replace('Monito ', 'Mon') if re.findall('Monit', str(x)) else x)\n",
    "df.replace('-',np.nan, inplace=True)\n",
    "df.insert(5, 'Type', 'Piezo')\n",
    "df.insert(6, 'Type_ech', 'Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "boolean-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    #r=re.search('(\\w+)/.+',str(df.loc[i, 'ID_ech']))\n",
    "    #if r : df.loc[i, 'ID']=r.group(1)\n",
    "    r=re.search('^\\d+',str(df.loc[i, 'ID']))\n",
    "    if r : df.loc[i, 'ID']='F'+str(df.loc[i, 'ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "champion-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Refus']=df['Refus'].apply(lambda x: 'x' if not pd.isnull(x) else '')\n",
    "df.replace('#',np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fancy-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    x=df.loc[i,'Nappe']\n",
    "    if not re.search('^F|^Mo', str(df.loc[i,'ID'])) : df.loc[i,'Type']='Inconnu'\n",
    "        \n",
    "    if re.search('[R|r]em', str(x)) : df.loc[i,'Nappe']='Remblais'\n",
    "    elif re.search('[A|a]ll', str(x)) : df.loc[i,'Nappe']='Alluvions'\n",
    "    elif re.search('[S|s]oc', str(x)) : df.loc[i,'Nappe']='Socle'\n",
    "    elif re.search('[A|a]rg', str(x)) : df.loc[i,'Nappe']='Argile'\n",
    "    else : df.loc[i,'Nappe']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "aa2cec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_mes'] = '2050-01-01'\n",
    "#df['Date_mes'] = df['Date_mes'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "b643100e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;34mPossible new pollutants names:\u001b[0;0m\n",
      "['Societe', 'Zone', 'Sous_zone', 'Numéro_zone', 'ID', 'Type', 'Type_ech', 'Affectation', 'X', 'Y', 'Z', 'Long_for', 'Refus', 'ID_ech', 'Ech_top', 'Ech_base', 'Soumis', 'Nappe', 'Description', 'Ep_remb', 'Ep_alluv', 'Intensite', 'Min_organo', 'Max_organo', 'Polluant', 'MS', 'pH_H2O', 'Temp_pH_H2O', 'Temp_pH_CaCl2', 'pH_CaCl2', 'Temp_pH_KCl', 'pH_KCl', 'Temp_CE', 'CE', 'MO', 'Residu_perte_feu', 'Fract_2000µ', 'Fract_63µ', 'Fract_45µ', 'Fract_16µ', 'Fract_2µ', 'Chrome_VI', 'CN_libre', 'CN_tot', 'Thiocyantes', 'Cyanures totaux EPA', 'Ethylbenzène', 'Anthracene', 'Benzoaanthracène', 'Benzo(a)pyrene', 'Indéno[123cd]pyrène', 'Acenaphtylene', 'Acenaphthene', 'Benzo_b_fluoranthene', 'Dibenzo[ah]anthracène', 'C16_C21', 'C21_C35', 'C35_C40', 'C21_C30', 'SOM C10_C40', 'Idc_phenol', 'Date_mes']\n"
     ]
    }
   ],
   "source": [
    "df = col_ren(df, name=POL_NAMES_MODEL, mode=1, cutoff=0.7)#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ca11831e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 1423 ; measure: 1423 ; lithology: 0 ; analysis: 1423 ; equipement: 0 ; unknown: 49 ; \n",
      "\n",
      "\u001b[1;32mNot used columns:\u001b[0;0m\n",
      " ['Numéro_zone', 'Affectation', 'Soumis', 'Ep_remb', 'Ep_alluv']\n"
     ]
    }
   ],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c0b8d925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "borehole: 304 ; measure: 1423 ; lithology: 0 ; analysis: 1423 ;equipement: 0 ; unknown: 17\n"
     ]
    }
   ],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb5c8a7",
   "metadata": {},
   "source": [
    "##### data merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "72c1d0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflict values present. Please resolve this manually !\n"
     ]
    }
   ],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "689e2d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all conflicts have been fixed!\n"
     ]
    }
   ],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID',\n",
    "                valid_dict={'Societe_x':list(conflict_df.index), 'Type_x':list(conflict_df.index),\n",
    "                            'Long_for_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9383b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "02fa1997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d4060b4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID','Date_mes'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "7d15c38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_mes\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)\n",
    "source_mes = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "484a7068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "source_ukw, conflict_df = data_merger(source_ukw, ukw, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5cd86a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 520 ; source_eqp: 0 ; source_uknw: 32 ; source_litho: 1628 ; source_an: 1572 ; source_mes: 1717\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Samples.csv', index=False)\n",
    "ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737593b",
   "metadata": {},
   "source": [
    "### $\\color{red}{\\textbf{Excel data final merge}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84f7589c",
   "metadata": {},
   "source": [
    "source_dict = {'bh':bh.copy(),'eqp':eqp.copy(),'ukw':ukw.copy(),'litho':litho.copy(),'an':an.copy(),'mes':mes.copy()}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34d188b5",
   "metadata": {},
   "source": [
    "# Not really needed here because all source data have XYZ coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "43831f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_coords = source_bh[['ID', 'X', 'Y', 'Z','Date_for']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "94a2d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, bh_coords, how='left', on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "679fd3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conflict values present. Please resolve this manually !\n"
     ]
    }
   ],
   "source": [
    "source_litho, conflict_df = data_merger(source_litho, bh_coords, how='left', on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "176f81f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all conflicts have been fixed!\n"
     ]
    }
   ],
   "source": [
    "dataset = source_litho\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'Date_for_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)\n",
    "source_litho = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fbb4bfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, bh_coords, how='left', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d9f21163",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ukw, conflict_df = data_merger(source_ukw, bh_coords, how='left', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "87c72bc7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_bh: 520 ; source_eqp: 0 ; source_uknw: 32 ; source_litho: 1627 ; source_an: 1583 ; source_mes: 1734\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False)\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False)\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3187304e",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029bdabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-rwanda",
   "metadata": {},
   "source": [
    "## 3-obsrevations terrain et mesures piézos phase 2.xlsx\n",
    "\n",
    "* **Sheet : 'Piézométrie'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-remains",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'observ_terrain/'\n",
    "sheet='Piezometrie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "black-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/résultats phase 2/'\n",
    "                   'obsrevations terrain et mesures piézos phase 2.xlsx', sheet_name='Piézométrie', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worth-sacrifice",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf=df[df.columns.to_list()[:3]]\n",
    "sdf=na_line_drop(sdf,0)\n",
    "sdf.rename(columns={'Niveau \\npiézométrique':'Niv_eau_sol', 'Commentaires ':'Date_ech'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdf2=df.loc[:11, df.columns.to_list()[3:-1]]\n",
    "sdf2.rename(columns={'Unnamed: 7':'Date_mes', 'Unnamed: 8':'Nappe', 'Unnamed: 9':'ID', 'NP/piézo [m]':'Niv_eau_pz',\n",
    "       'dim. piezo hors sol [m]':'Ht_pz_sol', 'NP/sol [m]':'Niv_eau_sol', 'Prof. piézo/piézo [m]':'Long_pz',\n",
    "       'Prof. piézo/sol [m]':'Long_pz_sol', 'CE [mS/cm]':'CE','t° [°C]':'Temp','O2 dissous\\n[%]':'O_diss', \n",
    "        'Observations':'Rmq'}, \n",
    "           inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sdf2['ID'])):\n",
    "    sdf2.loc[i,'ID']=re.sub(r'^P','F', sdf2.loc[i,'ID'])\n",
    "    \n",
    "    if pd.isnull(sdf2.loc[i,'CE']) and not pd.isnull(sdf2.loc[i,'CE [µS/cm]']):\n",
    "        sdf2.loc[i,'CE']=sdf2.loc[i,'CE [µS/cm]']/1000\n",
    "\n",
    "sdf2.drop(['CE [µS/cm]'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[14:, df.columns.to_list()[3:-1]]\n",
    "df.rename(columns={'Unnamed: 7':'Date_mes', 'Unnamed: 8':'Nappe', 'Unnamed: 9':'ID', 'NP/piézo [m]':'Niv_eau_pz',\n",
    "       'dim. piezo hors sol [m]':'Ht_pz_sol', 'NP/sol [m]':'Niv_eau_sol', 'Prof. piézo/piézo [m]':'Long_pz',\n",
    "       'Prof. piézo/sol [m]':'Long_pz_sol', 'CE [mS/cm]':'CE','t° [°C]':'Temp','O2 dissous\\n[%]':'O_diss', \n",
    "        'Observations':'Rmq'}, \n",
    "           inplace=True)\n",
    "df.drop([19,20], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "received-jersey",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df['ID'])):\n",
    "    df.loc[i,'ID']=re.sub(r'^P','F', df.loc[i,'ID'])\n",
    "    \n",
    "    if pd.isnull(df.loc[i,'CE']) and not pd.isnull(df.loc[i,'CE [µS/cm]']):\n",
    "        df.loc[i,'CE']=df.loc[i,'CE [µS/cm]']/1000\n",
    "        \n",
    "df.drop(['CE [µS/cm]', 'O_diss'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, conflict_df=data_merger(sdf2, df, how='outer', on='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e02292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = na_col_drop(df, 5)\n",
    "df['Type'] = 'Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391dc7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_viewer(df, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c1420",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31572ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9fabf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = bh\n",
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c46d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Samples.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Samples.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
