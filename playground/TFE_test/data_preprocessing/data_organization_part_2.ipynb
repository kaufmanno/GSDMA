{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indonesian-alloy",
   "metadata": {},
   "source": [
    "# ORGANISATION DES DONNEES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "demanding-former",
   "metadata": {},
   "source": [
    "config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from utils.config import DEFAULT_POL_LEXICON, POL_NAMES_MODEL\n",
    "from definitions import ROOT_DIR\n",
    "from utils.io import dataframe_viewer, data_merger, data_validation, data_slicer, \\\n",
    "collect_time_data, replicate_values, gen_id_from_ech, na_col_drop, na_line_drop, col_ren, \\\n",
    "dble_col_drop, find_borehole_by_position, compute_borehole_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7feb75",
   "metadata": {},
   "source": [
    "### Creation du répertoire de sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1966c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = ROOT_DIR + '/CF_data/Result_traitem/organisation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4014d",
   "metadata": {},
   "source": [
    "### Definition d'entêtes usuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a77803",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAS_NAMES_MODEL = {'Fraction   2000 µm':'Fract_2000µ', 'Fraction   63 µm':'Fract_63µ', 'Fraction   45 µm':'Fract_45µ', 'Fraction   16 µm':'Fract_16µ', \n",
    "                    'Fraction   2 µm':'Fract_2µ', 'Fraction 2 mm':'Fract_2', 'Fraction +2 mm':'Fract_2+', 'Fract_2':'Fract_2', 'Fract_2+':'Fract_2+', \n",
    "                    'Mat. organique':'MO', 'Mat. sèche':'MS', 'Argile':'Fract_arg', 'Fraction argileuse':'Fract_arg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_kw = ['O_diss','Niv_eau', 'temp', '^T$', '^CE$', 'pH$', 'ORP']\n",
    "meas_kw_col = ['O_diss','pH','CE','ORP','Niv_eau_pz','Niv_eau_sol','Temp']\n",
    "sufx = ['sup', 'prof', 'inf', '/\\dM(\\*)?']\n",
    "prefx = ['eau forage ']\n",
    "id_reg = '\\s*(?P<id>(?:^canne |Piezair )*\\w*\\d+\\w*)\\s*'\n",
    "pollutants_names = list(set(list(DEFAULT_POL_LEXICON.abbreviations.keys()) + list(POL_NAMES_MODEL.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16edcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type','Long_for','Long_pz','Sect_crep','Long_pz_sol','Ht_pz_sol',\n",
    "           'Diam_for','Diam_int_pz','Diam_ext_pz','Ht_chbre','Refus','Societe','Zone','Sous_zone','Etude','Method','Resp_chantier',\n",
    "           'Emplacement','Rmq']))\n",
    "\n",
    "mes_cols = list(set(['Date_mes','ID','ID_ech','X','Y','Z','Zsol','pH_H2O', 'Temp_pH_H2O', 'Temp_pH_CaCl2','pH_CaCl2','Temp_pH_KCl',\n",
    "            'pH_KCl','Residu_perte_feu','Fract_arg','Fract_min_2µ','Fract_min_50µ','Fract_min_2','Temp_pH_mes',\n",
    "            'pH_H20', 'Fract_min_2µ', 'Fract_min_50µ', 'Fract_min_2', 'pH_KCl', 'Temp_pH_mes', 'pH_H20', 'sulfures_tot''N_Kjdl','Temp_CE','Temp_pH','Nappe','Rmq','Fract_2000µ','Fract_63µ','Fract_45µ','Fract_16µ',\n",
    "            'Fract_2µ','Temp_ech', 'Periode'] + meas_kw_col + list(MEAS_NAMES_MODEL.values())))\n",
    "\n",
    "eqp_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type_equip','Equip_base','Equip_top',\n",
    "                     'Equip_epais','Rmq']))\n",
    "\n",
    "litho_cols = list(set(['Date_for','ID','ID_ech','X','Y','Z','Zsol','Long_for','Litho_top','Litho_base','Intv_top',\n",
    "                       'Intv_base','Litho_epais','Intv_epais','Keyword','Description','Rmq']))\n",
    "\n",
    "an_cols = list(set(['ID','X','Y','Z','Zsol','Date_ech','ID_ech','Type_ech','Ech_top','Ech_base','Ech_epais',\n",
    "                    'Intv_top','Intv_base','Description','Nappe','Organo','Intensite', 'Min_organo', 'Max_organo',\n",
    "                    'Polluant','Surnageant','Sousnageant','Caractere','Opacite','Rmq'] + pollutants_names))\n",
    "\n",
    "ukw_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type','Long_for','Method','Societe','Rmq']))\n",
    "\n",
    "cols_dict = {'borehole': bh_cols, 'measure': mes_cols, 'lithology': litho_cols, 'analysis': an_cols, \n",
    " 'equipement': eqp_cols, 'unknown': ukw_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4674736",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_crit = ['ID','X','Y','Z','Zsol','Type','Long_for','Long_pz','Diam_for','Diam_int_pz','Diam_ext_pz']\n",
    "\n",
    "mes_crit = ['Date_mes'] + meas_kw_col + list(MEAS_NAMES_MODEL.values())\n",
    "\n",
    "eqp_crit = ['Type_equip','Equip_base','Equip_top']\n",
    "\n",
    "litho_crit = ['Litho_top','Litho_base','Intv_top','Intv_base','Description']\n",
    "\n",
    "an_crit = ['ID_ech','Type_ech','Organo','Surnageant','Sousnageant'] + list(DEFAULT_POL_LEXICON.abbreviations.keys()) \n",
    "\n",
    "ukw_crit = ['ID','X','Y','Z','Zsol','Long_for','Type']\n",
    "\n",
    "crit_dict = {'borehole': bh_crit, 'measure': mes_crit, 'lithology': litho_crit, 'analysis': an_crit, \n",
    " 'equipement': eqp_crit, 'unknown': ukw_crit}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfd064",
   "metadata": {},
   "source": [
    "variables utilisées par jeu de données\n",
    "================================\n",
    "- bh \t: \tforages (simple ou piezo)\n",
    "- equip\t:\tequipements d'un forage (outils, méthodes utilisés, ...)\n",
    "- ukw\t:\tobjets physiques indéterminés\n",
    "- litho :\tdescriptions lithologiques\n",
    "- an \t: \tanalyses de contaminants sur des échantillons (sol, eau)\n",
    "- mes\t:\tmesures de propriétés sur des échantillons (sol, eau), de paramètres hydrochimiques, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45736216",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6124c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-siemens",
   "metadata": {},
   "source": [
    "## 4-profondeur de contact campagne de forages octobre 2019.xlsx\n",
    "\n",
    "* **Sheet : 'Feuil1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "patient-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Prof_contact_sol_forage/'\n",
    "sheet='Feuil1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/ouvrages/profondeur de contact campagne de forages octobre 2019.xlsx', \n",
    "                   sheet_name='Feuil1', skiprows=2)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "early-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'n°forage ':'ID','profondeur(m)':'Long_for','x':'X', 'y':'Y', 'z':'Z'}, inplace=True)\n",
    "df['Type']='Forage' # type is not defined clearly in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4467a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-weight",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = df\n",
    "source_bh=bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be073ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f389d7",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-houston",
   "metadata": {},
   "source": [
    "## 5-Forages_Pilote_Decoupe.xlsx\n",
    "\n",
    "* **Sheet : 'leve'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-lewis",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Forage_Pilote/'\n",
    "sheet='leve_Z_elect_pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-situation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/geometrie_electrodes_et_sondes/Forages_Pilote_Decoupe.xlsx', \n",
    "                   sheet_name='leve')#, skiprows=0)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Ref_puits':'ID','Niveau mesuré':'Z_mes', 'Niveau corrigé':'Z','Z_diff [m] repere_local':'Diff_Z_local',\n",
    "                   'long_fin [m]':'Long_for','Pos_Inox_#1 [m]':'Pos_Inox_#1', 'Unnamed: 11':'Rmq',\n",
    "                   'Pos_Inox_#6 [m]':'Pos_Inox_#6', 'Pos_Impol_#3 [m]':'Pos_Impol_#3'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type']='Forage' # type is not defined clearly in data\n",
    "#df['ID']=df['ID'].apply(lambda x: 'F'+str(x).replace('.0',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2849ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-formation",
   "metadata": {},
   "outputs": [],
   "source": [
    "elc = df[['ID','Pos_Inox_#6', 'Pos_Impol_#3']] # 'ID' is for boreholes\n",
    "bh = df[['ID','Long_for', 'Type']]# Z_local origin = 145.5 [m] # incoherence !??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = bh\n",
    "source_elc = elc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/') \n",
    "\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "elc.to_csv(tmp_dir+sheet+'_Electrodes.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False)\n",
    "source_elc.to_csv(tmp_dir+'source_merge/source_Electrodes.csv', index=False)\n",
    "\n",
    "print(f'source_bh:{len(source_bh)} ; source_elect:{len(source_elc)} ;')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40e2de6",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51996243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-belize",
   "metadata": {},
   "source": [
    "## 6-Liste XY investigations.xlsx\n",
    "* **Sheet : 'SOL_EAU'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-trustee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Liste_XY/'\n",
    "sheet='Sol_Eau'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-developer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Etude de caracterisation. SITEREM - 2011/Documents '\n",
    "                   'supplémentaires/Liste XY investigations.xlsx', sheet_name='SOL')#, skiprows=4)\n",
    "df['Type_ech']='Sol'\n",
    "df.rename(columns={'N°':'ID_ech'}, inplace=True)\n",
    "\n",
    "df1 = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Etude de caracterisation. SITEREM - 2011/Documents '\n",
    "                   'supplémentaires/Liste XY investigations.xlsx', sheet_name='EAU PR')#, skiprows=4)\n",
    "df1['Type_ech']='Eau'\n",
    "df1['Nappe']='Socle'\n",
    "df1.rename(columns={'N°':'ID_ech'}, inplace=True)\n",
    "\n",
    "df2 = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Etude de caracterisation. SITEREM - 2011/Documents '\n",
    "                   'supplémentaires/Liste XY investigations.xlsx', sheet_name='EAU RB')#, skiprows=4)\n",
    "df2['Type_ech']='Eau'\n",
    "df2['Nappe']='remblais'\n",
    "df2.rename(columns={'N°':'ID_ech'}, inplace=True)\n",
    "\n",
    "df3 = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Doc_SITEREM/Etude de caracterisation. SITEREM - 2011/Documents '\n",
    "                   'supplémentaires/Liste XY investigations.xlsx', sheet_name='EAU ALL')#, skiprows=4)\n",
    "df3['Type_ech']='Eau'\n",
    "df3['Nappe']='Alluvions'\n",
    "df3.rename(columns={'N°':'ID_ech'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-abortion",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df, 'outer', 'ID_ech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83e2c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(mdf, df2, 'outer', 'ID_ech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a867a2aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, conflict_df=data_merger(mdf, df3, 'outer', 'ID_ech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d54c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Nappe_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1a6415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(df, suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f3a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952e957",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = df\n",
    "source_an = an\n",
    "#source_an.insert(0,'ID', source_an.pop('ID_ech'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b1383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6af835",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6e4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-library",
   "metadata": {},
   "source": [
    "## 7-Résultats phase 1_MEMORIS.xls\n",
    "* **Sheet : 'Résult SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-pursuit",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Phase_1_Memoris/'\n",
    "sheet='Result_sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/résultats phase 1/'\n",
    "                   'Résultats phase 1_MEMORIS.xls', sheet_name='Résult SOL', skiprows=4)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-constitutional",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:35]\n",
    "an=df.loc[36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleasant-prayer",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[0] # put data on first line\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df.transpose()\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=col_ren(ech_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(list(range(5)), axis=0, inplace=True)\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=na_col_drop(ech_df,1)\n",
    "ech_df=na_line_drop(ech_df,3)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech', 'Description','Organo', 'Long_for', 'Refus','Ech_top', 'Ech_base', 'MS','Fract_2','Fract_2+']\n",
    "ech_df=col_ren(ech_df, name=name, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accomplished-exception",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ech_df['Description'])):\n",
    "    x = ech_df.loc[i,'Description']\n",
    "    if x=='R': ech_df.loc[i,'Description']='Remblais'\n",
    "    elif x=='L': ech_df.loc[i,'Description']='Limons'\n",
    "    elif x=='A': ech_df.loc[i,'Description']='Argiles'\n",
    "    elif x=='S': ech_df.loc[i,'Description']='Sables'\n",
    "\n",
    "ech_df['Refus']=ech_df['Refus'].apply(lambda x: 'x' if not re.search('x|X', str(x)) else '')\n",
    "ech_df.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "activated-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.replace(r'<|>','', inplace=True, regex=True)\n",
    "an.replace(r'-',np.nan, inplace=True, regex=True)\n",
    "an.rename(columns={'col_0':'ID_ech', 'col_34':'phénanthrène', 'col_63':'EOX'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-travel",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(5)), axis=0, inplace=True)\n",
    "an.reset_index(drop=True, inplace=True)\n",
    "an=na_col_drop(an,1)\n",
    "an.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-degree",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "an = col_ren(an, name=POL_NAMES_MODEL, mode=1)#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f741c356",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf, conflict_df = data_merger(ech_df, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e682eb8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(mdf, suffixes=sufx, prefixes=prefx, capture_regex=id_reg)\n",
    "df['ID'] = df['ID'].apply(lambda x: x+'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada24c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a45fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34c1fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ;' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ranking-underwear",
   "metadata": {},
   "source": [
    "set(ech_df['ID_ech']).symmetric_difference(set(an['ID_ech'])) #lacking ID between the 2 sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = bh\n",
    "source_an = an\n",
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8987cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-expense",
   "metadata": {},
   "source": [
    "* **Sheet : 'Résult EAU'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Phase_1_Memoris/'\n",
    "sheet='Result_eau'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "damaged-delivery",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/résultats phase 1/'\n",
    "                   'Résultats phase 1_MEMORIS.xls', sheet_name='Résult EAU', skiprows=4)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:32]\n",
    "an=df.loc[33:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interstate-animal",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[0] # put data on first line\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df.transpose()\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=col_ren(ech_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-furniture",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df['CE']=ech_df['CE'].apply(lambda x: pd.to_numeric(x)/1000 \n",
    "                                  if re.search('^\\d+', str(x)) and not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(list(range(5)), axis=0, inplace=True)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hired-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=dble_col_drop(ech_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=na_col_drop(ech_df,1)\n",
    "ech_df=na_line_drop(ech_df,3)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech','Date_ech','Num_maille','Affectation','X','Y','Zsol','Long_for','Prof_crep','Long_pz',\n",
    "      'Niv_eau_sol','pH','CE','Temp']\n",
    "ech_df=col_ren(ech_df, name=name, mode=1)\n",
    "ech_df.insert(1,'Type_ech','Eau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df['Prof_crep'].replace('\\[|\\]','', regex=True, inplace=True)\n",
    "for i in range(len(ech_df)):\n",
    "    c=ech_df.loc[i,'Prof_crep']\n",
    "    ech_df.loc[i,'Equip_top']=c.split('-')[0]\n",
    "    ech_df.loc[i,'Equip_base']=c.split('-')[1]\n",
    "\n",
    "ech_df['Type_equip'] = 'Crepine'\n",
    "ech_df.drop(columns=['Prof_crep'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ech_df['ID_ech'].replace('Canne ', 'Can', inplace=True, regex=True)\n",
    "ech_df['ID_ech'].replace('\\n', ' ', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mental-bacon",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.replace(r'<|>','', inplace=True, regex=True)\n",
    "an.replace(r'-',np.nan, inplace=True, regex=True)\n",
    "an.rename(columns={an.columns[0]:'ID_ech', 'col_43':'phénanthrène'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(5)), axis=0, inplace=True)\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-bennett",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(columns=an.columns[[-6,-5]], axis=1, inplace=True)\n",
    "an=na_col_drop(an,1)\n",
    "an.insert(1,'Type_ech','Eau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ce75ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf, conflict_df = data_merger(ech_df, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d82e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(mdf, suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd297bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].apply(lambda x: re.sub('^P', 'F', str(x)) if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60214c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = 'Piezo'\n",
    "df['Date_mes'] = df['Date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6236af09",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052b2282",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a230f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba05c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_eqp = eqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5564e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech', 'Type_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59484864",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c371d437",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_for_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec0ddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dc575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153c3201",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c54e59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "western-concord",
   "metadata": {},
   "source": [
    "## 8-Résultats phase 2_MEMORIS.xls\n",
    "* **Sheet : 'Résult SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Phase_2_Memoris/'\n",
    "sheet='Result_SOL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-black",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/résultats phase 2/'\n",
    "                   'Résultats phase 2_MEMORIS.xls', sheet_name='Résult SOL', skiprows=4)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:35]\n",
    "an=df.loc[36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metropolitan-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[1] # put data on first line\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df.transpose()\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=col_ren(ech_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(list(range(5)), axis=0, inplace=True)\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=na_col_drop(ech_df,1)\n",
    "ech_df=na_line_drop(ech_df,3)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "derived-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech', 'Date_ech', 'Description','Organo', 'Long_for', 'Refus','Ech_top', 'Ech_base', 'MS','Fract_2','Fract_2+']\n",
    "ech_df=col_ren(ech_df, name=name, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thirty-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ech_df['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defensive-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ech_df['Description'])):\n",
    "    x = ech_df.loc[i,'Description']\n",
    "    if x=='R': ech_df.loc[i,'Description']='Remblais'\n",
    "    elif x=='L': ech_df.loc[i,'Description']='Limons'\n",
    "    elif x=='LA': ech_df.loc[i,'Description']='Limons et argiles'\n",
    "    elif x=='LS': ech_df.loc[i,'Description']='Limons et sables'\n",
    "\n",
    "ech_df['Refus']=ech_df['Refus'].apply(lambda x: 'x' if not re.search('#', str(x)) else '')\n",
    "ech_df.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecological-arlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.replace(r'<|>','', inplace=True, regex=True)\n",
    "an.replace(r'-',np.nan, inplace=True, regex=True)\n",
    "an.rename(columns={'col_0':'ID_ech', 'col_34':'phénanthrène'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(5)), axis=0, inplace=True)\n",
    "an=na_col_drop(an,1)\n",
    "an.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "robust-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43e5b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf, conflict_df = data_merger(ech_df, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b938ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(mdf, suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615720b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = 'Forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754dd7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00a2641",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8925ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b66808",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = bh\n",
    "source_an = an\n",
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672b1853",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-testament",
   "metadata": {},
   "source": [
    "* **Sheet : 'Résult EAU'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-vienna",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Phase_2_Memoris/'\n",
    "sheet='Result_eau'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accredited-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/résultats phase 2/'\n",
    "                   'Résultats phase 2_MEMORIS.xls', sheet_name='Résult EAU', skiprows=4)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:32]\n",
    "an=df.loc[33:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-objective",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[1] # put data on first line\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df.transpose()\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=col_ren(ech_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indie-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df['CE']=ech_df['CE'].apply(lambda x: pd.to_numeric(x)/1000 \n",
    "                                  if re.search('^\\d+', str(x)) and not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chinese-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(list(range(5)), axis=0, inplace=True)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=dble_col_drop(ech_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-section",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ech_df=na_col_drop(ech_df,1)\n",
    "ech_df=na_line_drop(ech_df,3)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-burns",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech', 'Date_ech','Affectation','X', 'Y','Zsol', 'Long_for','Prof_crep','Long_pz_sol',\n",
    "      'Niv_eau_sol','pH', 'CE', 'Temp']\n",
    "ech_df=col_ren(ech_df, name=name, mode=1)\n",
    "ech_df.insert(1,'Type_ech','Eau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-premium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ech_df['ID_ech'].replace('\\n', ' ', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-edgar",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df['Prof_crep'].replace('\\[|\\]','', regex=True, inplace=True)\n",
    "for i in range(len(ech_df)):\n",
    "    c=ech_df.loc[i,'Prof_crep']\n",
    "    ech_df.loc[i,'Equip_top']=c.split('-')[0]\n",
    "    ech_df.loc[i,'Equip_base']=c.split('-')[1]\n",
    "    \n",
    "ech_df.drop(columns=['Prof_crep'], inplace=True)\n",
    "ech_df['Type_equip'] = 'Crepine'\n",
    "ech_df['Type']='Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-imaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.replace(r'<|>','', inplace=True, regex=True)\n",
    "an.replace(r'-',np.nan, inplace=True, regex=True)\n",
    "an.rename(columns={'col_0':'ID_ech', 'col_43':'phénanthrène'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(5)), axis=0, inplace=True)\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-humanity",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(columns=an.columns[[-6,-5]], axis=1, inplace=True)\n",
    "an=na_col_drop(an,1)\n",
    "an.insert(1,'Type_ech','Eau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-abuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33289ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf, conflict_df = data_merger(ech_df, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435d055",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['Type'] = 'Piezo'\n",
    "mdf['Date_mes'] = mdf['Date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211c02d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(mdf, suffixes=sufx, prefixes=prefx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4848675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[6, 'ID'] = 'P23'\n",
    "df['ID'] = df['ID'].apply(lambda x: re.sub('^P', 'F', str(x)) if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f766fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb922be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b251773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a47a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_eqp = eqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e54adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech', 'Type_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50029a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cc7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Type_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7c9a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbcb04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada38ee1",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19db8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-garage",
   "metadata": {},
   "source": [
    "## 9-Ensemble des résultats Memoris version Seafile.xls\n",
    "* **Sheet : 'Résult SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Memoris_seafile/'\n",
    "sheet='Result_SOL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/'\n",
    "                   'Ensemble des résultats Memoris version Seafile.xls', sheet_name='Résult SOL', skiprows=4)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:37]\n",
    "an=df.loc[38:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[0] # put data on first line\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-wallace",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df.transpose()\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=col_ren(ech_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(list(range(5)), axis=0, inplace=True)\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=na_col_drop(ech_df,1)\n",
    "ech_df=na_line_drop(ech_df,3)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optimum-snowboard",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(columns=ech_df.columns[[-3,-4]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broke-emerald",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech', 'Date_ech', 'Description','Organo', 'Long_for', 'Refus','Ech_top', 'Ech_base', 'MS','Fract_2','Fract_2+']\n",
    "ech_df=col_ren(ech_df, name=name, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ech_df['Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eligible-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ech_df.index:\n",
    "    x = ech_df.loc[i,'Description']\n",
    "    if x=='R' or x=='R ': ech_df.loc[i,'Description']='Remblais'\n",
    "    elif x=='L': ech_df.loc[i,'Description']='Limons'\n",
    "    elif x=='LA': ech_df.loc[i,'Description']='Limons et argiles'\n",
    "    elif x=='LS': ech_df.loc[i,'Description']='Limons et sables'\n",
    "\n",
    "ech_df['Refus']=ech_df['Refus'].apply(lambda x: 'x' if not re.search('#', str(x)) else '')\n",
    "ech_df.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unauthorized-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-archives",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.replace(r'<|>','', inplace=True, regex=True)\n",
    "an.replace(r'-',np.nan, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bright-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=dble_col_drop(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424a5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(5)), axis=0, inplace=True)\n",
    "an.reset_index(drop=True, inplace=True)\n",
    "an=na_col_drop(an,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "short-jonathan",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.rename(columns={'col_0':'ID_ech', 'col_34':'phénanthrène'}, inplace=True)\n",
    "an.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incredible-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079819ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf, conflict_df = data_merger(ech_df, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe6de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['Type'] = 'Forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947740b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(mdf, suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a6b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb96eb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75763482",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b67c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = bh\n",
    "source_an = an\n",
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92066059",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-providence",
   "metadata": {},
   "source": [
    "* **Sheet : 'Résult EAU'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Memoris_seafile/'\n",
    "sheet='Result_eau'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/'\n",
    "                   'Ensemble des résultats Memoris version Seafile.xls', sheet_name='Résult EAU', skiprows=4)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "average-humor",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:32]\n",
    "an=df.loc[33:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[0] # put data on first line\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hourly-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df.transpose()\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=col_ren(ech_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-failing",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df['CE']=ech_df['CE'].apply(lambda x: pd.to_numeric(x)/1000 \n",
    "                                  if re.search('^\\d+', str(x)) and not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(list(range(5)), axis=0, inplace=True)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=dble_col_drop(ech_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-underwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=na_col_drop(ech_df,1)\n",
    "ech_df=na_line_drop(ech_df,3)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-shade",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(columns=ech_df.columns[[2]], axis=2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech', 'Date_ech','Affectation','X', 'Y','Zsol', 'Long_for','Prof_crep','Long_pz_sol', \n",
    "      'Niv_eau_sol','pH', 'CE', 'Temp']\n",
    "ech_df=col_ren(ech_df, name=name, mode=1)\n",
    "ech_df.insert(1,'Type_ech','Eau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-action",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df['Prof_crep'].replace('\\[|\\]','', regex=True, inplace=True)\n",
    "for i in range(len(ech_df)):\n",
    "    c=ech_df.loc[i,'Prof_crep']\n",
    "    ech_df.loc[i,'Equip_top']=c.split('-')[0]\n",
    "    ech_df.loc[i,'Equip_base']=c.split('-')[1]\n",
    "    \n",
    "ech_df.drop(columns=['Prof_crep'], inplace=True)\n",
    "ech_df['Type_equip'] = 'Crepine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df['ID_ech'].replace('\\n', ' ', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collective-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-little",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.replace(r'<|>','', inplace=True, regex=True)\n",
    "an.replace(r'-',np.nan, inplace=True, regex=True)\n",
    "an.rename(columns={an.columns[0]:'ID_ech','Température pour mes. pH':'Temp_pH', 'col_43':'phénanthrène'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-progress",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(5)), axis=0, inplace=True)\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-principal",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=dble_col_drop(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfied-italian",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(columns=an.columns[[-6,-5]], axis=1, inplace=True)\n",
    "an=na_col_drop(an,1)\n",
    "an.insert(1,'Type_ech','Eau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "an['ID_ech'].replace('\\n', ' ', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c6991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf, conflict_df = data_merger(ech_df, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e65b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf['Type'] = 'Piezo'\n",
    "mdf['Date_mes'] = mdf['Date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b3211",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(mdf, suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859aacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].apply(lambda x: re.sub('^P', 'F', str(x)) if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1f610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7063a182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1978133",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c36e941",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_eqp = eqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824bbadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecd376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_for_x':list(conflict_df.index), 'Type_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a4079",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech', 'Type_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d760e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ebc9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e407dc5",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56f5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indoor-spotlight",
   "metadata": {},
   "source": [
    "## 10-Résultats SOL container phyto t=0_décret sol.xls\n",
    "* **Sheet : 'Résult SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invalid-pressure",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Container_phyto/'\n",
    "sheet='Result_SOL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/'\n",
    "                   'Résultats SOL container phyto t=0_décret sol.xls', sheet_name='Résult SOL', skiprows=4)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:21]\n",
    "an=df.loc[22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[0] # put data on first line\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-response",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df.transpose()\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=col_ren(ech_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-sarah",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=dble_col_drop(ech_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(list(range(5)), axis=0, inplace=True)\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=na_col_drop(ech_df,2)\n",
    "ech_df=na_line_drop(ech_df,3)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(columns=ech_df.columns[[-3]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech', 'Ech_top', 'Ech_base','MS','Date_ech','Fract_2','Fract_2+']\n",
    "ech_df=col_ren(ech_df, name=name, mode=1)\n",
    "ech_df=ech_df.query('ID_ech==ID_ech')\n",
    "ech_df.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "direct-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-continuity",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.replace(r'<|>','', inplace=True, regex=True)\n",
    "an.replace(r'-',np.nan, inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cubic-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=dble_col_drop(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-broad",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(5)), axis=0, inplace=True)\n",
    "an.reset_index(drop=True, inplace=True)\n",
    "an=na_col_drop(an,1)\n",
    "an.rename(columns={an.columns[0]:'ID_ech',  'col_35':'phénanthrène'}, inplace=True)\n",
    "an.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-thickness",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69379e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, conflict_df = data_merger(ech_df, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7c1516",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b26aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID_ech'].apply(lambda x: 'bh_' + x if not pd.isnull(x) else x)\n",
    "df['Date_mes'] = df['Date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d3785",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398b9ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b92e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an = an\n",
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-diversity",
   "metadata": {},
   "source": [
    "* **Sheet : 'Paramètres agro.'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shaped-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'Container_phyto/'\n",
    "sheet='Param_agro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Contamination/Résultats et mesures Siterem/'\n",
    "                   'Résultats SOL container phyto t=0_décret sol.xls', sheet_name='Paramètres agro.', skiprows=4)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.transpose()\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df=col_ren(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(range(1)), axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=dble_col_drop(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-breach",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=na_col_drop(df,1)\n",
    "df=na_line_drop(df,3)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modified-decline",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=df.columns[[5,6]], axis=2, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech','Ech_top','Ech_base','MS','Date_ech','MO','Residu_perte_feu','COT','Fract_arg','Fract_min_2µ', \n",
    "      'Fract_min_50µ', 'Fract_min_2', 'Fract_2', 'Fract_2+', 'pH_KCl','Temp_pH_mes', 'pH_H20', 'Sulfure_tot', \n",
    "      'Chlorure', 'N_Kjdl']\n",
    "df=col_ren(df, name=name, mode=1)\n",
    "df.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b93edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mdf['Type'] = 'Forage'\n",
    "df['Date_mes'] = df['Date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def08238",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d131e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID_ech'].apply(lambda x: 'bh_' + x if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d73dcd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e18239",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: bh = bh.query('ID==ID and X==X')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed597aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID_ech', 'Date_mes'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df3cfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_mes\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Fract_2_x':list(conflict_df.index), 'Fract_2+_x':list(conflict_df.index),\n",
    "                           'MS_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)\n",
    "source_an = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592d564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f99dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-providence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
