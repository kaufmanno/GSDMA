{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indonesian-alloy",
   "metadata": {},
   "source": [
    "# ORGANISATION DES DONNEES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "demanding-former",
   "metadata": {},
   "source": [
    "config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dtm\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from utils.config import DEFAULT_POL_LEXICON, POL_NAMES_MODEL\n",
    "from definitions import ROOT_DIR\n",
    "from utils.io import dataframe_viewer, data_merger, data_validation, data_slicer, \\\n",
    "collect_time_data, replicate_values, gen_id_from_ech, na_col_drop, na_line_drop, col_ren, \\\n",
    "dble_col_drop, find_borehole_by_position, compute_borehole_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7feb75",
   "metadata": {},
   "source": [
    "### Creation du répertoire de sauvegarde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1966c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = ROOT_DIR + '/CF_data/Result_traitem/organisation/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a4014d",
   "metadata": {},
   "source": [
    "### Definition d'entêtes usuelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a77803",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAS_NAMES_MODEL = {'Fraction   2000 µm':'Fract_2000µ', 'Fraction   63 µm':'Fract_63µ', \n",
    "                    'Fraction   45 µm':'Fract_45µ','Fraction   16 µm':'Fract_16µ','Fraction   2 µm':'Fract_2µ', \n",
    "                    'Fraction 2 mm':'Fract_2','Fraction +2 mm':'Fract_2+','Fract_2':'Fract_2', \n",
    "                    'Mat. organique':'MO','Mat. sèche':'MS','Argile':'Fract_arg','Fraction argileuse':'Fract_arg'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4e08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_kw = ['O_diss','Niv_eau', 'temp', '^T$', '^CE$', 'pH$', 'ORP']\n",
    "meas_kw_col = ['O_diss','pH','CE','ORP','Niv_eau_pz','Niv_eau_sol','Temp']\n",
    "sufx = ['sup', 'prof', 'inf', '/\\dM(\\*)?']\n",
    "prefx = ['eau forage ']\n",
    "id_reg = '\\s*(?P<id>(?:^canne |Piezair )*\\w*\\d+\\w*)\\s*'\n",
    "pollutants_names = list(set(list(DEFAULT_POL_LEXICON.abbreviations.keys()) + list(POL_NAMES_MODEL.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16edcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type','Long_for','Long_pz','Sect_crep','Long_pz_sol','Ht_pz_sol',\n",
    "           'Diam_for','Diam_int_pz','Diam_ext_pz','Ht_chbre','Refus','Societe','Zone','Sous_zone','Etude','Method','Resp_chantier',\n",
    "           'Emplacement','Rmq']))\n",
    "\n",
    "mes_cols = list(set(['Date_mes','ID','ID_ech','X','Y','Z','Zsol','pH_H2O','Temp_pH_H2O','Temp_pH_CaCl2','pH_CaCl2',\n",
    "            'Temp_pH_KCl','pH_KCl','Residu_perte_feu','Fract_arg','Fract_min_2µ','Fract_min_50µ','Fract_min_2',\n",
    "            'Temp_pH_mes','pH_H20','Fract_min_2µ', 'Fract_min_50µ', 'Fract_min_2', 'pH_KCl', 'Temp_pH_mes', \n",
    "            'pH_H20','sulfures_tot''N_Kjdl','Temp_CE','Temp_pH','Nappe','Rmq','Fract_2000µ','Fract_63µ','Fract_45µ',\n",
    "            'Fract_16µ','Fract_2µ','Temp_ech', 'Periode'] + meas_kw_col + list(MEAS_NAMES_MODEL.values())))\n",
    "\n",
    "eqp_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type_equip','Equip_base','Equip_top',\n",
    "                     'Equip_epais','Rmq']))\n",
    "\n",
    "litho_cols = list(set(['Date_for','ID','ID_ech','X','Y','Z','Zsol','Long_for','Litho_top','Litho_base','Intv_top',\n",
    "                       'Intv_base','Litho_epais','Intv_epais','Description','Rmq']))\n",
    "\n",
    "an_cols = list(set(['ID','X','Y','Z','Zsol','Date_ech','ID_ech','Type_ech','Ech_top','Ech_base','Ech_epais',\n",
    "                    'Intv_top','Intv_base','Description','Nappe','Organo','Intensite', 'Min_organo', 'Max_organo',\n",
    "                    'Polluant','Surnageant','Sousnageant','Caractere','Opacite','Rmq'] + pollutants_names))\n",
    "\n",
    "ukw_cols = list(set(['Date_for','ID','X','Y','Z','Zsol','Type','Long_for','Method','Societe','Rmq']))\n",
    "\n",
    "cols_dict = {'borehole': bh_cols, 'measure': mes_cols, 'lithology': litho_cols, 'analysis': an_cols, \n",
    " 'equipement': eqp_cols, 'unknown': ukw_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4674736",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh_crit = ['ID','X','Y','Z','Zsol','Type','Long_for','Long_pz','Diam_for','Diam_int_pz','Diam_ext_pz']\n",
    "\n",
    "mes_crit = ['Date_mes'] + meas_kw_col + list(MEAS_NAMES_MODEL.values())\n",
    "\n",
    "eqp_crit = ['Type_equip','Equip_base','Equip_top']\n",
    "\n",
    "litho_crit = ['Litho_top','Litho_base','Intv_top','Intv_base','Description']\n",
    "\n",
    "an_crit = ['ID_ech','Type_ech','Organo','Surnageant','Sousnageant'] + list(DEFAULT_POL_LEXICON.abbreviations.keys()) \n",
    "\n",
    "ukw_crit = ['ID','X','Y','Z','Zsol','Long_for','Type']\n",
    "\n",
    "crit_dict = {'borehole': bh_crit, 'measure': mes_crit, 'lithology': litho_crit, 'analysis': an_crit, \n",
    " 'equipement': eqp_crit, 'unknown': ukw_crit}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adfd064",
   "metadata": {},
   "source": [
    "variables utilisées par jeu de données\n",
    "================================\n",
    "- bh \t: \tforages (simple ou piezo)\n",
    "- equip\t:\tequipements d'un forage (outils, méthodes utilisés, ...)\n",
    "- ukw\t:\tobjets physiques indéterminés\n",
    "- litho :\tdescriptions lithologiques\n",
    "- an \t: \tanalyses de contaminants sur des échantillons (sol, eau)\n",
    "- mes\t:\tmesures de propriétés sur des échantillons (sol, eau), de paramètres hydrochimiques, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45736216",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0905ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-uruguay",
   "metadata": {},
   "source": [
    "## 14-Logs_forages_vUmons_2018-03-20.xlsx\n",
    "* **Sheet : 'Analyse_eau_Phases1&2'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-wagon",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'vUmons_logsFor/'\n",
    "sheet='Analyse_eau_Phases1&2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stretch-stone",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Logs_forages_vUmons_2018-03-20.xlsx', \n",
    "                   sheet_name='Analyse_eau_Phases1&2', skiprows=0)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(range(4)), axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-oakland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(9999,np.nan, inplace=True, regex=True) #int\n",
    "df.replace(f'[{9999}|9999].',np.nan, inplace=True, regex=True) #float, str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CE']=df['CE'].apply(lambda x: pd.to_numeric(x)/1000 \n",
    "                                  if re.search('^\\d+', str(x)) and not pd.isnull(x) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bf0639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=col_ren(df,mode=1,name=[re.sub('9999','-',x) for x in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4813550c",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_it = []\n",
    "for c in df.columns:\n",
    "    if re.search('_vn', c): drop_it.append(c)\n",
    "df.drop(columns=drop_it, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID', 'ID_ech', 'Date_ech', 'X', 'Y', 'Z', 'Long_for','Long_pz_sol', 'Niv_eau_sol', 'pH', 'CE', 'Temp', \n",
    "      'Arsenic', 'Cadmium', 'Chrome', 'Chrome VI', 'Cuivre', 'Mercure', 'Plomb', 'Nickel', 'Zinc', \n",
    "      'Cyanures (libres)', 'CN_totaux', 'cyanure (APE)', 'cyanure complex', 'thiocyanate', 'Benzène', 'Toluene', \n",
    "      'Éthylbenzène', 'Orthoxylène', 'Para_métaxylène', 'Xylenes', 'Styrène', 'Phénol', 'Naphtalène', \n",
    "      'Acénaphtylène', 'Acénaphtène', 'Fluorène', 'Phénanthrène', 'Anthracène', 'Fluoranthène', 'Pyrène', \n",
    "      'Benzo(a)anthracène', 'Chrysène', 'Benzo(b)fluoranthène', 'Benzo(k)fluoranthène', 'Benzo(a)pyrène', \n",
    "      'Dibenzo(ah)anthracène', 'Benzo(ghi)pérylène', 'Indéno(1,2,3-cd)pyrène', 'HAP Totaux (16) - EPA', \n",
    "      '1,1-Dichloroéthane', '1,2-Dichloroéthane', '1,1-dichloroéthène', 'Cis-1,2-dichloroéthène', \n",
    "      'Totaux (cis,trans) 1,2-dichloroéthènes', 'Trans 1,2-dichloroéthylène', 'Dichlorométhane', \n",
    "      '1,2-dichloropropane', 'Tétrachloroéthylène ', 'Tétrachlorométhane', '1,1,1-Trichloroéthane', \n",
    "      '1,1,2-Trichloroéthane', 'Trichloroéthylène', 'Chloroforme', 'Chlorure de vinyle', 'fraction aromat. >C6-C7',\n",
    "      'fraction aromat. >C7-C8', 'fraction aromat. >C8-C10', 'fraction aliphat. C5-C6', 'fraction aliphat. >C6-C8',\n",
    "      'fraction aliphat. >C8-C10', 'Fraction C5 - C8', 'Fraction C8 - C10', 'Fraction C10-C12', 'Fraction C12-C16',\n",
    "      'Fraction C16 - C21', 'Fraction C21 - C35', 'Hydrocarbures totaux C10-C35', 'MTBE', 'Chlorures']\n",
    "df=col_ren(df, mode=1,name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-actor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = col_ren(df,mode=1, name=POL_NAMES_MODEL)#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-archive",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['ID_ech'].replace('\\n', ' ', inplace=True, regex=True)\n",
    "df.insert(1,'Type_ech','Eau')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-craps",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.drop([20,39], axis=0,inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-chart",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[38:,'Date_ech']=df.loc[38:,'Date_ech'].apply(lambda x : dtm.datetime.fromordinal(dtm.datetime(1900, 1, 1).toordinal() + x - 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-parliament",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    if pd.isnull(df.loc[i,'ID_ech']): \n",
    "        df.loc[i,'ID_ech']=df.loc[i,'ID'].rstrip('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47005b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_ech'] = df['Date_ech'].astype('datetime64')\n",
    "df['Date_mes'] = df['Date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee2e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = 'Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc1b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].apply(lambda x: re.sub('^P', 'F', str(x)) if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b11e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e261e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bc4a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: \n",
    "    bh = bh.query('ID==ID and X==X')\n",
    "else:\n",
    "    bh = bh.query('ID==ID')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an = an\n",
    "source_bh = bh\n",
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-citizenship",
   "metadata": {},
   "source": [
    "* **Sheet : 'Analyse_sol_Phases1&2'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlling-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'vUmons_logsFor/'\n",
    "sheet='Analyse_sol_Phases1&2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-wells",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Logs_forages_vUmons_2018-03-20.xlsx', \n",
    "                   sheet_name='Analyse_sol_Phases1&2', skiprows=0)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech','Date_ech','ID','X','Y','Z','Nature_ech','Organo','Long_for','Refus','Ech_top','Ech_base',\n",
    "      'MS','Broyage < 150 µm','Broyage ','Fract_2','Fract_2+','Arsenic', 'Cadmium', 'Chrome', 'Chrome VI','Cuivre',\n",
    "      'Mercure', 'Plomb', 'Nickel', 'Zinc', 'Cyanure (libre)', 'Cyanure (totaux)', 'cyanure (APE)', \n",
    "      'cyanure complex', 'thiocyanate', 'Benzène', 'Toluène', 'Éthylbenzène', 'Orthoxylène', 'Para- et métaxylène',\n",
    "      'Xylènes', 'Styrène', 'Phénol', 'Naphtalène', 'Acénaphtylène', 'Acénaphtène', 'Fluorène', 'Phénanthrène', \n",
    "      'Anthracène', 'Fluoranthène', 'Pyrène', 'Benzo(a)anthracène', 'Chrysène', 'Benzo(b)fluoranthène', \n",
    "      'Benzo(k)fluoranthène', 'Benzo(a)pyrène', 'Dibenzo(ah)anthracène', 'Benzo(ghi)pérylène', \n",
    "      'Indéno(1,2,3-cd)pyrène', 'HAP Totaux (16) - EPA', '1,1-Dichloroéthane', '1,2-Dichloroéthane', \n",
    "      '1,1-dichloroéthène', 'Cis-1,2-dichloroéthène', 'Trans 1,2-dichloroéthylène', 'Dichlorométhane', \n",
    "      'Totaux (cis,trans) 1,2-dichloroéthènes', '1,2-dichloropropane', 'Tétrachloroéthylène', \n",
    "      'Tétrachlorométhane', '1,1,1-Trichloroéthane', '1,1,2-Trichloroéthane', 'Trichloroéthylène', 'Chloroforme', \n",
    "      'Chlorure de vinyle', 'fraction aromat. >C6-C7', 'fraction aromat. >C7-C8', 'fraction aromat. >C8-C10', \n",
    "      'fraction aliphat. C5-C6', 'fraction aliphat. >C6-C8', 'fraction aliphat. >C8-C10', 'Fraction C5 - C8', \n",
    "      'Fraction C8 - C10', 'Fraction C10-C12', 'Fraction C12-C16', 'Fraction C16 - C21', 'Fraction C21 - C35', \n",
    "      'Hydrocarbures totaux C10-C35']\n",
    "df=col_ren(df, mode=1, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-operator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(range(4)), axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-substitute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(9999,np.nan, inplace=True, regex=True) #int\n",
    "df.replace(f'[{9999}|9999].',np.nan, inplace=True, regex=True) #float, str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df.index:\n",
    "    x = df.loc[i,'Nature_ech']\n",
    "    if x in ['R','R ']: df.loc[i,'Nature_ech']='Remblais'\n",
    "    elif x in ['L']: df.loc[i,'Nature_ech']='Limons'\n",
    "    elif x in ['LA']: df.loc[i,'Nature_ech']='Limons et argiles'\n",
    "    elif x in ['LS']: df.loc[i,'Nature_ech']='Limons et sables'\n",
    "\n",
    "df['Refus']=df['Refus'].apply(lambda x: 'x' if not pd.isnull(x) else '')\n",
    "df.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improving-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(14, axis=0, inplace=True)\n",
    "df.drop(['Broyage < 150 µm', 'Broyage '], axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.insert(1,'Description', df.pop('Nature_ech'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[8, 'ID_ech']='F4/2M'\n",
    "df.loc[31, 'ID_ech']='F19/1'\n",
    "df.loc[32, 'ID_ech']='F19/2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = col_ren(df, mode=1, name=POL_NAMES_MODEL) #,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81869772",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_ech'] = df['Date_ech'].astype('datetime64')\n",
    "df['Date_mes'] = df['Date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab393c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = 'Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5987431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ID'] = df['ID'].apply(lambda x: re.sub('^P', 'F', str(x)) if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80605f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8474cf92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3477c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: \n",
    "    bh = bh.query('ID==ID and X==X')\n",
    "else:\n",
    "    bh = bh.query('ID==ID')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10cd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ffbb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_for_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60263ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, an, how='outer', on=['ID_ech', 'Date_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_mes, conflict_df = data_merger(source_mes, mes, how='outer', on=['ID_ech', 'Date_mes'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6d7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-italic",
   "metadata": {},
   "source": [
    "* **Sheet : 'Synthèse'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'vUmons_logsFor/'\n",
    "sheet='Synthese'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-cycling",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Logs_forages_vUmons_2018-03-20.xlsx', \n",
    "                   sheet_name='Synthèse', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-delta",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:29]\n",
    "df.replace('\\*','', inplace=True, regex=True)\n",
    "df['Refus']=df['Refus'].apply(lambda x: 'x' if not pd.isnull(x) else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mineral-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID','X','Y','Z', 'Refus','Long_for', 'RB', 'ALL', 'S_A', 'S_S', \n",
    "      'Rb_base','All_top', 'Soc_alt_top','Soc_sn_top']\n",
    "df=col_ren(df, mode=1, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-breath",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols=['ID','X','Y','Z', 'Refus','Long_for']\n",
    "\n",
    "for i in range(len(df)):\n",
    "    if not pd.isnull(df.loc[i, 'RB']): \n",
    "        df.loc[i, 'Nappe']='Remblais'\n",
    "        df.loc[i, 'Litho_top']=0\n",
    "        if not pd.isnull(df.loc[i, 'Rb_base']):\n",
    "            df.loc[i, 'Litho_base']=df.loc[i, 'Rb_base']\n",
    "        else:\n",
    "            df.loc[i, 'Litho_base']=df.loc[i, 'Long_for']\n",
    "    \n",
    "    if not pd.isnull(df.loc[i, 'ALL']):\n",
    "        df.loc[i+.2,cols]=df.loc[i,cols]\n",
    "        df.loc[i+.2, 'Nappe']='Alluvions'\n",
    "        df.loc[i+.2, 'Litho_top']=df.loc[i, 'All_top']\n",
    "        if not pd.isnull(df.loc[i, 'S_A']):\n",
    "            df.loc[i+.2, 'Litho_base']=df.loc[i, 'Soc_alt_top']\n",
    "        else:\n",
    "            df.loc[i+.2, 'Litho_base']=df.loc[i, 'Long_for']\n",
    "    \n",
    "    if not pd.isnull(df.loc[i, 'S_A']):\n",
    "        df.loc[i+.5,cols]=df.loc[i,cols]\n",
    "        df.loc[i+.5, 'Nappe']='Socle altéré'\n",
    "        df.loc[i+.5, 'Litho_top']=df.loc[i, 'Soc_alt_top']\n",
    "        if not pd.isnull(df.loc[i, 'S_S']):\n",
    "            df.loc[i+.5, 'Litho_base']=df.loc[i, 'Soc_sn_top']\n",
    "        else:\n",
    "            df.loc[i+.5, 'Litho_base']=df.loc[i, 'Long_for']\n",
    "            \n",
    "    if not pd.isnull(df.loc[i, 'S_S']):\n",
    "        df.loc[i+.7,cols]=df.loc[i,cols]\n",
    "        df.loc[i+.7, 'Nappe']='Socle sain'\n",
    "        df.loc[i+.7, 'Litho_top']=df.loc[i, 'Soc_sn_top']\n",
    "        df.loc[i+.7, 'Litho_base']=df.loc[i, 'Long_for']\n",
    "\n",
    "df.drop(columns=['RB', 'ALL', 'S_A', 'S_S', 'Rb_base','All_top', 'Soc_alt_top','Soc_sn_top'], inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = df['Nappe']\n",
    "df['Type'] = 'Forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64dd45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e96361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8980911",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: \n",
    "    bh = bh.query('ID==ID and X==X')\n",
    "else:\n",
    "    bh = bh.query('ID==ID')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b806a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc25d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Type_x':list(conflict_df.index), 'Long_for_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)\n",
    "source_bh = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75617512",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho = litho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85bde66",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-career",
   "metadata": {},
   "source": [
    "* **Sheet : 'Sond2017v2'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electric-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'vUmons_logsFor/'\n",
    "sheet='Sond2017v2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-basis",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Logs_forages_vUmons_2018-03-20.xlsx', \n",
    "                   sheet_name='Sond2017v2', skiprows=0)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('\\*','', inplace=True, regex=True)\n",
    "df['Refus']=df['Refus'].apply(lambda x: 'x' if x==1 else '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "random-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['R_ID','ID','X','Y','Z','Refus','Date_for','Long_for','Z_fond','RB','ALL', 'S_A', 'S_S', \n",
    "      'Rb_base','cote_rb','All_top', 'Soc_alt_top','Soc_sn_top']\n",
    "df=col_ren(df, mode=1, name=name)\n",
    "df=df[['ID','X','Y','Z','Refus','Date_for','Long_for','Z_fond','RB','ALL', 'S_A', 'S_S', \n",
    "      'Rb_base','All_top', 'Soc_alt_top','Soc_sn_top']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-practitioner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols=['ID','Date_for','X','Y','Z','Z_fond','Refus','Long_for']\n",
    "\n",
    "for i in range(len(df)):    \n",
    "    if df.loc[i, 'RB']==1: \n",
    "        df.loc[i, 'Nappe']='Remblais'\n",
    "        df.loc[i, 'Litho_top']=0\n",
    "        \n",
    "        if not pd.isnull(df.loc[i, 'Rb_base']): df.loc[i, 'Litho_base']=df.loc[i, 'Rb_base']\n",
    "        else: df.loc[i, 'Litho_base']=df.loc[i, 'Long_for']\n",
    "    \n",
    "    val_def=df.loc[i, 'Litho_base'] # temporary value of litho_base if nan\n",
    "    \n",
    "    if df.loc[i, 'ALL']==1:\n",
    "        df.loc[i+.2,cols]=df.loc[i,cols]\n",
    "        df.loc[i+.2, 'Nappe']='Alluvions'\n",
    "        \n",
    "        if not pd.isnull(df.loc[i, 'All_top']): df.loc[i+.2, 'Litho_top']=df.loc[i, 'All_top']\n",
    "        else: df.loc[i+.2, 'Litho_top']=val_def #df.loc[i, 'litho_base']\n",
    "            \n",
    "        if df.loc[i, 'S_A']==1: df.loc[i+.2, 'Litho_base']=df.loc[i, 'Soc_alt_top']\n",
    "        else: df.loc[i+.2, 'Litho_base']=df.loc[i, 'Long_for']\n",
    "    \n",
    "    if df.loc[i, 'S_A']==1:\n",
    "        df.loc[i+.5,cols]=df.loc[i,cols]\n",
    "        df.loc[i+.5, 'Nappe']='Socle altéré'\n",
    "        \n",
    "        if not pd.isnull(df.loc[i, 'Soc_alt_top']): df.loc[i+.5, 'Litho_top']=df.loc[i, 'Soc_alt_top']\n",
    "        else: df.loc[i+.5, 'Litho_top']=val_def #df.loc[i+.2, 'litho_base']\n",
    "        \n",
    "        if df.loc[i, 'S_S']==1: df.loc[i+.5, 'Litho_base']=df.loc[i, 'Soc_sn_top']\n",
    "        else: df.loc[i+.5, 'Litho_base']=df.loc[i, 'Long_for']\n",
    "            \n",
    "    if df.loc[i, 'S_S']==1:\n",
    "        df.loc[i+.7,cols]=df.loc[i,cols]\n",
    "        df.loc[i+.7, 'Nappe']='Socle sain'\n",
    "        df.loc[i+.7, 'Litho_top']=df.loc[i, 'Soc_sn_top']\n",
    "        df.loc[i+.7, 'Litho_base']=df.loc[i, 'Long_for']\n",
    "\n",
    "df.drop(columns=['RB', 'ALL', 'S_A', 'S_S','Rb_base','All_top', 'Soc_alt_top','Soc_sn_top'], inplace=True)\n",
    "df.sort_index(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Description'] = df['Nappe']\n",
    "df['Type'] = 'Forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb3729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4427d1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4112a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: \n",
    "    bh = bh.query('ID==ID and X==X')\n",
    "else:\n",
    "    bh = bh.query('ID==ID')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ec6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54176e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Type_x':list(conflict_df.index), 'Long_for_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)\n",
    "source_bh = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c28a48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_litho, conflict_df = data_merger(source_litho, litho, how='outer', on=['ID', 'Litho_top'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c9f27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_litho\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Litho_base_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)\n",
    "source_litho = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70818828",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-convert",
   "metadata": {},
   "source": [
    "# Processing for new data added - April 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868c4d84",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84916ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6f0254",
   "metadata": {},
   "source": [
    "## 15-Résultats SOL extension pilote et piézairs.xlsx\n",
    "* **Sheet : 'Résult SOL'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bae9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'result_sol_ext_pilote/'\n",
    "sheet='Result_Sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a6210b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Profils_de_sol_Siterem- extension_pilote_et_pilote/'\n",
    "                   'Resultats SOL extension pilote et piezairs.xlsx', \n",
    "                   sheet_name='Résult SOL', skiprows=5)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeec13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:35]\n",
    "an=df.loc[36:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac7673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[0] # put data on first line\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a71b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df.transpose()\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=col_ren(ech_df, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e61d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=dble_col_drop(ech_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20c482",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df.drop(list(range(3)), axis=0, inplace=True)\n",
    "ech_df.reset_index(drop=True, inplace=True)\n",
    "ech_df=na_col_drop(ech_df,3)\n",
    "ech_df=na_line_drop(ech_df,3)\n",
    "ech_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db3d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=ech_df[:-1]\n",
    "ech_df.drop(columns=['broyage'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b1843",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID_ech','Ech_top', 'Ech_base','MS','Date_ech','Long_for','Refus','Description','MO','COT','pH_KCl', \n",
    "      'Temp_pH','pH_H20','Fract_2','Fract_2+', 'Fract_min_2µ','Fract_min_50µ','Fract_min_2']\n",
    "ech_df=col_ren(ech_df, name=name, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14498bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(ech_df.Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a427abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ech_df['Description'])):\n",
    "    x = ech_df.loc[i,'Description']\n",
    "    if x in ['R','R ']: ech_df.loc[i,'Description']='Remblais'\n",
    "    elif x in ['TN','TN ']: ech_df.loc[i,'Description']='Terrain naturel'\n",
    "\n",
    "ech_df['Refus']=ech_df['Refus'].apply(lambda x: 'x' if not pd.isnull(x) else '')\n",
    "ech_df.insert(1,'Type_ech','Sol')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a828a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ech_df)):\n",
    "    x=ech_df.loc[i,'ID_ech']\n",
    "    r=re.search('([\\w|\\d]+)\\n.+$', x)\n",
    "    if r: \n",
    "        ech_df.loc[i,'ID_ech']='226/'+r.group(1) # Rename borehole 304 to 226 because of conflict with piezair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235aeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f2aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.rename(columns={an.columns[0]:'ID_ech','col_35':'Phénanthrène'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1786430",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an[an.columns[:-17]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6631d0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = col_ren(an, name=POL_NAMES_MODEL, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f063fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(3)), axis=0, inplace=True)\n",
    "an.reset_index(drop=True, inplace=True)\n",
    "an=na_col_drop(an,1)\n",
    "an = na_line_drop(an, 1)\n",
    "an.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d170ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = an\n",
    "for i in range(len(data)):\n",
    "    x=data.loc[i,'ID_ech']\n",
    "    r=re.search('([\\w|\\d]+)\\n.+$', x)\n",
    "    if r: \n",
    "        data.loc[i,'ID_ech']='226/'+r.group(1) # Rename borehole 304 to 226 because of conflict with piezair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbb9343",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, conflict_df = data_merger(ech_df, an, how='outer', on=['ID_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6380d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(df, id_ech_col='ID_ech', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = []\n",
    "for i in df.index:\n",
    "    if not re.search('\\d+', df.loc[i,'ID']): to_drop.append(i)\n",
    "df.drop(index=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5a12bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Date_ech'] = df['Date_ech'].astype('datetime64')\n",
    "df['Date_mes'] = df['Date_ech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c24648a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = 'Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597adf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64c1d21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dict = data_slicer(df, cols_dict, crit_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48112c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukw = df_dict['unknown']\n",
    "bh = df_dict['borehole']\n",
    "\n",
    "bh = bh.drop(index=ukw.index)\n",
    "ukw.drop_duplicates(['ID'], inplace=True)\n",
    "ukw.reset_index(drop=True, inplace=True)\n",
    "bh.drop_duplicates(['ID'], inplace=True)\n",
    "if 'X' in bh.columns: \n",
    "    bh = bh.query('ID==ID and X==X')\n",
    "else:\n",
    "    bh = bh.query('ID==ID')\n",
    "bh.reset_index(drop=True, inplace=True)\n",
    "\n",
    "mes = df_dict['measure']\n",
    "an = df_dict['analysis']\n",
    "litho = df_dict['lithology']\n",
    "eqp = df_dict['equipement']\n",
    "\n",
    "print(f'borehole: {len(bh)} ; measure: {len(mes)} ; lithology: {len(litho)} ; analysis: {len(an)} ; ' \n",
    "      f'equipement: {len(eqp)} ; unknown: {len(ukw)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db892e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh = bh\n",
    "source_mes = mes\n",
    "source_an = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d25a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35398edc",
   "metadata": {},
   "source": [
    "* **Sheet : 'inorganiques et composés majeur'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a375fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'donnees_terrain_2019/'\n",
    "sheet='Inorg_comp_majeur'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cc845b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Profils_de_sol_Siterem- extension_pilote_et_pilote/'\n",
    "                   'Resultats SOL extension pilote et piezairs.xlsx', \n",
    "                   sheet_name='inorganiques et composés majeur', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,1)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84550ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech_df=df.loc[:20] # not really interesting here!\n",
    "an=df.loc[21:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3d7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.loc[0.5] = df.loc[0] # put data on first line\n",
    "an.loc[1.5] = df.loc[2]\n",
    "an = an.sort_index().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa8d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an.transpose()\n",
    "an.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3e4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=col_ren(an, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d35895",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.rename(columns={an.columns[0]:'ID_ech', 'Date de prélèvement':'Date_ech'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70602b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=an[an.columns[:-7]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "an=dble_col_drop(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "an.drop(list(range(3)), axis=0, inplace=True)\n",
    "an.reset_index(drop=True, inplace=True)\n",
    "an=na_col_drop(an,2)\n",
    "an = na_line_drop(an,1)\n",
    "an.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567ec7a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "an = col_ren(an, name=POL_NAMES_MODEL, mode=1)#, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f6aacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = dble_col_drop(an)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c2a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = an\n",
    "for i in range(len(data)):\n",
    "    x=data.loc[i,'ID_ech']\n",
    "    r=re.search('([\\w|\\d]+)\\n.+$', x)\n",
    "    if r: \n",
    "        data.loc[i,'ID_ech']='226/'+r.group(1) # Rename borehole 304 to 226 because of conflict with piezair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd426ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "an['Date_ech'] = an['Date_ech'].astype('datetime64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519aaf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gen_id_from_ech(an, id_ech_col='ID_ech', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6deda888",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8818d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_an, conflict_df = data_merger(source_an, df, how='outer', on=['ID_ech', 'Date_ech'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64876870",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d4ff8d",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36e85cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "framed-assignment",
   "metadata": {},
   "source": [
    "## 16-Profils de sol et données de terrain 2019.xlsx\n",
    "* **Sheet : 'Log'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bizarre-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'donnees_terrain_2019/'\n",
    "sheet='Log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-cricket",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Profils_de_sol_Siterem- extension_pilote_et_pilote/'\n",
    "                   'Profils de sol et donnees de terrain 2019.xlsx', \n",
    "                   sheet_name='Log', skiprows=0)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rapid-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['ID','Litho_top', 'Litho_base', 'Keyword', 'Description']\n",
    "df = col_ren(df, name=name, mode=1, )\n",
    "df = df[1:]\n",
    "df['Date_for'] = dtm.datetime(2019,12,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-nursing",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=df.query('Litho_base.isnull() or Litho_top.isnull()').index, inplace=True)\n",
    "df.drop(index=[64], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b877c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = 'Piezo'\n",
    "df.loc[65:80, 'Type'] = 'piezair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569502ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emplacement'] = 'Extension Pilote'\n",
    "df.loc[83:, 'Emplacement'] = 'Mini-pilote' #piezair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83997390",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "litho = df\n",
    "source_litho = litho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d91d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-accessory",
   "metadata": {},
   "source": [
    "* **Sheet : 'Echantillon'+'Organoleptique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'donnees_terrain_2019/'\n",
    "sheet='Echantillon'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-munich",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Profils_de_sol_Siterem- extension_pilote_et_pilote/'\n",
    "                   'Profils de sol et donnees de terrain 2019.xlsx', \n",
    "                   sheet_name='Echantillon', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-scheme",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID','Ech_top', 'Ech_base', 'ID_ech']\n",
    "df=col_ren(df, name=name, mode=1)\n",
    "df.insert(1,'Type_ech','Sol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equivalent-roots",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=[43,44,55,56,66], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "ech=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-marketing",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Profils_de_sol_Siterem- extension_pilote_et_pilote/'\n",
    "                   'Profils de sol et donnees de terrain 2019.xlsx', \n",
    "                   sheet_name='Organoleptique', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,4)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID','Pol_top', 'Pol_base','Polluant','Intensite']\n",
    "df=col_ren(df, name=name, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-sugar",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=[10,11,14,15], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-colombia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, conflict_df =data_merger(ech, df, on='ID', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714610d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limited-prerequisite",
   "metadata": {},
   "outputs": [],
   "source": [
    "an = df\n",
    "source_an = an"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c93e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-duplicate",
   "metadata": {},
   "source": [
    "* **Sheet : 'Données de forage'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-ending",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'donnees_terrain_2019/'\n",
    "sheet='Donnees_forage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baking-duration",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Profils_de_sol_Siterem- extension_pilote_et_pilote/'\n",
    "                   'Profils de sol et donnees de terrain 2019.xlsx', \n",
    "                   sheet_name='Données de forage', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID', 'X', 'Y', 'Z', 'Date_for', 'Long_for', 'Method', 'Diam_for','Rmq', 'Long_pz', 'Diam_pz', \n",
    "      'Sect_crep','Societe', 'Resp_chantier']\n",
    "df=col_ren(df, name=name, mode=1)\n",
    "df.drop(index=[16,23], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(5, 'Type', 'Piezo')\n",
    "df.loc[16:21,'Type']='Piezair'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[9,'ID']='224 bis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-litigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Refus'] = ''\n",
    "df['Type_refus']=''\n",
    "\n",
    "for i in range(len(df['Rmq'])):\n",
    "    val = str(df.loc[i,'Rmq'])\n",
    "    if re.search('[Bb]loqué', val) :\n",
    "        df.loc[i,'Refus'] = 'x'\n",
    "        \n",
    "        if re.search('[lL]aitier', val):\n",
    "            df.loc[i,'Type_refus'] = 'Laitier'\n",
    "        elif re.search('[Bb]éton', val):\n",
    "            df.loc[i,'Type_refus'] = 'Béton'\n",
    "        elif re.search('[Mm]atériaux', val):\n",
    "            df.loc[i,'Type_refus'] = 'Matériaux indurés' \n",
    "    else: \n",
    "        df.loc[i,'Refus'] = '' \n",
    "\n",
    "df['Diam_int_pz'] = df['Diam_pz'].apply(lambda x: pd.to_numeric(x.replace('mm','').split('x')[1]) if not pd.isnull(x) else x)\n",
    "df['Diam_ext_pz'] = df['Diam_pz'].apply(lambda x: pd.to_numeric(x.replace('mm','').split('x')[0]) if not pd.isnull(x) else x)\n",
    "df['Diam_for'] = df['Diam_for'].apply(lambda x: pd.to_numeric(x) if not pd.isnull(x) else x)\n",
    "\n",
    "df.insert(10, 'Diam_ext_pz', df.pop('Diam_ext_pz')) # move to a specified position\n",
    "df.insert(11, 'Diam_int_pz', df.pop('Diam_int_pz'))\n",
    "df.drop(columns=['Rmq', 'Diam_pz'], axis=1, inplace=True)\n",
    "df.drop(df.query(\"ID!=ID\").index, inplace=True) # delete all ID='NaN' lines\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f977196b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = df\n",
    "source_bh = bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5287bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-shock",
   "metadata": {},
   "source": [
    "* **Sheet : 'Equipement'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'donnees_terrain_2019/'\n",
    "sheet='Equipement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-cedar",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Profils_de_sol_Siterem- extension_pilote_et_pilote/'\n",
    "                   'Profils de sol et donnees de terrain 2019.xlsx', \n",
    "                   sheet_name='Equipement', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Déplacement'], inplace=True)\n",
    "name=['ID','Equip_top', 'Equip_base', 'Diam_for', 'Diam_ext_pz', 'Legende']\n",
    "df=col_ren(df, mode=1, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(index=[24,25], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-intro",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Type'] = 'Piezo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9985f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "placed-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "eqp = df\n",
    "source_eqp = eqp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc26efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increased-tonight",
   "metadata": {},
   "source": [
    "* **Sheet : 'Piézométrie'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'donnees_terrain_2019/'\n",
    "sheet='piezometrie'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-judgment",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_UMONS/Profils_de_sol_Siterem- extension_pilote_et_pilote/'\n",
    "                   'Profils de sol et donnees de terrain 2019.xlsx', \n",
    "                   sheet_name='Piézométrie', skiprows=1)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=['ID','Niv_pz_sol', 'Type_ech', 'Date_mes']\n",
    "df=col_ren(df, name=name, mode=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9647bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sudden-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "mes = df\n",
    "source_mes = mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c737522b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "#bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "#source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474ecad7",
   "metadata": {},
   "source": [
    "#### ======================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c929ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des variables\n",
    "_df = pd.DataFrame()\n",
    "source_bh, source_eqp, source_ukw = _df, _df, _df\n",
    "source_litho, source_an, source_mes = _df, _df, _df\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4dbe1d",
   "metadata": {},
   "source": [
    "## 17-coordonnees extension pilote.xls\n",
    "* **Sheet : 'échant sol'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c66a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'coord_ext_pilote/'\n",
    "sheet='échant sol'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a416cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_SITEREM/coordonnees extension pilote.xls', \n",
    "                   sheet_name=sheet, skiprows=0)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d2e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['ID','X','Y','Z']\n",
    "df = col_ren(df, name=name, mode=1, )\n",
    "df = df[3:19]\n",
    "df['Date_for'] = dtm.datetime(2019,10,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33e1623",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emplacement'] = 'Extension Pilote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[9, 'ID'] = 219"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3d0ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab479fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = df\n",
    "source_bh = bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8632c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae65adf",
   "metadata": {},
   "source": [
    "* **Sheet : 'canne chauffe'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc67a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'coord_ext_pilote/'\n",
    "sheet='canne chauffe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab96d1f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_SITEREM/coordonnees extension pilote.xls', \n",
    "                   sheet_name=sheet, skiprows=0)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e3441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['ID','X','Y','Z']\n",
    "df = col_ren(df, name=name, mode=1, )\n",
    "df = df[3:33]\n",
    "df['Date_for'] = dtm.datetime(2019,10,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emplacement'] = 'Extension Pilote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea34cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d6db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['ID'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7169ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132ca9b2",
   "metadata": {},
   "source": [
    "* **Sheet : 'Feuil1'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10eaa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dir= save_dir + 'coord_ext_pilote/'\n",
    "sheet='Feuil1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ab0dd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(ROOT_DIR + '/CF_data/Data_SITEREM/coordonnees extension pilote.xls', \n",
    "                   sheet_name=sheet, skiprows=0)\n",
    "df=na_line_drop(df,0)\n",
    "df=na_col_drop(df,2)\n",
    "df.replace(r'<|>','', inplace=True, regex=True)\n",
    "df.replace(r'-$',np.nan, inplace=True, regex=True)\n",
    "\n",
    "dataframe_viewer(df, rows=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de2bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['ID','X','Y','Z']\n",
    "df = col_ren(df, name=name, mode=1, )\n",
    "df = df[3:]\n",
    "df['Date_for'] = dtm.datetime(2019,10,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85787888",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Emplacement'] = 'Extension Pilote'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a2f1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "for i in df.index:\n",
    "    if pd.isnull(df.loc[i, 'ID']):\n",
    "        df.loc[i, 'ID'] = f'BH_name_{k}'\n",
    "        k+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = ['ID', 'ID_ech']\n",
    "dtf = df\n",
    "for id_col in id_cols:\n",
    "    if id_col in dtf.columns:\n",
    "        dtf[id_col] = dtf[id_col].apply(lambda x: str(x) if not isinstance(x, str) and not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5735a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bh = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_bh, conflict_df = data_merger(source_bh, bh, how='outer', on=['X','Y'], dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d849138",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = source_bh\n",
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'ID_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494c47ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir), os.makedirs(tmp_dir+'source_merge/')\n",
    "    \n",
    "#eqp.to_csv(tmp_dir+sheet+'_Equipments.csv', index=False)\n",
    "#mes.to_csv(tmp_dir+sheet+'_Measures.csv', index=False)\n",
    "bh.to_csv(tmp_dir+sheet+'_Boreholes.csv', index=False)\n",
    "#an.to_csv(tmp_dir+sheet+'_Analysis.csv', index=False)\n",
    "#ukw.to_csv(tmp_dir+sheet+'_Unknown.csv', index=False)\n",
    "#litho.to_csv(tmp_dir+sheet+'_Lithologies.csv', index=False)\n",
    "\n",
    "source_bh.to_csv(tmp_dir+'source_merge/source_Boreholes.csv', index=False) #all Boreholes data in the source\n",
    "#source_mes.to_csv(tmp_dir+'source_merge/source_Measures.csv', index=False) #all Measures data in the source\n",
    "#source_eqp.to_csv(tmp_dir+'source_merge/source_Equipments.csv', index=False)\n",
    "#source_an.to_csv(tmp_dir+'source_merge/source_Analysis.csv', index=False)\n",
    "#source_ukw.to_csv(tmp_dir+'source_merge/source_Unknown.csv', index=False)\n",
    "#source_litho.to_csv(tmp_dir+'source_merge/source_Lithologies.csv', index=False)\n",
    "\n",
    "print(f'source_bh: {len(source_bh)} ; source_eqp: {len(source_eqp)} ; source_uknw: {len(source_ukw)} ; '\n",
    "      f'source_litho: {len(source_litho)} ; source_an: {len(source_an)} ; source_mes: {len(source_mes)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-providence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
