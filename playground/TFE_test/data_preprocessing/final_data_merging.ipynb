{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-killing",
   "metadata": {},
   "source": [
    "# FUSION FINALE DES JEUX DE DONNEES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import dataframe_viewer, files_search, data_merger, data_validation, data_overview, \\\n",
    "gen_id_from_ech, na_line_drop\n",
    "\n",
    "import re, os\n",
    "import pandas as pd\n",
    "from definitions import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(files, check_position=True, verbose=True): # find another name for this function\n",
    "    \"\"\"\n",
    "    create dataframes from files and test if they contain position informations\n",
    "    files: list of files name\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    i = 0\n",
    "    for f in files:\n",
    "        i += 1\n",
    "        df = pd.read_csv(f, delimiter=',')\n",
    "        id_cols = ['ID', 'ID_ech']\n",
    "        for id_col in id_cols:\n",
    "            if id_col in df.columns:\n",
    "                df[id_col] = df[id_col].apply(lambda x: str(x) if not pd.isnull(x) else x)\n",
    "                \n",
    "        if check_position:\n",
    "            if 'X' in df.columns:\n",
    "                df['X'] = df['X'].apply(lambda x: x.replace(',','.') if isinstance(x, str) else x)\n",
    "                df['X'] = df['X'].astype('float64')\n",
    "            if 'Y' in df.columns:\n",
    "                df['Y'] = df['Y'].apply(lambda x: x.replace(',','.') if isinstance(x, str) else x)\n",
    "                df['Y'] = df['Y'].astype('float64')\n",
    "            if 'Z' in df.columns:\n",
    "                df['Z'] = df['Z'].apply(lambda x: x.replace(',','.') if isinstance(x, str) else x)\n",
    "                df['Z'] = df['Z'].astype('float64')\n",
    "        \n",
    "        df = na_line_drop(df, line_non_na=1)\n",
    "        dfs.append(df)\n",
    "        \n",
    "        if verbose:\n",
    "            if 'X' in list(df.columns): msg = ' --> Coordinates'\n",
    "            else: msg = ' --> No coordinates'\n",
    "\n",
    "            print(f\"df{i} : {msg}\")\n",
    "    \n",
    "            \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_dir = ROOT_DIR + '/CF_data/Result_traitem/organisation/'\n",
    "save_dir = csv_data_dir + '../fusion_finale/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a5bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(f\"rm -rf {save_dir}\") \n",
    "os.system(f\"mkdir {save_dir}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4574f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sufx = ['sup', 'prof', 'inf', '/\\dM(\\*)?']\n",
    "prefx = ['eau forage ']\n",
    "id_reg = '\\s*(?P<id>(?:^canne |Piezair )*\\w*\\d+\\w*)\\s*'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-noise",
   "metadata": {},
   "source": [
    "# Collecte des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my dictionary structure to retrieve good files (Keynames !!!)\n",
    "files_dict={'Borehole':0,'Litho':0,'Equipm':0,'Measure':0,'Sample':0,'Unknow':0}\n",
    "data_dict={'Borehole':0,'Litho':0,'Equipm':0,'Measure':0,'Sample':0,'Unknow':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-sensitivity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_search(csv_data_dir, files_dict, prefix='source', details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "how=['inner', 'outer', 'left', 'right']\n",
    "view = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d22ec7",
   "metadata": {},
   "source": [
    "## Forages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Borehole'\n",
    "dataset = pd.DataFrame()\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66512dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7a868",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a9105",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Memoris_seafile/source_merge/source_Boreholes.csv' # 1\n",
    "file2= csv_data_dir + 'Phase_1_Memoris/source_merge/source_Boreholes.csv' # 2\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb0026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048bd93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a70a0",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede67f61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Phase_2_Memoris/source_merge/source_Boreholes.csv' # 3\n",
    "file2= csv_data_dir + 'Prof_contact_sol_forage/source_merge/source_Boreholes.csv' # 4\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7dd6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bc414",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12aa198",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dceb39",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29aa4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'database_Memoris3/source_merge/source_Boreholes.csv' # 8\n",
    "file2= csv_data_dir + 'donnees_terrain_2019/source_merge/source_Boreholes.csv' # 9\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffbf2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3471a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'Type_y':list(conflict_df.index), 'Long_for_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aff8ef",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0f518",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'profils_sols_donnees_forages/source_merge/source_Boreholes.csv' # 11\n",
    "file2= csv_data_dir + 'vUmons_logsFor/source_merge/source_Boreholes.csv' # 13\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ace9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Type_refus'] = df1['Refus'].apply(lambda x: x if not pd.isnull(x) else x)\n",
    "df1['Refus'] = df1['Refus'].apply(lambda x: 'x' if not pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5df08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631dc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "data_validation(overall_data=data, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Type_y':list(conflict_df.index), 'Long_for_y':list(conflict_df.index),\n",
    "                           'Long_pz_sol_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in data.columns:\n",
    "    if 'index' in data.columns:\n",
    "        data.drop(columns='index', inplace=True)\n",
    "    data.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d8d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'Date_for_y':list(conflict_df.index), 'Type_y':list(conflict_df.index), \n",
    "                            'Long_pz_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66451201",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b4376",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbaa65c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Forage_Pilote/source_merge/source_Boreholes.csv' # 0\n",
    "file2= csv_data_dir + 'Siterem_Ext_Pilote/source_merge/source_Boreholes.csv' # 5\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['ID'] = df2['ID'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebe75b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0abfb401",
   "metadata": {},
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'Z_x':list(conflict_df.index), 'Type_x':list(conflict_df.index), \n",
    "                            'Long_for_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca6d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaea63c",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83cd60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Siterem_Pilote/source_merge/source_Boreholes.csv' # 6\n",
    "file2= csv_data_dir + 'Siterem_Result_Sol/source_merge/source_Boreholes.csv' # 7\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9630c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3bb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9cde7",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70dd0c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'observ_terrain/source_merge/source_Boreholes.csv' # 10\n",
    "file2= csv_data_dir + 'result_sol_ext_pilote/source_merge/source_Boreholes.csv' # 12\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da626427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1413005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc438b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'Long_pz_sol_y':list(conflict_df.index), 'Rmq_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97642de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf73ff8",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b663df0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'coord_ext_pilote/source_merge/source_Boreholes.csv' # \n",
    "\n",
    "df1 = create_df([file1])[0]\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1dc047",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['X','Y'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d8c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'ID_x':[569, 570], 'ID_y':[565], 'Date_for_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0f2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de75a1",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Sauvegarde du jeu de données}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eae990",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['Borehole'] = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(save_dir + 'Boreholes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a52f19d",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579799cf",
   "metadata": {},
   "source": [
    "# Lithologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Litho'\n",
    "dataset = pd.DataFrame()\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9038f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb241960",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63078412",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a63f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'database_Memoris3/source_merge/source_Lithologies.csv' # 0\n",
    "file2= csv_data_dir + 'profils_sols_donnees_forages/source_merge/source_Lithologies.csv' # 2\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed312a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID', 'Litho_top', 'Litho_base'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68412a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea8b390",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fec0c",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae92cc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'donnees_terrain_2019/source_merge/source_Lithologies.csv' # 1\n",
    "file2= csv_data_dir + 'vUmons_logsFor/source_merge/source_Lithologies.csv' # 3\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffea2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(index = df1.query('Litho_top.str.contains(\"De\")', engine='python').index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ab1704",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_list = [df1, df2]\n",
    "for n, dt in enumerate(dt_list):\n",
    "    for w in ['_top', '_base']:\n",
    "        for c in dt.columns:\n",
    "            if re.search(w, c, flags=re.I):\n",
    "                print(n, c)\n",
    "                dt[c] = dt[c].astype('float') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d7111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID', 'Litho_top', 'Litho_base'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26741138",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'Litho_top', 'Litho_base'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe49a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820aeda1",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Sauvegarde du jeu de données}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict['Litho'] = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f820536",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(save_dir + 'Lithologies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84243cd9",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5c5f0",
   "metadata": {},
   "source": [
    "# Echantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Sample'\n",
    "dataset = pd.DataFrame()\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4323bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdbef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd7db0",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4e297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Memoris_seafile/source_merge/source_Samples.csv' # 2\n",
    "file2= csv_data_dir + 'Liste_XY/source_merge/source_Samples.csv' # 1\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e0d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID', 'ID_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72835bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852b1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4e1c7",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a94c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir +  'Phase_1_Memoris/source_merge/source_Samples.csv' # 3\n",
    "file2= csv_data_dir + 'Phase_2_Memoris/source_merge/source_Samples.csv' # 4\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb1890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f48bf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'C16-C21_y':list(conflict_df.index), 'C21-C35_y':list(conflict_df.index), \n",
    "                            'C12-C16_y':list(conflict_df.index), 'Fract_2+_y':list(conflict_df.index), \n",
    "                            'C10-C12_y':list(conflict_df.index), 'HC_tot_C10-C35_y':list(conflict_df.index), \n",
    "                            'Fract_2_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a453e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c4975",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0ac02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir +  'database_Memoris3/source_merge/source_Samples.csv' # 8\n",
    "file2= csv_data_dir +  'profils_sols_donnees_forages/source_merge/source_Samples.csv' # 10\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d409e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b1745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID', 'ID_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43340c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc23b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'Nappe_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e9b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb8999",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fe8a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir +  'Container_phyto/source_merge/source_Samples.csv' # 0\n",
    "file2= csv_data_dir +  'vUmons_logsFor/source_merge/source_Samples.csv' # 12\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4dfd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bfb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = gen_id_from_ech(mdf, id_ech_col='ID_ech', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "col = 'ID_ech'\n",
    "for i in data.index:\n",
    "    v = data.loc[i, col]\n",
    "    if not pd.isnull(v) and re.search('ech', v, re.I):\n",
    "        data.loc[i, 'ID'] = 'F_' + re.sub(' |.','', v,re.I)\n",
    "mdf = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d276d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f8dba5",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605743a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir +  'Siterem_Ext_Pilote/source_merge/source_Samples.csv' # 5\n",
    "file2= csv_data_dir +  'Siterem_Pilote/source_merge/source_Samples.csv' # 6\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ID_ech'] = df1['ID_ech'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013df53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf34956",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9ee89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'C16-C21_x':list(conflict_df.index), 'C12-C16_x':list(conflict_df.index), \n",
    "                            'C10-C12_x':list(conflict_df.index), 'HC_tot_C10-C35_x':list(conflict_df.index), \n",
    "                            'C21-C35_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2353a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d668700",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1932c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir +  'Siterem_Result_Sol/source_merge/source_Samples.csv' # 7\n",
    "file2= csv_data_dir +  'donnees_terrain_2019/source_merge/source_Samples.csv' # 9\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7732520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['ID'] = df2['ID'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98525bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce4ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID', 'ID_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd58696",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'Ech_top_y':list(conflict_df.index), 'Ech_base_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51266df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd69f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba89b091",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fa62a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir +  'result_sol_ext_pilote/source_merge/source_Samples.csv' # 11\n",
    "\n",
    "df1 = create_df([file1])[0]\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1bfff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bad9c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0039542a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4b549",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Sauvegarde du jeu de données}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b711f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict['Sample'] = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bbeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(save_dir + 'Samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bd13c5",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600cb665",
   "metadata": {},
   "source": [
    "## Objets inconnus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed01cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Unknow'\n",
    "dataset = pd.DataFrame()\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267f931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca224c78",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df9a455",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir +  'database_Memoris3/source_merge/source_Unknown.csv' # 11\n",
    "\n",
    "df1 = create_df([file1])[0]\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd7642",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a583ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67f5868",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Sauvegarde du jeu de données}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771926c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict['Unknow'] = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c430761",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(save_dir + 'Unknown.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f36ae5",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5b63d7",
   "metadata": {},
   "source": [
    "## Equipements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e46b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Equipm'\n",
    "dataset = pd.DataFrame()\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d8be24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b6307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f945c9c",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee1a3cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Memoris_seafile/source_merge/source_Equipments.csv' # 0\n",
    "file2= csv_data_dir + 'Phase_1_Memoris/source_merge/source_Equipments.csv' # 1\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef26d916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be51f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efea9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091fd2ea",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546afb93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Phase_2_Memoris/source_merge/source_Equipments.csv' # 2\n",
    "file1= csv_data_dir + 'profils_sols_donnees_forages/source_merge/source_Equipments.csv' # 4\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b227905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6d397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID','Type_equip'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ee94fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'Type_equip'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac72baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5600a5a4",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d0a74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'donnees_terrain_2019/source_merge/source_Equipments.csv' # 3\n",
    "\n",
    "df1 = create_df([file1])[0]\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf542bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ID'] = df1['ID'].astype('object')\n",
    "df1.rename(columns={'Legende':'Type_equip'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdcb47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID', 'Type_equip'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b68f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79571f5a",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Sauvegarde du jeu de données}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b4133a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict['Equipm'] = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bcf46d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(save_dir + 'Equipments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da83ac9b",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855acda1",
   "metadata": {},
   "source": [
    "# Mesures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Measure'\n",
    "dataset = pd.DataFrame()\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57006b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f0e0a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3e43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_reg = '\\s*(?P<id>(?:^canne |Piezair )*\\w*\\d+\\w*)\\s*' # default \n",
    "id_reg = '\\s*(?P<id>(?:^canne |Piezair |Drain |Moni )*\\w*\\d+\\w*)\\s*'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f82446",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2da165e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Memoris_seafile/source_merge/source_Measures.csv' #1\n",
    "file2= csv_data_dir + 'Phase_1_Memoris/source_merge/source_Measures.csv' # 2\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165db7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2542bf44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID','ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081b3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4f7f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723cd4e",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e7539f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Phase_2_Memoris/source_merge/source_Measures.csv' # 3\n",
    "file2= csv_data_dir + 'database_Memoris3/source_merge/source_Measures.csv' # 7\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b32120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID','ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175e663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr = mdf.copy() \n",
    "found = []\n",
    "for i in datafr.index:\n",
    "    if pd.isnull(datafr.loc[i, 'ID_ech']):\n",
    "        found.append(i)\n",
    "        datafr.loc[i, 'ID_ech'] = datafr.loc[i, 'ID']\n",
    "if found: print(f\"{len(found)} Nan found in 'ID_ech' and fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508147ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in datafr.index:\n",
    "    if re.search('FP 49 PROF', datafr.loc[i, 'ID_ech']):\n",
    "        datafr.loc[i, 'ID_ech'] = 'FP49 PROF'\n",
    "    elif re.search('FP 49 SUP', datafr.loc[i, 'ID_ech']):\n",
    "        datafr.loc[i, 'ID_ech'] = 'FP49 SUP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32afdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr = gen_id_from_ech(datafr, id_ech_col='ID_ech', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)#, verbose=True)\n",
    "mdf = datafr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c0943",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID','ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46955443",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'Fract_2_y':list(conflict_df.index), 'Fract_2+_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99889fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e7296e",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e5cbd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'profils_sols_donnees_forages/source_merge/source_Measures.csv' # 10\n",
    "file2= csv_data_dir + 'database_Memoris3/source_merge/source_Measures.csv' # 12\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e008a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f2404",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ffb8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr = mdf.copy() \n",
    "found = []\n",
    "for i in datafr.index:\n",
    "    if pd.isnull(datafr.loc[i, 'ID_ech']):\n",
    "        found.append(i)\n",
    "        datafr.loc[i, 'ID_ech'] = datafr.loc[i, 'ID']\n",
    "if found: print(f\"{len(found)} Nan found in 'ID_ech' and fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c717331",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr = gen_id_from_ech(datafr, id_ech_col='ID_ech', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)\n",
    "mdf = datafr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194e0321",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID','ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc8e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'MS_x':list(conflict_df.index), 'pH_CaCl2_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bb1ab3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2a72a6",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c40b3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Container_phyto/source_merge/source_Measures.csv' # 0\n",
    "file2= csv_data_dir + 'Siterem_Ext_Pilote/source_merge/source_Measures.csv' # 4\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768de1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39aa90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['ID_ech'] = df2['ID_ech'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1164e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7569e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr = mdf.copy() \n",
    "found = []\n",
    "for i in datafr.index:\n",
    "    if pd.isnull(datafr.loc[i, 'ID_ech']):\n",
    "        found.append(i)\n",
    "        datafr.loc[i, 'ID_ech'] = datafr.loc[i, 'ID']\n",
    "if found: print(f\"{len(found)} Nan found in 'ID_ech' and fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10cbbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datafr = gen_id_from_ech(datafr, id_ech_col='ID_ech', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)\n",
    "mdf = datafr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1c3852",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87876ee3",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8632e3f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'Siterem_Pilote/source_merge/source_Measures.csv' #5\n",
    "file2= csv_data_dir + 'Siterem_Result_Sol/source_merge/source_Measures.csv' #6\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf9296",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76df1e81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID','ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c40a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr = mdf.copy() \n",
    "found = []\n",
    "for i in datafr.index:\n",
    "    if pd.isnull(datafr.loc[i, 'ID_ech']):\n",
    "        found.append(i)\n",
    "        datafr.loc[i, 'ID_ech'] = datafr.loc[i, 'ID']\n",
    "if found: print(f\"{len(found)} Nan found in 'ID_ech' and fixed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33534910",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafr = gen_id_from_ech(datafr, id_ech_col='ID_ech', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)\n",
    "mdf = datafr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695664d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID','ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907cc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'Fract_2_y':list(conflict_df.index), 'Fract_2+_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d89648",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388d02d",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e0f6b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'donnees_terrain_2019/source_merge/source_Measures.csv' # 8\n",
    "file2= csv_data_dir + 'observ_terrain/source_merge/source_Measures.csv' # 9\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5510f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768beea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how='outer', on=['ID','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f51b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8756a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index',  \n",
    "                valid_dict={'CE_y':list(conflict_df.index), 'Temp_y':list(conflict_df.index),\n",
    "                           'pH_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57870193",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb1a37",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Lecture et fusion}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48eac259",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= csv_data_dir + 'result_sol_ext_pilote/source_merge/source_Measures.csv' # 11\n",
    "\n",
    "df1 = create_df([file1])[0]\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fcdccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df1\n",
    "dataset, conflict_df=data_merger(dataset, data, how='outer', on=['ID','ID_ech','Date_mes'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180486ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Dataset rows: {len(dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253a92a",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Sauvegarde du jeu de données}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3015a5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dict['Measure'] = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467b9133",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(save_dir + 'Measures.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
