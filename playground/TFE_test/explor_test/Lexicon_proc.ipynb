{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minute-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "from utils.Lexicon_process import build_lexicon, modifier_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "central-thailand",
   "metadata": {},
   "source": [
    "## Create a lexicon from description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiovascular-tobacco",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydir='../../CF_data/synthese/Result_traitem/database_Memoris3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lexicon(path=None, kind_list=None, df_dict=None, desc_col='Description', \n",
    "                  kw_com={}, com_kw_file=None, auto=True, update=False):\n",
    "    \"\"\"\n",
    "    Generate a lexicon from lithological descriptions\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    path: str\n",
    "        root dir from which CSV files (also in subdirs) containing lithological description will be retrieve\n",
    "    kind_list : list\n",
    "        list of lexicon thematic ['lithology','material','colour']. Default is ['lithology']\n",
    "    desc_col : str\n",
    "        name of the dataframe column that contains descriptions\n",
    "    kw_com: dict\n",
    "        dict of common keywords to be considered for each lexicon thematic\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    \n",
    "    \"\"\"\n",
    "    from importlib import import_module\n",
    "    \n",
    "    if com_kw_file is None:\n",
    "        kw_module = import_module('Lexicon_FRA') # ('common_keywords_FR')\n",
    "    else:\n",
    "        kw_module = import_module(com_kw_file)\n",
    "    \n",
    "    assert isinstance(path, str), \"Expected a str for parameter *path*!\"\n",
    "    assert isinstance(kind_list, list), \"Expected a list for parameter *kind*!\"\n",
    "    assert isinstance(desc_col, str), \"Expected a str for parameter *desc_col*!\"\n",
    "    assert isinstance(kw_com, dict), \"Expected a list for parameter *kw_com*!\"\n",
    "   \n",
    "    kind_def = ['lithology', 'material', 'modifier', 'colour']\n",
    "    \n",
    "    LEXICON  =  kw_module.LEXICON\n",
    "    litho_com = LEXICON['lithology'] \n",
    "    mat_com = LEXICON['material'] \n",
    "    modf_com = LEXICON['modifier'] \n",
    "    colour_com = LEXICON['colour']\n",
    "    #split_com = LEXICON['splitters'] \n",
    "    \n",
    "    #--------------------------- Processing --------------------------------\n",
    "    def process(kind_list):\n",
    "        flag = re.IGNORECASE\n",
    "        kw, desc = [], []\n",
    "        litho_lex, mat_lex, modf_lex, colour_lex = [], [], [], []\n",
    "        filter_lex = []\n",
    "\n",
    "        lex = {'lithology':litho_lex, 'material':mat_lex, 'modifier':modf_lex, 'colour':colour_lex, } # generated from the processing\n",
    "        com = {'lithology':litho_com, 'material':mat_com, 'modifier':modf_com,  'colour':colour_com,} # manualy build to contain default values\n",
    "        \n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            if not pd.isnull(df.loc[i, desc_col]): \n",
    "                kw = kw + df.loc[i, desc_col].split(' ')\n",
    "        kw = list(set(kw))\n",
    "\n",
    "        for i in range(len(kw)):\n",
    "            if len(kw[i]) > 2 and not re.search('\\d.*',kw[i]): # to eliminate all 'one letter words' and all numbers\n",
    "                wlist  =  [re.sub(r\"^/|\\.|l'|d'\",\"\",kw[i]).rstrip('[.|...|,|;|(|)|?]').lstrip('?|(|+').replace(',…',\"\")]\n",
    "                desc = desc + wlist\n",
    "        desc = list(set(desc))\n",
    "\n",
    "        if kind_list == ['all']:\n",
    "            kind_list = kind_def\n",
    "                \n",
    "        for kind in kind_list:\n",
    "            filter_lex = []\n",
    "            tmp_lex = lex[kind]\n",
    "            if len(kw_com) == 0: \n",
    "                tmp_com = com[kind]\n",
    "            else: \n",
    "                tmp_com = kw_com[kind]\n",
    "\n",
    "            if kind not in kind_def: \n",
    "                print(\"Parameter *kind* must be 'lithology' or compatible str : see docstring !\")\n",
    "\n",
    "            for v in tmp_com:\n",
    "                if kind == 'colour':\n",
    "                    w = v.rstrip('[e|t]')\n",
    "                    r = re.compile(\"{:s}(e|es|s)?([-|/]\\w+)?([â|a]tre)?$\".format(w), flags=flag)\n",
    "                elif kind == 'modifier':\n",
    "                    w = v.rstrip('[e|es]')\n",
    "                    r = re.compile('(?:-)?(\\w+eu(?:x|se|ses))') #(\"^\\w+-\\w+(eu)+(x|se|ses)?$\", flags=flag)\n",
    "                elif kind == 'material':\n",
    "                    w = v.rstrip('[e|es]')\n",
    "                    r = re.compile(\"^{:s}(e|es)?(-)*(.^/)*$\".format(w), flags=flag)\n",
    "                elif kind == 'lithology':\n",
    "                    w = v.rstrip('[e|es]')\n",
    "                    r = re.compile(\"^{:s}(e|es|o)?([-|/]\\w+)*$\".format(w), flags=flag)\n",
    "                else:\n",
    "                    w = v.rstrip('[e|es]')\n",
    "                    r = re.compile(\"^\\w+-\\w+(eu)+(x|se|ses)?$\", flags=flag)\n",
    "                \n",
    "                tmp_lex = tmp_lex + list(filter(r.findall, desc))\n",
    "                    \n",
    "            for l in tmp_lex:\n",
    "                w = l.capitalize()\n",
    "                if re.search('.+o$|.+s$',w) and kind == 'lithology':\n",
    "                    w = re.sub('o$','e',w)\n",
    "                    w = re.sub('s$','',w)\n",
    "                    \n",
    "                if w not in filter_lex: \n",
    "                    filter_lex = filter_lex + [w]\n",
    "            \n",
    "            lex[kind] = lex[kind] + filter_lex\n",
    "            \n",
    "            if kind == 'modifier':\n",
    "                print(f'{len(lex[kind])} {lex[kind]}')\n",
    "            \n",
    "            #print(f\"{len(desc)} total keywords found\")\n",
    "            print(f\"|>>> Processing for '{kind}' : {len(filter_lex)} keywords extracted\")\n",
    "            \n",
    "            \"\"\"#----------------------------------------------\n",
    "            mdf = []\n",
    "            for w in desc:\n",
    "                r = re.search('(?:-)?(\\w+eu(?:x|se|ses))',w)\n",
    "                if r: \n",
    "                    mdf = mdf + [re.sub(r'(x|se|ses)$','(?:x|se|ses)?',r.group(1))]\n",
    "            mdf = list(set(mdf))\n",
    "            \n",
    "            for v in LEXICON[kind]: # to manage composites lithologies  \n",
    "                w = re.sub('(e|es)$','',v.replace('(?:s)?',''))\n",
    "                #print(w)\n",
    "                r = re.compile(\"^{:s}(\\w+)?eu?\".format(w), flags=flag)\n",
    "                tmp_lex = tmp_lex + list(set(filter(r.findall, mdf)))\n",
    "            print(f'{len(tmp_lex)} {tmp_lex}')\n",
    "            \n",
    "            #------------------------------------------\"\"\"\n",
    "        \n",
    "        return lex, desc\n",
    "    \n",
    "    #--------------------------- Global lexicon updating -----------------------\n",
    "    def update_lexicon_db(lexicon_db=None, svg=None, colour_db=None):\n",
    "\n",
    "        if svg is None: svg = 'Lexicon_FR.py'\n",
    "        else: svg = f\"{svg}.py\"\n",
    "        \n",
    "        with open(svg, 'w+') as f:\n",
    "            f.write(f'\"\"\"\\nDefinition de mots clés pour les descriptions de cuttings de forages.\\n'+\n",
    "            ':copyright: 2021  Y. N\\'DEPO & O. Kaufmann \\n\"\"\"')\n",
    "\n",
    "            f.write(f'\\n\\n#====================LEXIQUE================================ \\n')\n",
    "            f.write(f'LEXICON = {lexicon_db}')\n",
    "\n",
    "            f.write(f'\\n\\n#===============================COULEURS=============================== \\n')\n",
    "            f.write(f'COLORS = {colour_db}')\n",
    "\n",
    "        print('The lexicon have been updated')\n",
    "\n",
    "    #------------------------------------- Main ----------------------------\n",
    "    \n",
    "    if auto and path is not None:\n",
    "        flist, df_list = [], []\n",
    "\n",
    "        for path, dirs, files in walk(mydir):\n",
    "            for f in files:\n",
    "                if f[0] != '.' and re.compile(r\".+[L|l]ith.+\\.csv\").match(f) and f is not None:\n",
    "                    p = path + \"/\" + f\n",
    "                    flist.append('{}'.format(p))\n",
    "                    df_list.append(pd.read_csv('{}'.format(p)))\n",
    "\n",
    "        df_dict = dict(list(enumerate(df_list))) #dict(zip(keys, values)) where key = range(len(df_list))\n",
    "    \n",
    "    elif not auto and df_dict is not None: pass \n",
    "    else: pass\n",
    "    \n",
    "    if not isinstance(df_dict, type(None)):\n",
    "        for nb, df in df_dict.items():\n",
    "            print(f\"\\nkeywords extraction and filtering from '{flist[nb].replace(mydir,'..')}' ...\")\n",
    "            lexicon, desc = process(kind_list)\n",
    "    \n",
    "    #----------------- Lexicon_db update --------- \n",
    "    #(pas sûr de continuer avec cette idée, ça devient trop complexe au regard de la \n",
    "    # structure du fichier default_lexicon.py [présence d'altérations de mots [..|..] )\n",
    "    if update:\n",
    "        lexicon_db = LEXICON\n",
    "        for kind in kind_def:\n",
    "            lexicon_db[kind] = list(set(lexicon_db[kind] + lexicon[kind]))\n",
    "\n",
    "        update_lexicon_db(lexicon_db)    \n",
    "    else:\n",
    "        print('\\nNo lexicon update set !')\n",
    "\n",
    "    return lexicon, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "experimental-seeking",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "keywords extraction and filtering from '../source_Lithology.csv' ...\n",
      "|>>> Processing for 'lithology' : 14 keywords extracted\n",
      "|>>> Processing for 'material' : 7 keywords extracted\n",
      "|>>> Processing for 'modifier' : 48 keywords extracted\n",
      "|>>> Processing for 'colour' : 51 keywords extracted\n",
      "\n",
      "No lexicon update set !\n"
     ]
    }
   ],
   "source": [
    "lexicon, desc=build_lexicon(mydir, ['all'])#, kw_com=colour_com, auto=True)\n",
    "\n",
    "# put good keywords in ..._com for better results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "complicated-referral",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(lexicon)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "common-decade",
   "metadata": {},
   "source": [
    "print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "marine-breeding",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lexicon_process(desc, lexicon_mod=None,):    \n",
    "        \n",
    "    from importlib import import_module\n",
    "    \n",
    "    if lexicon_mod is None:\n",
    "        lex_module = import_module('Lexicon_FRA') # ('common_keywords_FR')\n",
    "    else:\n",
    "        lex_module = import_module(lexicon_mod)\n",
    "    \n",
    "    LEXICON = lex_module.LEXICON\n",
    "    l, md = '', ''\n",
    "    mdf, litho = [], []\n",
    "    mdf_lex, lack_mdf, filter_lex = [], [], []\n",
    "    lex={'lithology':[]}\n",
    "    \n",
    "    match = filter(re.compile('(?:-)?(\\w+eu(?:x|se|ses))').findall, desc)\n",
    "\n",
    "    for i in match:\n",
    "        for j in i.split('-'):\n",
    "            # retrieve modifier\n",
    "            if not re.search(r'\\w+o$',j):\n",
    "                md = re.sub(r'eu(x|se|ses)$','eu(?:x|se|ses)?',j)\n",
    "\n",
    "            # retrieve lithology\n",
    "            if re.search(r'(velo)$',j):\n",
    "                #l = re.sub(r'(velo)$','vier(?:s)?',j)\n",
    "                l = re.sub(r'(velo)$','vier',j)\n",
    "            elif re.search(r'(ono)$',j):\n",
    "                #l = re.sub(r'o$','(?:s)?',j)\n",
    "                l = re.sub(r'o$','',j)\n",
    "            elif re.search(r'o$',j):\n",
    "                #l = re.sub(r'(o)$','e(?:s)?',j)\n",
    "                l = re.sub(r'(o)$','e',j)\n",
    "\n",
    "            if md not in mdf and md != '':\n",
    "                mdf = mdf + [md]\n",
    "            if l not in litho and l != '':\n",
    "                litho = litho + [l]\n",
    "\n",
    "\n",
    "    for v in LEXICON['lithology']: # to manage modifiers  \n",
    "        w=re.sub('(e|es)$','',v.replace('(?:s)?',''))\n",
    "        #print(w)\n",
    "        r=re.compile(\"^{:s}\\w?eu\".format(w), flags=re.IGNORECASE)\n",
    "        mdf_lex=mdf_lex+list(set(filter(r.findall, mdf)))\n",
    "\n",
    "    lack_mdf = list(set(mdf)-set(mdf_lex))\n",
    "\n",
    "    if len(lack_mdf) > 0 :   \n",
    "        log_file = \"Lexicon_Log.py\"\n",
    "\n",
    "        with open(log_file, 'w+') as f:\n",
    "            f.write('\"\"\"This file contains all keywords skipped during lexicon building processes\"\"\"')\n",
    "            f.write(f'\\n\\n#====================MODIFIERS LOG================================ \\n')\n",
    "            f.write(f'skipped_words = {lack_mdf}')\n",
    "\n",
    "        print(f'Extraction completed with skipped modifiers : check log file ({log_file}) ! ')\n",
    "    else:\n",
    "        print('Extraction completed !')\n",
    "    \n",
    "    return mdf_lex, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "capital-testament",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexicon_process' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-08192e906c61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlexicon_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'lexicon_process' is not defined"
     ]
    }
   ],
   "source": [
    "lexicon_process(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lexicon_FRA_mod import LEXICON\n",
    "\n",
    "kind = 'lithology'\n",
    "tmp_lex = []\n",
    "filter_lex = []\n",
    "lex={'lithology':[]}\n",
    "\n",
    "for v in LEXICON[kind]: # to manage modifiers  \n",
    "    w=re.sub('(e|es)$','',v.replace('(?:s)?',''))\n",
    "    #print(w)\n",
    "    r=re.compile(\"^{:s}(\\w+)?eu?\".format(w), flags=re.IGNORECASE)\n",
    "    tmp_lex=tmp_lex+list(set(filter(r.findall, mdf)))\n",
    "print(f'{len(tmp_lex)} {tmp_lex}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "returning-administrator",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-894a1ee20563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'(?:-)?(\\w+eu(?:x|se|ses))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "re.compile('(?:-)?(\\w+eu(?:x|se|ses))').match(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in desc:\n",
    "    r = re.search('(?:-)?(\\w+eu(?:x|se|ses))',w)\n",
    "    if r: \n",
    "        mdf = mdf + [re.sub(r'(x|se|ses)$','(?:x|se|ses)?',r.group(1))]\n",
    "mdf=list(set(mdf))\n",
    "\n",
    "r=re.compile(\"^{:s}(\\w+)?eu?\".format(w), flags=re.IGNORECASE)\n",
    "tmp_lex=tmp_lex+list(set(filter(r.findall, mdf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = []\n",
    "lith = []\n",
    "for w in desc:\n",
    "    r = re.search('(?:-)?(\\w+eu(?:x|se|ses))',w)\n",
    "    if r: \n",
    "        mdf = mdf + [re.sub(r'(x|se|ses)$','(?:x|se|ses)?',r.group(1))]\n",
    "mdf=list(set(mdf))\n",
    "        \n",
    "for w in desc: # to manage composite lithologies retrieving the primary and use the secondary as modifier\n",
    "    r = re.search('(\\w+o)(?:-|to|so)',w)\n",
    "    if r:\n",
    "        if re.search(r'(velo)$',r.group(1)):\n",
    "            #l=re.sub(r'(velo)$','vier(?:s)?',r.group(1))\n",
    "            l=re.sub(r'(velo)$','vier',r.group(1))\n",
    "        elif re.search(r'(ono)$',r.group(1)):\n",
    "            #l=re.sub(r'o$','(?:s)?',r.group(1))\n",
    "            l=re.sub(r'o$','',r.group(1))\n",
    "        elif re.search(r'o$',r.group(1)):\n",
    "            #l=re.sub(r'(o)$','e(?:s)?',r.group(1))\n",
    "            l=re.sub(r'(o)$','e',r.group(1))\n",
    "            \n",
    "        lith = lith + [l]\n",
    "lith=list(set(lith))\n",
    "\n",
    "print(f'{len(mdf)} {mdf} \\n\\n {len(lith)} {lith}') #modifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : create a function to add keywords in the lexicon (if not exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Lexicon_FRA import LEXICON\n",
    "\n",
    "kind = 'lithology'\n",
    "tmp_lex = []\n",
    "filter_lex = []\n",
    "lex={'lithology':[]}\n",
    "\n",
    "for v in LEXICON[kind]: # to manage composites lithologies  \n",
    "    w=re.sub('(e|es)$','',v.replace('(?:s)?',''))\n",
    "    #print(w)\n",
    "    r=re.compile(\"^{:s}(\\w+)?eu?\".format(w), flags=re.IGNORECASE)\n",
    "    tmp_lex=tmp_lex+list(set(filter(r.findall, mdf)))\n",
    "print(f'{len(tmp_lex)} {tmp_lex}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "written-questionnaire",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_lex = []\n",
    "filter_lex = []\n",
    "lex={'lithology':[]}\n",
    "\n",
    "for v in LEXICON[kind]: # to manage non composites lithologies  \n",
    "    w=re.sub('(e|es)$','',v)#.replace('(?:s)?',''))\n",
    "    #print(w)\n",
    "    r=re.compile(\"^{:s}(e|es)?([-|/]\\w+)*$\".format(w), flags=re.IGNORECASE)\n",
    "    tmp_lex=tmp_lex+list(set(filter(r.findall, desc)))\n",
    "print(f'{len(tmp_lex)} {tmp_lex}')\n",
    "\n",
    "for l in tmp_lex:\n",
    "    w=l.capitalize()\n",
    "    if re.search('.+[^èo]s$',w) and kind=='lithology':\n",
    "        #w=re.sub('o$','e',w)\n",
    "        w=re.sub('s$','',w)\n",
    "\n",
    "    if w not in filter_lex: \n",
    "        filter_lex=filter_lex+[w]\n",
    "\n",
    "lex[kind]=lex[kind]+filter_lex\n",
    "print(f'{len(lex[kind])} {lex[kind]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joint-samoa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LEXICON[kind][:5]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "valued-hobby",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(desc) #all keywords found in description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for a part of a word\n",
    "print(list(filter(re.compile('(?:-)?\\w+eu(?:x|se|ses)?').search, desc)))\n",
    "#print(list(filter(lambda v: v if re.search('(?:-)?\\w+eu(?:x|se|ses)?',v) else '', desc)))\n",
    "#print(list(filter(lambda v:v if re.search('\\+[B|b]',v) else '', desc)))\n",
    "#re.match('.+([o-])?.$', desc).groups()#, re.sub('o$', 'e', desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-justice",
   "metadata": {},
   "source": [
    "#### striplog test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metric-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "from striplog import Component, Legend, Decor, Lexicon\n",
    "from Lexicon_FRA import LEXICON\n",
    "#import Lexicon_FR as lexique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-cancellation",
   "metadata": {},
   "outputs": [],
   "source": [
    "descrip=\"sables hétérogène gris foncé sablo-silteuses pluricentimétriques avec du naphtalène 20-25% charge pierreuse de type laitier\"#, à peu de grains fins à. Vers 2 - 2.4 m, présence d'eau.\"\n",
    "#desc='shaly sand with vf'\n",
    "\n",
    "#lexicon=Lexicon(LEXICON) # our french lexicon\n",
    "#lexicon=Lexicon.default() # the striplog default lexicon (english)\n",
    "\n",
    "comp=Component.from_text(descrip, Lexicon(LEXICON))#lexique.LEXIQUE)\n",
    "comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "re.search('-(\\w+eu)(?:x|se|ses)?', descrip).group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-wellington",
   "metadata": {},
   "source": [
    "===================================== other tests ============================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-payday",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw=lexicon['colour']\n",
    "d=[]\n",
    "for i in range(len(kw)):\n",
    "    if len(kw[i])>2 and not re.search('\\d.*',kw[i]): #to eliminate all 'one letter words' and all numbers\n",
    "        wlist=[re.sub(r\"^/|\\.|l'|d'\",\"\",kw[i]).rstrip('[.|...|,|;|(|)|?]').lstrip('?|(|+')\\\n",
    "               .replace(',…',\"\").replace('es',\"e\")]\n",
    "        d=d+wlist\n",
    "d=list(set(d))\n",
    "print(len(d),'\\n', d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(list(filter(lambda v:v if re.search('[/|-]',v) else '', desc)))\n",
    "print(list(filter(lambda v:v if re.search('[B|b]l',v) else '', d)))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "express-humanitarian",
   "metadata": {},
   "source": [
    "desc=['sables argilo-mangeuses', 'argilo-silteux' 'roses', 'noir', 'blanc/gris', 'rougeâtre', 'rouge-brun',\n",
    "      'rosâtre', 'noirâtre']\n",
    "desc='sables argilo-mangeuses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-malaysia",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp=[]\n",
    "for v in colour_com: \n",
    "    w=v.rstrip('[e|es]')\n",
    "    r=re.compile(\"{:s}(e|es|s)?([-|/]\\w+)?([â|a]tre)?$\".format(w), flags=re.IGNORECASE)\n",
    "    tmp=tmp+list(filter(r.findall, desc))\n",
    "    \n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sound-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lexicon_db(svg=None):\n",
    "\n",
    "    if svg is None: svg='Lexicon_FR.py'\n",
    "    else: svg=f\"{svg}.py\"\n",
    "\n",
    "    with open(svg, 'w+') as f:\n",
    "        f.write(f'\"\"\"\\nDefinition de mots clés pour les descriptions de cuttings.\\n'+\n",
    "        ':copyright: 2021  Y. N\\'DEPO & O. Kaufmann \\n\"\"\"')\n",
    "\n",
    "        f.write(f'\\n\\n# =========== LEXIQUE ===========\\n')\n",
    "        f.write(f'LEXICON = {lexicon_db}')\n",
    "\n",
    "        f.write(f'\\n\\n# =========== COULEURS ===========\\n')\n",
    "        f.write(f'COLORS = {colour_db}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-bread",
   "metadata": {},
   "source": [
    "========================== draft ================================================"
   ]
  },
  {
   "cell_type": "raw",
   "id": "variable-advertising",
   "metadata": {},
   "source": [
    "from itertools import compress\n",
    "\n",
    "fruits = ['apple', 'banana', 'cherry']\n",
    "s = 'green apple and red cherry'\n",
    "\n",
    "list(compress(fruits, (f in s for f in fruits))) #match and return words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "silver-minutes",
   "metadata": {},
   "source": [
    "# Definition of common keywords "
   ]
  },
  {
   "cell_type": "raw",
   "id": "sunrise-europe",
   "metadata": {},
   "source": [
    "litho_com=[\"Andésite\", \"Basalte\", \"Carbonatite\", \"Dacite\", \"Ignimbrite\", \"Obsidienne\", \"Phonolite\", \"Ponce\", \n",
    "           \"Rhyolite\", \"Trachyte\", \"Tuf volcanique\", \"Diorite\", \"Gabbro\", \"Granite\", \"Kimberlite\", \"Monzonite\", \n",
    "           \"Ophite\", \"Péridotite\", \"Syénite\", \"Aplite\", \"Dolérite\", \"Kersantite\", \"Pegmatite\", \"Porphyre\", \"Amphibolite\", \n",
    "           \"Ardoise\", \"Cipolin\", \"Gneiss\", \"Anatectite\", \"Leptynite\", \"Marbre\", \"Micaschiste\", \"Pyroxénite\", \"Quartzite\", \n",
    "           \"Schiste\", \"Argile\", \"Sable\", \"Gravier\", \"Calcaire\", \"Grès\", \"Craie\", \"Conglomérat\", \"brèche\", \n",
    "           \"poudingue\", \"tillite\", \"Molasse \", \"Silcrète\", \"Arkose\", \"Grès\", \"Quartzite\", \"Alios\", \"Argile\", \"Schiste\", \n",
    "           \"Cendres\", \"Cinérites\", \"Lapillis\", \"Tuf volcanique\", \"Calcaire\", \"Craie\", \"Dolomie\", \"Marne\", \n",
    "           \"Pierre coquillière\", \"Diatomite\", \"Jaspe\", \"Silex\", \"Radiolarite\", \"Phtanite\", \"Anthracite\", \"Houille\", \n",
    "           \"Lignite\", \"Tourbe\", \"Gypse\", \"anhydrite\", \"Bauxite\", \"Glauconie\", \"Alios\", \"Amphibolite\", \"Andésite\", \"Aplite\",\n",
    "           \"Ardoise\", \"Argile\", \"Arkose\", \"Basalte\", \"Bauxite\", \"Bentonite\", \"Brèche\", \"Calcaire\", \"Carbonatite\", \"Cargneule\",\n",
    "           \"Cendre\", \"Cinérite\", \"Cipolin\", \"Combarbalite\", \"Conglomérat\", \"Craie\", \"Dacite\", \"Diatomite\", \"Diorite\",\n",
    "           \"Dolérite\", \"Dolomie\", \"éclogite\", \"Gabbro\", \"Glauconite\", \"Gneiss\", \"Granite d'anatexie\", \"Granite\", \"Gravier\", \n",
    "           \"Grès\", \"Gypse\", \"Halite\", \"Houille\", \"Ignimbrite\", \"Jaspe\", \"Kersantite\", \"Kimberlite\", \"Lapillis\", \"Leptynite\", \n",
    "           \"Lignite\", \"Marbre\", \"Marne\", \"Micaschiste\", \"Molasse\", \"Monzonite\", \"Obsidienne\", \"Pegmatite\", \"Péridotite\", \n",
    "           \"Phonolite\", \"Phtanite\", \"Pierre coquillère\", \"Ponce\", \"Porphyre\", \"Poudingue\", \"Pyroxénite\", \"Quartzite\", \n",
    "           \"Radiolarite\", \"Rhyolite\", \"Sable\", \"Schiste\", \"Silcrète\", \"Silex\", \"Syénite\", \"Tourbe\", \"Trachyte\", \n",
    "           \"Tuf volcanique\", \"Tuf\", \"Tuffeau\",\n",
    "          ]\n",
    "litho_com=list(set(litho_com))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "known-midwest",
   "metadata": {},
   "source": [
    "colour_com=[\"Bleu\",\"Blanc\",\"Gris\",\"Jaune\",\"Marron\",\"Noir\",\"Orange\",\"Rose\",\"Rouge\", \n",
    "            \"vert\",\"violet\",\n",
    "            \"Turquoise\",\"Magenta\",\"Beige\",\"Argent\",\"mauve\",\"lie-de-vin\",\n",
    "           ]\n",
    "colour_com=list(set(colour_com))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "australian-integration",
   "metadata": {},
   "source": [
    "print('LITHOLOGY = ',litho_com, \"\\n\\n\", 'COLOUR =', colour_com)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "headed-herald",
   "metadata": {},
   "source": [
    "#idea : load info in a file that save words if there are not in the list (with possibility to add or not)\n",
    "\n",
    "sep_com=['et', 'par', 'dans','du', 'de la'] #just an example\n",
    "mat_com=['Remblai', 'Béton', 'Laitier', 'Scories', 'Brique', 'Briquaillon', 'Caillou', 'Pierre'] # for other materials\n",
    "#state_com=[]\n",
    "#qtity_com=[]\n",
    "#other_com=[]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "stainless-rubber",
   "metadata": {},
   "source": [
    "colour_db={'Bleu':'#0000FF','Aigue-marine':'#79F8F8','Azur':'#007FFF', 'Azur':'#1E7FCB','Azur clair':'#74D0F1',\n",
    "             'Azurin':'#A9EAFE','Bleu acier':'#3A8EBA','Bleu ardoise':'#686F8C','Bleu barbeau':'#5472AE',\n",
    "             'Bleu bleuet':'#5472AE','Bleu bondi':'#0095B6','Bleu céleste':'#26C4EC','Bleu céruléen':'#0F9DE8',\n",
    "             'Bleu céruléen':'#357AB7','Bleu charrette':'#8EA2C6','Bleu charron':'#17657D','Bleu charron':'#8EA2C6',\n",
    "             'Bleu ciel':'#77B5FE','Bleu cobalt':'#22427C','Bleu de Berlin':'#24445C','Bleu de France':'#318CE7',\n",
    "             'Bleu de minuit':'#003366','Bleu de Prusse':'#24445C','Bleu denim':'#1560BD','Bleu des mers du sud':'#00CCCB',\n",
    "             'Bleu dragée':'#DFF2FF','Bleu égyptien':'#1034A6','Bleu électrique':'#2C75FF','Bleu guède':'#56739A',\n",
    "             'Bleu horizon':'#7F8FA6','Bleu majorelle':'#6050DC','Bleu marine':'#03224C','Bleu maya':'#73C2FB','Bleu minéral':'#24445C',\n",
    "             'Bleu nuit':'#0F056B','Bleu outremer':'#1B019B','Bleu outremer':'#2B009A','Bleu paon':'#067790','Bleu persan':'#6600FF',\n",
    "             'Bleu pétrole':'#1D4851','Bleu roi':'#318CE7','Bleu saphir':'#0131B4','Bleu sarcelle':'#008080','Bleu smalt':'#003399',\n",
    "             'Bleu tiffany':'#0ABAB5','Bleu turquin':'#425B8A','Cæruléum':'#26C4EC','Canard':'#048B9A','Cérulé':'#74D0F1','Cyan':'#00FFFF',\n",
    "             'Cyan':'#2BFAFA','Fumée':'#BBD2E1','Givré':'#80D0D0','Indigo':'#791CF8','Indigo':'#2E006C','Indigo du web':'#4B0082',\n",
    "             'Klein':'#002FA7','Klein':'#21177D','Lapis-lazuli':'#26619C','Lavande':'#9683EC','Pastel':'#56739A','Pervenche':'#CCCCFF',\n",
    "             'Turquoise':'#25FDE9','Blanc':'#FFFFFF','Albâtre':'#FEFEFE','Argile':'#EFEFEF','Azur brume':'#F0FFFF','Beige clair':'#F5F5DC',\n",
    "             'Blanc cassé':'#FEFEE2','Blanc céruse':'#FEFEFE','Blanc crème':'#FDF1B8',\"Blanc d'argent\":'#FEFEFE','Blanc de lait':'#FBFCFA',\n",
    "             'Blanc de lin':'#FAF0E6','Blanc de platine':'#FAF0C5','Blanc de plomb':'#FEFEFE','Blanc de Saturne':'#FEFEFE',\n",
    "             'Blanc de Troyes':'#FEFDF0','Blanc de Zinc':'#F6FEFE',\"Blanc d'Espagne\":'#FEFDF0',\"Blanc d'ivoire\":'#FFFFF4',\n",
    "             'Blanc écru':'#FEFEE0','Blanc lunaire':'#F4FEFE','Blanc neige':'#FEFEFE','Blanc opalin':'#F2FFFF','Blanc-bleu':'#FEFEFE',\n",
    "             \"Coquille d'oeuf\":'#FDE9E0','Cuisse de nymphe':'#FEE7F0','Brun':'#5B3C11','Acajou':'#88421D','Alezan':'#A76726',\n",
    "             'Ambre':'#F0C300','Auburn':'#9D3E0C','Basané':'#8B6C42','Beige':'#C8AD7F','Beige clair':'#F5F5DC','Beigeasse':'#AFA778',\n",
    "             'Bistre':'#3D2B1F','Bistre':'#856D4D','Bitume':'#4E3D28','Blet':'#5B3C11','Brique':'#842E1B','Bronze':'#614E1A',\n",
    "             'Brou de noix':'#3F2204','Bureau':'#6B5731','Cacao':'#614B3A','Cachou':'#2F1B0C','Café':'#462E01','Café au lait':'#785E2F',\n",
    "             'Cannelle':'#7E5835','Caramel':'#7E3300','Châtaigne':'#806D5A','Châtain':'#8B6C42','Chaudron':'#85530F','Chocolat':'#5A3A22',\n",
    "             'Citrouille':'#DF6D14','Fauve':'#AD4F09','Feuille-morte':'#99512B','Grège':'#BBAE98','Gris de maure':'#685E43',\n",
    "             'Lavallière':'#8F5922','Marron':'#582900','Mordoré':'#87591A','Noisette':'#955628','Orange brûlée':'#CC5500',\n",
    "             'Puce':'#4E1609','Rouge bismarck':'#A5260A','Rouge tomette':'#AE4A34','Rouille':'#985717','Sang de boeuf':'#730800',\n",
    "             'Senois':'#8D4024','Sépia':'#A98C78','Sépia':'#AE8964','Tabac':'#9F551E','Terre de Sienne':'#8E5434',\"Terre d'ombre\":'#625B48',\n",
    "             'Vanille':'#E1CE9A','Gris':'#606060','Ardoise':'#5A5E6B','Argent':'#CECECE','Argile':'#EFEFEF','Bis':'#766F64',\n",
    "             'Bistre':'#3D2B1F','Bistre':'#856D4D','Bitume':'#4E3D28','Céladon':'#83A697','Châtaigne':'#806D5A','Etain oxydé':'#BABABA',\n",
    "             'Etain pur':'#EDEDED','Fumée':'#BBD2E1','Grège':'#BBAE98','Gris acier':'#AFAFAF','Gris anthracite':'#303030',\n",
    "             'Gris de Payne':'#677179','Gris fer':'#848484','Gris Fer':'#7F7F7F','Gris Perle':'#CECECE','Gris Perle':'#C7D0CC',\n",
    "             'Gris souris':'#9E9E9E','Gris tourterelle':'#BBACAC','Mastic':'#B3B191','Pinchard':'#CCCCCC','Plomb':'#798081',\n",
    "             'Rose Mountbatten':'#997A8D','Taupe':'#463F32','Tourdille':'#C1BFB1','Jaune':'#FFFF00','Ambre':'#F0C300','Aurore':'#FFCB60',\n",
    "             'Beurre':'#F0E36B','Beurre frais':'#FFF48D','Blé':'#E8D630','Blond':'#E2BC74',\"Boutton d'or\":'#FCDC12','Bulle':'#EDD38C',\n",
    "             \"Caca d'oie\":'#CDCD0D','Chamois':'#D0C07A','Champagne':'#FBF2B7','Chrome':'#EDFF0C','Chrome':'#FFFF05',\n",
    "             'Citron':'#F7FF3C','Fauve':'#AD4F09','Flave':'#E6E697','Fleur de soufre':'#FFFF6B','Gomme-gutte':'#EF9B0F',\n",
    "             'Jaune auréolin':'#EFD242','Jaune banane':'#D1B606','Jaune canari':'#E7F00D','Jaune chartreuse':'#DFFF00',\n",
    "             'Jaune de cobalt':'#FDEE00','jaune de Naples':'#FFF0BC',\"Jaune d'or\":'#EFD807','Jaune impérial':'#FFE436',\n",
    "             'Jaune mimosa':'#FEF86C','Jaune moutarde':'#C7CF00','Jaune nankin':'#F7E269','Jaune olive':'#808000',\n",
    "             'Jaune paille':'#FEE347','Jaune poussin':'#F7E35F','Maïs':'#FFDE75','Mars':'#EED153','Mastic':'#B3B191','Miel':'#DAB30A',\n",
    "             'Ocre jaune':'#DFAF2C','Ocre rouge':'#DD985C','Or':'#FFD700','Orpiment':'#FCD21C','Poil de chameau':'#B67823',\n",
    "             'Queue de vache':'#C3B470','Queue de vache':'#A89874','Sable':'#E0CDA9','Safran':'#F4C430','Soufre':'#FFFF6B','Topaze':'#FAEA73',\n",
    "             'Vanille':'#E1CE9A','Vénitien':'#E7A854','Noir':'#000000','Aile de corbeau':'#000000','Brou de noix':'#3F2204','Cassis':'#2C030B',\n",
    "             'Cassis':'#3A020D','Dorian':'#0B1616','Ebène':'#000000','Noir animal':'#000000','Noir charbon':'#000000',\n",
    "             \"Noir d'aniline\":'#120D16','Noir de carbone':'#130E0A','Noir de fumée':'#130E0A','Noir de jais':'#000000',\"Noir d'encre\":'#000000',\n",
    "             \"Noir d'ivoire\":'#000000','Noiraud':'#2F1E0E','Réglisse':'#2D241E','Orange':'#ED7F10','Abricot':'#E67E30','Aurore':'#FFCB60',\n",
    "             'Bis':'#F1E2BE','Bisque':'#FFE4C4','Carotte':'#F4661B','Citrouille':'#DF6D14','Corail':'#E73E01','Cuivre':'#B36700',\n",
    "             'Gomme-gutte':'#EF9B0F','Mandarine':'#FEA347','Melon':'#DE9816','Orangé':'#FAA401','Orange brûlée':'#CC5500','Roux':'#AD4F09',\n",
    "             'Safran':'#F3D617','Saumon':'#F88E55','Tangerine':'#FF7F00','Tanné':'#A75502','Vanille':'#E1CE9A','Ventre de biche':'#E9C9B1',\n",
    "             'Rose':'#FD6C9E','Bisque':'#FFE4C4','Cerise':'#DE3163','Chair':'#FEC3AC',\"Coquille d'oeuf\":'#FDE9E0',\n",
    "             'Cuisse de nymphe':'#FEE7F0','Framboise':'#C72C48','Fushia':'#FD3F92','Héliotrope':'#DF73FF','Incarnadin':'#FE96A0','Magenta':'#FF00FF',\n",
    "             'Magenta foncé':'#800080','Magenta fushia':'#DB0073','Mauve':'#D473D4','Pêche':'#FDBFB7','Rose balais':'#C4698F','Rose bonbon':'#F9429E',\n",
    "             'Rose dragée':'#FEBFD2','Rose Mountbatten':'#997A8D','Rose thé':'#FF866A','Rose vif':'#FF007F','Saumon':'#F88E55','Rouge':'#FF0000',\n",
    "             'Amarante':'#91283B','Bordeaux':'#6D071A','Brique':'#842E1B','Cerise':'#BB0B0B','Corail':'#E73E01','Ecarlate':'#ED0000','Fraise':'#BF3030',\n",
    "             'Fraise écrasée':'#A42424','Framboise':'#C72C48','Fushia':'#FD3F92','Grenadine':'#E9383F','Grenat':'#6E0B14','Incarnadin':'#FE96A0',\n",
    "             'Incarnat':'#FF6F7D','Magenta':'#FF00FF','Magenta foncé':'#800080','Magenta fushia':'#DB0073','Mauve':'#D473D4','Nacarat':'#FC5D5D',\n",
    "             'Ocre rouge':'#DD985C','Passe-velours':'#91283B','Pourpre':'#9E0E40','Prune':'#811453','Rose vif':'#FF007F','Rouge alizarine':'#D90115',\n",
    "             'Rouge anglais':'#F7230C','Rouge bismarck':'#A5260A','Rouge bourgogne':'#6B0D0D','Rouge capucine':'#FF5E4D','Rouge cardinal':'#B82010',\n",
    "             'Rouge carmin':'#960018','Rouge cinabre':'#DB1702','Rouge cinabre':'#FD4626','Rouge coquelicot':'#C60800','Rouge cramoisi':'#960018',\n",
    "             'Rouge cramoisi':'#DC143C',\"Rouge d'Andrinople\":'#A91101',\"Rouge d'aniline\":'#EB0000','Rouge de falun':'#801818','Rouge de mars':'#F7230C',\n",
    "             'Rouge écrevisse':'#BC2001','Rouge feu':'#FE1B00','Rouge feu':'#FF4901','Rouge garance':'#EE1010','Rouge groseille':'#CF0A1D',\n",
    "             'Rouge ponceau':'#C60800','Rouge rubis':'#E0115F','Rouge sang':'#850606','Rouge tomate':'#DE2916','Rouge tomette':'#AE4A34',\n",
    "             'Rouge turc':'#A91101','Rouge vermillon':'#DB1702','Rouge vermillon':'#FD4626','Rouge-violet':'#C71585','Rouille':'#985717',\n",
    "             'Sang de boeuf':'#730800','Senois':'#8D4024','Terracotta':'#CC4E5C','Vermeil':'#FF0921','Zizolin':'#6C0277','Vert':'#00FF00',\n",
    "             'Aigue-marine':'#79F8F8','Asperge':'#7BA05B','Bleu sarcelle':'#008E8E','Canard':'#048B9A','Céladon':'#83A697','Givré':'#80D0D0',\n",
    "             'Glauque':'#649B88','Hooker':'#1B4F08','Jade':'#87E990','Kaki':'#94812B','Menthe':'#16B84E','Vert anglais':'#18391E','Vert anis':'#9FE855',\n",
    "             \"Menthe à l'eau\":'#54F98D','Sinople':'#149414','Turquoise':'#25FDE9','Vert absinthe':'#7FDD4C','Vert amande':'#82C46C',\n",
    "             'Vert avocat':'#568203','Vert bouteille':'#096A09','Vert chartreuse':'#C2F732','Vert citron':'#00FF00','Vert de chrome':'#18391E',\n",
    "             'Vert de gris':'#95A595','Vert de vessie':'#22780F',\"Vert d'eau\":'#B0F2B6','Vert émeraude':'#01D758','Vert empire':'#00561B',\n",
    "             'Vert épinard':'#175732','Vert gazon':'#3A9D23','Vert impérial':'#00561B','Vert kaki':'#798933','Vert lichen':'#85C17E','Vert lime':'#9EFD38',\n",
    "             'Vert malachite':'#1FA055','Vert mélèse':'#386F48','Vert militaire':'#596643','Vert mousse':'#679F5A','Vert olive':'#708D23',\n",
    "             'Vert opaline':'#97DFC6','Vert perroquet':'#3AF24B','Vert pin':'#01796F','Vert pistache':'#BEF574','Vert poireau':'#4CA66B',\n",
    "             'Vert pomme':'#34C924','Vert prairie':'#57D53B','Vert prasin':'#4CA66B','Vert printemps':'#00FE7E','Vert sapin':'#095228',\n",
    "             'Vert sauge':'#689D71','Vert smaragdin':'#01D758','Vert tilleul':'#A5D152','Vert véronèse':'#586F2D',\n",
    "             'Vert viride':'#40826D','Violet':'#660099','Améthyste':'#884DA7','Aubergine':'#370028','Bleu persan':'#6600FF','Byzantin':'#BD33A4',\n",
    "             'Byzantium':'#702963','Cerise':'#DE3163','Colombin':'#6A455D','Fushia':'#FD3F92','Glycine':'#C9A0DC','Gris de lin':'#D2CAEC','Héliotrope':'#DF73FF',\n",
    "             'Indigo':'#791CF8','Indigo':'#2E006C','Indigo du web':'#4B0082','Lavande':'#9683EC','Lie de vin':'#AC1E44','Lilas':'#B666D2',\n",
    "             'Magenta':'#FF00FF','Magenta foncé':'#800080','Magenta fushia':'#DB0073','Mauve':'#D473D4','Orchidée':'#DA70D6',\n",
    "             'Parme':'#CFA0E9','Pourpre':'#9E0E40','Prune':'#811453','Rose bonbon':'#F9429E','Rose vif':'#FF007F',\n",
    "             'Rouge-violet':'#C71585',\"Violet d'évêque\":'#723E64','Violine':'#A10684','Zizolin':'#6C0277'}\n",
    "\n",
    "#colour_com=[]\n",
    "#for k,v in colour_dict.items():\n",
    "#    colour_dict[k]=v[:7]\n",
    "#    colour_com=colour_com+[k]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "prescribed-merit",
   "metadata": {},
   "source": [
    "colour_com"
   ]
  },
  {
   "cell_type": "raw",
   "id": "sticky-blackberry",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "def build_lexicon(path=None, kind_list=None, df_dict=None, desc_col='Description', kw_com=[], auto=True):\n",
    "    \"\"\"\n",
    "    Generate a lexicon from lithological descriptions\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    path: str\n",
    "        root dir from which CSV files (also in subdirs) containing lithological description will be retrieve\n",
    "    kind_list : list\n",
    "        list of lexicon thematic ['lithology','material','colour']. Default is ['lithology']\n",
    "    desc_col : str\n",
    "        name of the dataframe column that contains descriptions\n",
    "    kw_com: list\n",
    "        list of common keywords to be considered for lexicon generation\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    \n",
    "    \"\"\"\n",
    "    assert isinstance(path, str), \"Expected a str for parameter *path*!\"\n",
    "    assert isinstance(kind_list, list), \"Expected a list for parameter *kind*!\"\n",
    "    assert isinstance(desc_col, str), \"Expected a str for parameter *desc_col*!\"\n",
    "    assert isinstance(kw_com, list), \"Expected a list for parameter *kw_com*!\"\n",
    "   \n",
    "    #--------------------------- Processing ------------------------------------------\n",
    "    def process(kind_list):\n",
    "        flag=re.IGNORECASE\n",
    "        kw, desc=[], []\n",
    "        litho_lex, mat_lex, sep_lex, colour_lex=[], [], [], []\n",
    "        #litho_com, mat_com, sep_com, colour_com=[], [], [], [] #must be imported from a file.py\n",
    "        filter_lex=[]\n",
    "\n",
    "        lex={'lithology':litho_lex, 'material':mat_lex, 'separator':sep_lex, 'colour':colour_lex, } # generated from the processing\n",
    "        com={'lithology':litho_com, 'material':mat_com, 'separator':sep_com,  'colour':colour_lex,} # manualy build to contain default values\n",
    "        kind_def=['lithology', 'material', 'separator', 'colour']\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            if not pd.isnull(df.loc[i, desc_col]): kw=kw+df.loc[i, desc_col].split(' ')\n",
    "        kw=list(set(kw))\n",
    "\n",
    "        for i in range(len(kw)):\n",
    "            if len(kw[i])>2 and not re.search('\\d.*',kw[i]): #to eliminate all 'one letter words' and all numbers\n",
    "                wlist=[re.sub(\"\\.|l'|d'\",\"\",kw[i]).rstrip('[.|...|,|;|(|)|?]').lstrip('?|(|+').replace(',…',\"\")]\n",
    "                desc=desc+wlist\n",
    "        desc=list(set(desc))\n",
    "\n",
    "        if kind_list==['all']:\n",
    "            kind_list=kind_def\n",
    "                \n",
    "        for kind in kind_list:\n",
    "            print(kind)\n",
    "            if kind=='lithology': \n",
    "                tmp_lex=lex['lithology']\n",
    "                if len(kw_com)==0: tmp_com=com['lithology']\n",
    "                else: tmp_com=kw_com\n",
    "\n",
    "            elif kind=='colour':\n",
    "                tmp_lex=lex['colour']\n",
    "                if len(kw_com)==0: tmp_com=com['colour']\n",
    "                else: tmp_com=kw_com\n",
    "\n",
    "            elif kind=='material':\n",
    "                tmp_lex=lex['material']\n",
    "                if len(kw_com)==0: tmp_com=com['material']\n",
    "                else: tmp_com=kw_com\n",
    "                    \n",
    "            elif kind=='separator':\n",
    "                tmp_lex=lex['separator']\n",
    "                if len(kw_com)==0: tmp_com=com['separator']\n",
    "                else: tmp_com=kw_com\n",
    "\n",
    "            elif kind not in kind_def: \n",
    "                print(\"Parameter *kind* must be 'lithology' or compatible str : see docstring !\")\n",
    "\n",
    "            for v in tmp_com: \n",
    "                w=v.rstrip('[e|es]')\n",
    "                if kind=='colour':\n",
    "                    r=re.compile(\"^{:s}(e|es|s)?[-/]*(.*[â|a]tre)?$\".format(w), flags=flag)\n",
    "                else:\n",
    "                    r=re.compile(\"^{:s}(e|es|o)?(-|/)*(.*eu)?(x|se|ses)?$\".format(w), flags=flag)\n",
    "                tmp_lex=tmp_lex+list(filter(r.match, desc))\n",
    "\n",
    "            for l in tmp_lex:\n",
    "                w=l.capitalize()\n",
    "                if w not in filter_lex: filter_lex=filter_lex+[w]\n",
    "\n",
    "            if kind=='lithology': \n",
    "                litho_lex=filter_lex\n",
    "            elif kind=='colour':\n",
    "                colour_lex=filter_lex\n",
    "            elif kind=='material':\n",
    "                mat_lex=filter_lex\n",
    "            elif kind=='separator':\n",
    "                sep_lex=filter_lex\n",
    "\n",
    "            #print(f\"{len(desc)} total keywords found\")\n",
    "            print(f\"|>>> Processing for '{kind}' : {len(filter_lex)} keywords extracted\")\n",
    "        \n",
    "        print('\\n',filter_lex,'\\n')\n",
    "        return #filter_lex\n",
    "    #------------------------------------------------------------------------------------------\n",
    "    if auto and path is not None:\n",
    "        flist, df_list = [], []\n",
    "\n",
    "        for path, dirs, files in walk(mydir):\n",
    "            for f in files:\n",
    "                if f[0]!='.' and re.compile(r\".+[L|l]ith.+\\.csv\").match(f) and f is not None:\n",
    "                    p=path+\"/\"+f\n",
    "                    flist.append('{}'.format(p))\n",
    "                    df_list.append(pd.read_csv('{}'.format(p)))\n",
    "\n",
    "        df_dict=dict(list(enumerate(df_list))) #dict(zip(keys, values)) where key=range(len(df_list))\n",
    "    \n",
    "    elif not auto and df_dict is not None: pass \n",
    "    else: pass\n",
    "    \n",
    "    if not isinstance(df_dict, type(None)):\n",
    "        for nb, df in df_dict.items():\n",
    "            print(f\"keywords extraction and filtering from '{flist[nb].replace(mydir,'')}' ...\")\n",
    "            #lexicon=process()\n",
    "            process(kind_list)\n",
    "\n",
    "    #return #df_list#desc#lexicon"
   ]
  },
  {
   "cell_type": "raw",
   "id": "wired-despite",
   "metadata": {},
   "source": [
    "def update_lexicon(legend=None, timescale=None, svg=None, src='en', dest='fr'):\n",
    "    trans=google_translator()\n",
    "    \n",
    "    leg_name = {1:'Canstrat', 2:'NAGMDM__6_1', 3:'NAGMDM__6_2', 4:'NSDOE', 5:'SGMC'} #6:'NAGMDM__4_3' #(issue) \n",
    "    time_name = {1:'DNAG', 2:'ISC', 3:'USGS_ISC'}\n",
    "    #lex_head=['lithology','modifier', 'amount', 'grainsize', 'colour', 'synonyms', 'splitters', 'parts_of_speech']\n",
    "    \n",
    "    if svg is None: \n",
    "        svg=f'default_Lexicon_{dest.upper()}.py'\n",
    "        \n",
    "    if legend is None:\n",
    "        print('Process with all legends known !')\n",
    "        legend=[1,2,3,4,5]\n",
    "\n",
    "    if timescale is None:\n",
    "        print('Process with all timescales known !')\n",
    "        timescale=[1,2,3]\n",
    "\n",
    "    #------------------------- writting file.py -----------------\n",
    "    leg, time = 0,0\n",
    "\n",
    "    with open(svg, 'w+') as f:\n",
    "        f.write(f'\"\"\"\\nDefinition de quelques valeurs par défault pour les descriptions de cuttings.\\n'+\n",
    "        ':copyright: 2015 Agile Geoscience\\n:license: Apache 2.0\\n:Traduction: N.Y.H \\n\"\"\"')\n",
    "\n",
    "        f.write(f'\\n\\n# =========== LEGENDES ===========\\n')\n",
    "        for n in legend:\n",
    "            if isinstance(n, int) and n in leg_name.keys(): \n",
    "                f.write(f'\\n# {leg_name[n]}\\n')\n",
    "                f.write(f'{leg_name[n]}_LEGEND = \"\"\"colour,width,component lithology\\n')\n",
    "                print(f'|__ {leg_name[n]} Legend processing ...')\n",
    "                leg = Legend.default(name=leg_name[n])\n",
    "                for i in range(len(leg)):\n",
    "                    w = trans.translate(leg[i].component.lithology, lang_src=src, lang_tgt=dest) \n",
    "                    f.write(f'{leg[i].colour},None,{w},\\n')\n",
    "                f.write(f'\"\"\"\\n')\n",
    "\n",
    "            elif isinstance(n, Legend):\n",
    "                for d in n:\n",
    "                    f.write(f'\\n# {n}\\n')\n",
    "                    f.write(f'{n}_LEGEND = \"\"\"colour,width,component lithology\\n')\n",
    "\n",
    "                    for i in range(len(n)):\n",
    "                        w = trans.translate(n[d].component.lithology, lang_src=src, lang_tgt=dest) \n",
    "                        f.write(f'{n[i].colour},None,{w},\\n')\n",
    "                    f.write(f'\"\"\"\\n')\n",
    "            else: \n",
    "                print(\"Error! param 'legend' must be a 'int' [1-6] or a 'Striplog.legend.Legend' object\")\n",
    "\n",
    "\n",
    "        f.write(f'\\n\\n# =========== ECHELLES DES TEMPS ===========\\n')\n",
    "\n",
    "        for n in timescale:\n",
    "            if isinstance(n, int) and n in time_name.keys(): \n",
    "                f.write(f'\\n# {time_name[n]}\\n')\n",
    "                f.write(f'{time_name[n]}_TIMESCALE = \"\"\"colour,width,component age\\n')\n",
    "                print(f'|__ {time_name[n]} Timescale processing ...')\n",
    "                time = Legend.default_timescale(name=time_name[n])\n",
    "                for i in range(len(time)):\n",
    "                    w = trans.translate(time[i].component.age, lang_src=src, lang_tgt=dest) \n",
    "                    f.write(f'{time[i].colour},None,{w},\\n')\n",
    "                f.write(f'\"\"\"\\n')\n",
    "\n",
    "            elif isinstance(n, Decor):\n",
    "                for d in n:\n",
    "                    f.write(f'\\n# {n}\\n')\n",
    "                    f.write(f'{n}_TIMESCALE = \"\"\"colour,width,component age\\n')\n",
    "\n",
    "                    for i in range(len(n)):\n",
    "                        w = trans.translate(n[d].component.age, lang_src=src, lang_tgt=dest) \n",
    "                        f.write(f'{n[i].colour},None,{w},\\n')\n",
    "                    f.write(f'\"\"\"\\n')\n",
    "            else: \n",
    "                print(\"Error! param 'timescale' must be a 'int' [1-3] or a 'Striplog.legend.Decor' object\")\n",
    "\n",
    "\n",
    "        f.write(f'\\n\\n# =========== LEXIQUE ===========\\n')\n",
    "        f.write(f'LEXICON = {LEXIQUE}')\n",
    "        \n",
    "        f.write(f'\\n\\n# =========== COULEURS ===========\\n')\n",
    "        f.write(f'COLORS = {COLOURS}')\n",
    "\n",
    "        \n",
    "    # we can also modify the 'file.py' file directly if we want (to correct some translations)\n",
    "    #TODO: try to choose hatch according to the lithology with a dict or random function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "actual-gasoline",
   "metadata": {},
   "source": [
    "def build_lexicon(df, kind=None, desc_col='Description', kw_com=[]):\n",
    "    \"\"\"\n",
    "    Generate a lexicon from lithological descriptions\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    df: Pandas.Dataframe\n",
    "        The dataframe containing a descriptions' column\n",
    "    kind : str\n",
    "        the kind of lexicon to generate ('lithology','material','colour'). Default is 'lithology'\n",
    "    desc_col : str\n",
    "        name of the dataframe column that contains descriptions\n",
    "    kw_com: list\n",
    "        list of common keywords to be considered for lexicon generation\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    \n",
    "    \"\"\"\n",
    "    assert isinstance(df, pd.DataFrame), \"Expected a Dataframe for parameter *df*!\"\n",
    "    assert isinstance(kind, str), \"Expected a str for parameter *kind*!\"\n",
    "    assert isinstance(desc_col, str), \"Expected a str for parameter *desc_col*!\"\n",
    "    assert isinstance(kw_com, list), \"Expected a list for parameter *kw_com*!\"\n",
    "    \n",
    "    flag=re.IGNORECASE\n",
    "    kw, desc=[], []\n",
    "    litho_lex, mat_lex, sep_lex=[], [], []\n",
    "    litho_com, mat_com, sep_com=[], [], []\n",
    "    filter_lex=[]\n",
    "    \n",
    "    \n",
    "    lex={'lithology':litho_lex, 'material':mat_lex, 'separator':sep_lex, } # generated from the processing\n",
    "    com={'lithology':litho_com, 'material':mat_com, 'separator':sep_com, } # manualy build to contain default values\n",
    "    kind_list=['lithology', 'material', 'separator']\n",
    "    \n",
    "    print('Extraction and keywords filtering from column',desc_col,'...\\n')\n",
    "    for i in range(len(df)):\n",
    "        if not pd.isnull(df.loc[i, desc_col]): kw=kw+df.loc[i, desc_col].split(' ')\n",
    "    kw=list(set(kw))\n",
    "    \n",
    "    for i in range(len(kw)):\n",
    "        if len(kw[i])>2 and not re.search('\\d.*',kw[i]): #to eliminate all 'one letter words' and all numbers\n",
    "            wlist=[re.sub(\"\\.|l'|d'\",\"\",kw[i]).rstrip('[.|...|,|;|(|)|?]').lstrip('?|(|+').strip(',…')]\n",
    "            desc=desc+wlist\n",
    "    desc=list(set(desc))\n",
    "    \n",
    "    if kind=='lithology': \n",
    "        tmp_lex=lex['lithology']\n",
    "        if len(kw_com)==0: tmp_com=com['lithology']\n",
    "        else: tmp_com=kw_com\n",
    "            \n",
    "    elif kind=='material':\n",
    "        tmp_lex=lex['material']\n",
    "        if len(kw_com)==0: tmp_com=com['material']\n",
    "        else: tmp_com=kw_com\n",
    "    \n",
    "    for v in tmp_com: \n",
    "        w=v.rstrip('[e|es]')\n",
    "        r=re.compile(\"^{:s}(e|es|o)?(.*eu)?(x|se|ses)?$\".format(w), flags=flag) #\n",
    "        tmp_lex=tmp_lex+list(filter(r.match, desc))\n",
    "\n",
    "    for l in tmp_lex:\n",
    "        w=l.capitalize()\n",
    "        if w not in filter_lex: filter_lex=filter_lex+[w]\n",
    "    \n",
    "    if kind not in kind_list: \n",
    "        print(\"Parameter *kind* must be 'lithology' or compatible str : see docstring !\")\n",
    "        \n",
    "    if kind=='lithology': \n",
    "        litho_lex=filter_lex\n",
    "    elif kind=='material':\n",
    "        mat_lex=filter_lex\n",
    "    \n",
    "    print(f\"{len(desc)} keywords found!\")\n",
    "    print(f\"{len(filter_lex)} keywords extracted for '{kind}'\\n\")\n",
    "    \n",
    "    return filter_lex"
   ]
  },
  {
   "cell_type": "raw",
   "id": "interior-suspect",
   "metadata": {},
   "source": [
    "def translate_legend(legend=None, timescale=None, svg=None, src='en', dest='fr'):\n",
    "    trans=google_translator()\n",
    "    \n",
    "    leg_name = {1:'Canstrat', 2:'NAGMDM__6_1', 3:'NAGMDM__6_2', 4:'NSDOE', 5:'SGMC'} #6:'NAGMDM__4_3' #(issue) \n",
    "    time_name = {1:'DNAG', 2:'ISC', 3:'USGS_ISC'}\n",
    "    #lex_head=['lithology','modifier', 'amount', 'grainsize', 'colour', 'synonyms', 'splitters', 'parts_of_speech']\n",
    "    \n",
    "    if svg is None: \n",
    "        svg=f'default_Lexicon_{dest.upper()}.py'\n",
    "        \n",
    "    if legend is None:\n",
    "        print('Process with all legends known !')\n",
    "        legend=[1,2,3,4,5]\n",
    "\n",
    "    if timescale is None:\n",
    "        print('Process with all timescales known !')\n",
    "        timescale=[1,2,3]\n",
    "\n",
    "    #------------------------- writting file.py -----------------\n",
    "    leg, time = 0,0\n",
    "\n",
    "    with open(svg, 'w+') as f:\n",
    "        f.write(f'\"\"\"\\nDefinition de quelques valeurs par défault pour les descriptions de cuttings.\\n'+\n",
    "        ':copyright: 2015 Agile Geoscience\\n:license: Apache 2.0\\n:Traduction: N.Y.H \\n\"\"\"')\n",
    "\n",
    "        f.write(f'\\n\\n# =========== LEGENDES ===========\\n')\n",
    "        for n in legend:\n",
    "            if isinstance(n, int) and n in leg_name.keys(): \n",
    "                f.write(f'\\n# {leg_name[n]}\\n')\n",
    "                f.write(f'{leg_name[n]}_LEGEND = \"\"\"colour,width,component lithology\\n')\n",
    "                print(f'|__ {leg_name[n]} Legend processing ...')\n",
    "                leg = Legend.default(name=leg_name[n])\n",
    "                for i in range(len(leg)):\n",
    "                    w = trans.translate(leg[i].component.lithology, lang_src=src, lang_tgt=dest) \n",
    "                    f.write(f'{leg[i].colour},None,{w},\\n')\n",
    "                f.write(f'\"\"\"\\n')\n",
    "\n",
    "            elif isinstance(n, Legend):\n",
    "                for d in n:\n",
    "                    f.write(f'\\n# {n}\\n')\n",
    "                    f.write(f'{n}_LEGEND = \"\"\"colour,width,component lithology\\n')\n",
    "\n",
    "                    for i in range(len(n)):\n",
    "                        w = trans.translate(n[d].component.lithology, lang_src=src, lang_tgt=dest) \n",
    "                        f.write(f'{n[i].colour},None,{w},\\n')\n",
    "                    f.write(f'\"\"\"\\n')\n",
    "            else: \n",
    "                print(\"Error! param 'legend' must be a 'int' [1-6] or a 'Striplog.legend.Legend' object\")\n",
    "\n",
    "\n",
    "        f.write(f'\\n\\n# =========== ECHELLES DES TEMPS ===========\\n')\n",
    "\n",
    "        for n in timescale:\n",
    "            if isinstance(n, int) and n in time_name.keys(): \n",
    "                f.write(f'\\n# {time_name[n]}\\n')\n",
    "                f.write(f'{time_name[n]}_TIMESCALE = \"\"\"colour,width,component age\\n')\n",
    "                print(f'|__ {time_name[n]} Timescale processing ...')\n",
    "                time = Legend.default_timescale(name=time_name[n])\n",
    "                for i in range(len(time)):\n",
    "                    w = trans.translate(time[i].component.age, lang_src=src, lang_tgt=dest) \n",
    "                    f.write(f'{time[i].colour},None,{w},\\n')\n",
    "                f.write(f'\"\"\"\\n')\n",
    "\n",
    "            elif isinstance(n, Decor):\n",
    "                for d in n:\n",
    "                    f.write(f'\\n# {n}\\n')\n",
    "                    f.write(f'{n}_TIMESCALE = \"\"\"colour,width,component age\\n')\n",
    "\n",
    "                    for i in range(len(n)):\n",
    "                        w = trans.translate(n[d].component.age, lang_src=src, lang_tgt=dest) \n",
    "                        f.write(f'{n[i].colour},None,{w},\\n')\n",
    "                    f.write(f'\"\"\"\\n')\n",
    "            else: \n",
    "                print(\"Error! param 'timescale' must be a 'int' [1-3] or a 'Striplog.legend.Decor' object\")\n",
    "\n",
    "\n",
    "        f.write(f'\\n\\n# =========== LEXIQUE ===========\\n')\n",
    "        f.write(f'LEXICON = {LEXIQUE}')\n",
    "        \n",
    "        f.write(f'\\n\\n# =========== COULEURS ===========\\n')\n",
    "        f.write(f'COLORS = {COLOURS}')\n",
    "\n",
    "        \n",
    "    # we can also modify the 'file.py' file directly if we want (to correct some translations)\n",
    "    #TODO: try to choose hatch according to the lithology with a dict or random function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cardiac-cartoon",
   "metadata": {},
   "source": [
    "colour_dict={\"Abricot\" : \"#E67E30230126480457910267854\", \"Acajou\" : \"#88421D13666290517947216532\", \"Aigue-marine\" : \"#79F8F8121248248510031808972\", \"Alezan\" : \"#A76726167103380387735306340\", \"Amande\" : \"#82C46C13019610834045231054259\", \"Amarante\" : \"#91283B145405907259433495736\", \"Ambre\" : \"#F0C300240195001910064910047\", \"Améthyste\" : \"#884DA71367716719540352793748\", \"Anthracite\" : \"#303030484848000810019\", \"Aquilain\" : \"#AD4F091737990549532269036\", \"Argent\" : \"#FFFFFF255255255000000100\", \"Aubergine\" : \"#370028550400100277831610011\", \"Auburn\" : \"#9D3E0C15762120619238218633\", \"Aurore\" : \"#FFCB6025520396020620409969\", \"Avocat\" : \"#5682038613033409849819526\", \"Azur\" : \"#007FFF0127255100500021010050\", \"Baillet\" : \"#AE642D174100450437432265943\", \"Basané\" : \"#8B6C42139108660225345353640\", \"Beurre\" : \"#F0E36B24022710705556548268\", \"Bis\" : \"#766F6411811110006155437843\", \"Bisque\" : \"#FFE4C42552281960112303310088\", \"Bistre\" : \"#856D4D133109770184248342741\", \"Bitume\" : \"#4E3D287861400224969333223\", \"Blanc cassé\" : \"#FEFEE225425422600110609394\", \"Blanc lunaire\" : \"#F4FEFE24425425440001808398\", \"Blé\" : \"#E8D6302322144808799548055\", \"Bleu acier\" : \"#3A8EBA5814218669240272015248\", \"Bleu barbeau ou bleuet\" : \"#5472AE8411417452340322203651\", \"Bleu canard\" : \"#048B9A413915497100401869531\", \"Bleu céleste\" : \"#26C4EC381962368417071928454\", \"Bleu charrette\" : \"#8EA2C614216219828180222193367\", \"Bleu ciel\" : \"#77B5FE1191812545329002129973\", \"Bleu de cobalt\" : \"#22427C346612473470512195731\", \"Bleu de Prusse, de Berlin ou bleu hussard\" : \"#24445C36689261260642064425\", \"Bleu électrique\" : \"#2C75FF4411725583540021910059\", \"Bleu givré\" : \"#80D0D01282082083800181804666\", \"Bleu marine\" : \"#03224C3347696550702159215\", \"Bleu nuit\" : \"#0F056B15510786950582469122\", \"Bleu outremer\" : \"#00478700711351004704720810053\", \"Bleu paon\" : \"#067790611914496170441919229\", \"Bleu persan\" : \"#4E63CE789920662520192306281\", \"Bleu pétrole\" : \"#1D485129728164110681904722\", \"Bleu roi ou de France\" : \"#318CE7491402317939092107955\", \"Bleu turquin\" : \"#425B8A669113852340462193540\", \"Blond vénitien\" : \"#E7A85423116884027649347562\", \"Blond\" : \"#E2BC742261881160174911396567\", \"Bouton d'or\" : \"#FCDC1225222018013931529853\", \"Brique\" : \"#842E1B13246270658048116631\", \"Bronze\" : \"#614E1A9778260207362445824\", \"Brou de noix\" : \"#3F2204633440469475318813\", \"Caca d'oie\" : \"#CDCD0D20520513009420608843\", \"Cacao\" : \"#614B3A9775580234062262530\", \"Cachou\" : \"#2F1B0C4727120437482265912\", \"Cæruleum\" : \"#357AB75312218371330282085546\", \"Café\" : \"#462E01704610349973399714\", \"Café au lait\" : \"#785E2F12094470226153394433\", \"Cannelle\" : \"#7E583512688530305851294135\", \"Capucine\" : \"#FF5E4D2559477063700610065\", \"Caramel\" : \"#7E3300126510060100512410025\", \"Carmin\" : \"#9600181500240100844135010029\", \"Carotte\" : \"#F4661B24410227058894219153\", \"Chamois\" : \"#D0C07A208192122084118494865\", \"Chartreuse\" : \"#7FFF00127255050010009010050\", \"Châtain\" : \"#8B6C42139108660225345353640\", \"Chaudron\" : \"#85530F13383150388948358029\", \"Chocolat\" : \"#5A3A229058340366265264524\", \"Cinabre\" : \"#DB1702219232089991469843\", \"Citrouille\" : \"#DF6D14223109200519113268448\", \"Coquille d'œuf\" : \"#FDE9E025323322408111198894\", \"Corail\" : \"#E73E012316210731009169945\", \"Cramoisi\" : \"#DC143C220206009173143488347\", \"Cuisse de nymphe\" : \"#FEE7F025423124009603379295\", \"Cuivre\" : \"#B367001791030042100303510035\", \"Cyan\" : \"#2BFAFA43250250830021809557\", \"Écarlate\" : \"#ED00002370001001007010046\", \"Écru\" : \"#FEFEE025425422400120609494\", \"Émeraude\" : \"#00815F0129951000264916410051\", \"Fauve\" : \"#AD4F091737990549532269036\", \"Flave\" : \"#E6E697230230151003410606175\", \"Fraise\" : \"#BF30301914848075752506047\", \"Fraise écrasée\" : \"#A424241643636078783606439\", \"Framboise\" : \"#C72C48199447207864223496448\", \"Fuchsia\" : \"#FD3F92253631460754213347562\", \"Fumée\" : \"#BBD2E11872102251770122043981\", \"Garance\" : \"#EE1010238161609393708750\", \"Glauque\" : \"#649B8810015513635012391592250\", \"Glycine\" : \"#C9A0DC2011602209270142814675\", \"Grège\" : \"#BBAE98187174152071927382066\", \"Grenadine\" : \"#E9383F23356630767393588057\", \"Grenat\" : \"#6E0B14110112009082573558224\", \"Gris acier\" : \"#AFAFAF175175175000310069\", \"Gris de Payne\" : \"#677179103113121157053207844\", \"Gris fer\" : \"#7F7F7F127127127000500050\", \"Gris perle\" : \"#CECECE206206206000190081\", \"Gris souris\" : \"#9E9E9E158158158000380062\", \"Groseille\" : \"#CF0A1D207102909586193549143\", \"Gueules\" : \"#E213132261919092921108448\", \"Héliotrope\" : \"#DF73FF22311525513550028610073\", \"Incarnat\" : \"#FF6F7D25511112505651035410072\", \"Indigo\" : \"#791CF8121282488951032659454\", \"Indigo\" : \"#2E006C4601085710005826610021\", \"Isabelle\" : \"#FEA7772541671190345302153100\", \"Jaune canari\" : \"#E7F00D2312401340956629050\", \"Jaune citron\" : \"#F7FF3C24725560307606210062\", \"Jaune d'or\" : \"#EFD8072392167010976549448\", \"Jaune de cobalt\" : \"#FDEE002532380061000569099\", \"Jaune de Mars\" : \"#EED15323820983012657498263\", \"Jaune de Naples\" : \"#FFF0BC255240188062604710087\", \"Jaune impérial\" : \"#FFE436255228540117905210061\", \"Jaune mimosa\" : \"#FEF86C25424810802570589971\", \"Lapis-lazuli\" : \"#26619C389715676380392106138\", \"Lavallière\" : \"#8F592214389340387644306235\", \"Lavande\" : \"#9683EC1501312363644072517372\", \"Lie de vin\" : \"#AC1E44172306808360333447040\", \"Lilas\" : \"#B666D218210221013510182845561\", \"Lime ou vert citron\" : \"#9EFD3815825356380781899861\", \"Lin\" : \"#FAF0E62502402300482306794\", \"Magenta\" : \"#FF00FF255025501000030010050\", \"Maïs\" : \"#FFDE752552221170135404610073\", \"Malachite\" : \"#1FA055311608581047371456837\", \"Mandarine\" : \"#FEA34725416371036720309964\", \"Marron\" : \"#58290088410053100652810017\", \"Mastic\" : \"#B3B191179177145011930561864\", \"Mauve\" : \"#D473D42121152120460173005364\", \"Menthe\" : \"#16B84E221847888058281417940\", \"Moutarde\" : \"#C7CF00199207040100196210041\", \"Nacarat\" : \"#FC5D5D252939306363106399\", \"Nankin\" : \"#F7E26924722610509573519069\", \"Noisette\" : \"#95562814986400427342255837\", \"Ocre jaune\" : \"#DFAF2C223175440228013447452\", \"Ocre rouge\" : \"#DD985C221152920315813286561\", \"Olive\" : \"#708D23112141352107545766035\", \"Or\" : \"#FFD700255215001610005110050\", \"Orange brûlé\" : \"#CC5500204850058100202510040\", \"Orchidée\" : \"#DA70D62181122140492153025965\", \"Orpiment\" : \"#FCD21C25221028017891499755\", \"Paille\" : \"#FEE34725422771011720519964\", \"Parme\" : \"#CFA0E92071602331131092796277\", \"Pelure d'oignon\" : \"#D5849021313214403832163514968\", \"Pervenche\" : \"#CCCCFF20420425520200024010090\", \"Pistache\" : \"#BEF574190245116220534868771\", \"Poil de chameau\" : \"#B67823182120350348129356843\", \"Ponceau ou Coquelicot\" : \"#C608001988009610022210039\", \"Pourpre\" : \"#9E0E40158146409159383398434\", \"Prasin\" : \"#4CA66B7616610754036351413747\", \"Prune\" : \"#811453129208308436493257329\", \"Puce\" : \"#4E1609782290728869117917\", \"Rose Mountbatten\" : \"#997A8D1531221410208403231354\", \"Rouge anglais\" : \"#F7230C247351208695369451\", \"Rouge cardinal\" : \"#B820101843216083912868439\", \"Rouge cerise\" : \"#BB0B0B1871111094942708939\", \"Rouge d'Andrinople\" : \"#A91101169171090993469933\", \"Rouge de Falun\" : \"#8018181282424081815006830\", \"Rouge feu\" : \"#FF490125573107110001710050\", \"Rouge indien\" : \"#CD5C5C20592920531582055\", \"Rouge sang\" : \"#85060613366095954809127\", \"Rouge tomette\" : \"#AE4A3417474520577032115444\", \"Rouille\" : \"#98571715287230438540307434\", \"Roux\" : \"#AD4F091737990549532269036\", \"Rubis\" : \"#E0115F224179509258123379288\", \"Sable\" : \"#E0CDA9224205169082512394777\", \"Sable\" : \"#0000000000000000\", \"Safre\" : \"#0131B414918099730292249935\", \"Sang de bœuf\" : \"#7308001158009310055410023\", \"Sanguine\" : \"#85060613366095954809127\", \"Saphir\" : \"#0131B414918099730292249935\", \"Sarcelle\" : \"#008080012812818010025118010050\", \"Saumon\" : \"#F88E5524814285043663219265\", \"Sépia\" : \"#AE89641741371000214332303154\", \"Sinople\" : \"#149414201482086086421207633\", \"Smalt\" : \"#0033990511531006704022010030\", \"Soufre\" : \"#FFFF6B255255107005806010071\", \"Tabac\" : \"#9F551E15985300478138266837\", \"Taupe\" : \"#463F327063500102973391724\", \"Terre d'ombre\" : \"#926D27146109390257343395836\", \"Tomate\" : \"#DE29162224122082901368248\", \"Topaze\" : \"#FAEA7325023411506542539372\", \"Tourterelle ou Colombin\" : \"#BBACAC1871721720882701070\", \"Turquoise\" : \"#25FDE937253233850811749857\", \"Vanille\" : \"#E1CE9A225206154083212445474\", \"Vermeil\" : \"#FF092125593309687035410052\", \"Vermillon\" : \"#DB1702219232089991469843\", \"Vert bouteille\" : \"#096A099106992092581208423\", \"Vert céladon\" : \"#83A6971311661512109351541658\", \"Vert d'eau\" : \"#B0F2B61762421822702551257282\", \"Vert de chrome\" : \"#18391E24573058047781314116\", \"Vert-de-gris\" : \"#95A5951491651491001035120862\", \"Vert de Hooker\" : \"#1B4F082779866090691048217\", \"Vert de vessie\" : \"#22780F341201572088531097826\", \"Vert émeraude ou Smaragdin\" : \"#366735541035348049601194940\", \"Vert épinard\" : \"#17573223875074043661455822\", \"Vert impérial\" : \"#00561B086271000696613910017\", \"Vert lichen\" : \"#85C17E13319312631035241143563\", \"Vert olive\" : \"#556B2F8510747823930282561\", \"Vert perroquet\" : \"#3AF24B58242757606951268859\", \"Vert poireau\" : \"#4CA66B7616610754036351413747\", \"Vert pomme\" : \"#34C924522013674082211147046\", \"Vert prairie\" : \"#57D53B872135959072161096553\", \"Vert printemps\" : \"#00FF7F0255127100050015010050\", \"Vert sapin\" : \"#0952289824089051681458018\", \"Vert sauge\" : \"#689D7110415711334028381302151\", \"Vert tilleul\" : \"#A5D152165209822106118815857\", \"Vert Véronèse\" : \"#5A652190101331106760705126\", \"Violet\" : \"#8806CE148021134970192839938\", \"Violet d'évêque\" : \"#723E641146210004612553163035\", \"Viride\" : \"#40826D6413010951016491613438\", \"Zinzolin\" : \"#6C027710821199980532949724\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
