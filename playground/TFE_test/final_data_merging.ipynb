{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-killing",
   "metadata": {},
   "source": [
    "# Final merge of memoris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import dataframe_viewer, files_search, data_merger, data_validation, data_overview, \\\n",
    "data_filter, fix_duplicates, gen_id_from_ech\n",
    "\n",
    "import re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dtm\n",
    "from definitions import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4574f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "sufx = ['sup', 'prof', 'inf', '/\\dM(\\*)?']\n",
    "prefx = ['eau forage ']\n",
    "id_reg = '\\s*(?P<id>(?:^canne |Piezair )*\\w*\\d+\\w*)\\s*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(files, verbose=True): # find another name for this function\n",
    "    \"\"\"\n",
    "    create dataframes from files and test if they contain position informations\n",
    "    files: list of files name\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    i = 0\n",
    "    for f in files:\n",
    "        i += 1\n",
    "        df = pd.read_csv(f, delimiter=',')\n",
    "        dfs.append(df)\n",
    "        \n",
    "        if verbose:\n",
    "            if 'X' in list(df.columns): msg = ' --> Coordinates'\n",
    "            else: msg = ' --> No coordinates'\n",
    "\n",
    "            print(f\"df{i} : {msg}\")\n",
    "            \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-noise",
   "metadata": {},
   "source": [
    "## Collecting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = ROOT_DIR+'/CF_data/Result_traitem/'\n",
    "save_dir = ROOT_DIR+'/CF_data/Fusion_finale/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my dictionary structure to retrieve good files (Keynames !!!)\n",
    "files_dict={'Borehole':0,'Litho':0,'Equipm':0,'Measure':0,'Sample':0,'Unknow':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-sensitivity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_search(work_dir, files_dict, prefix='source', details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "how=['inner', 'outer', 'left', 'right']\n",
    "view = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f6d75",
   "metadata": {},
   "source": [
    "# ================== PROCESSING  ===================== "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d22ec7",
   "metadata": {},
   "source": [
    "# Boreholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b1328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Borehole'\n",
    "dataset = pd.DataFrame() # for saving object info after last merging\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66512dac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33248c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c7a868",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a9105",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'Memoris_seafile/source_merge/source_Boreholes.csv' # 1\n",
    "file2= work_dir + 'Phase_1_Memoris/source_merge/source_Boreholes.csv' # 2\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb0026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73ea53",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6a70a0",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede67f61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'Phase_2_Memoris/source_merge/source_Boreholes.csv' # 3\n",
    "file2= work_dir + 'Prof_contact_sol_forage/source_merge/source_Boreholes.csv' # 4\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7dd6d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bc414",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dceb39",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f29aa4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'database_Memoris3/source_merge/source_Boreholes.csv' # 8\n",
    "file2= work_dir + 'donnees_terrain_2019/source_merge/source_Boreholes.csv' # 9\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afffbf2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3471a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'Type_y':list(conflict_df.index), 'Long_for_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aff8ef",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba0f518",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'profils_sols_donnees_forages/source_merge/source_Boreholes.csv' # 11\n",
    "file2= work_dir + 'vUmons_logsFor/source_merge/source_Boreholes.csv' # 13\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5df08d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619d8d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'Date_for_y':list(conflict_df.index), 'Type_y':list(conflict_df.index), \n",
    "                            'Long_for_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2b4376",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbaa65c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'Forage_Pilote/source_merge/source_Boreholes.csv' # 0\n",
    "file2= work_dir + 'Siterem_Ext_Pilote/source_merge/source_Boreholes.csv' # 5\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e8cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['ID'] = df2['ID'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ebe75b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc03af66",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ea8df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'Z_x':list(conflict_df.index), 'Type_x':list(conflict_df.index), \n",
    "                            'Long_for_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaea63c",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c83cd60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'Siterem_Pilote/source_merge/source_Boreholes.csv' # 6\n",
    "file2= work_dir + 'Siterem_Result_Sol/source_merge/source_Boreholes.csv' # 7\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9630c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa85d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'Long_pz_x':list(conflict_df.index), 'Type_x':list(conflict_df.index), \n",
    "                            'Long_for_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac9cde7",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70dd0c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'observ_terrain/source_merge/source_Boreholes.csv' # 10\n",
    "file2= work_dir + 'result_sol_ext_pilote/source_merge/source_Boreholes.csv' # 12\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da626427",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1413005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dc438b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'Long_pz_sol_x':[18], 'Long_pz_sol_y':[i for i in conflict_df.index if i not in [18]], \n",
    "                            'Rmq_y':list(conflict_df.index), 'Type_x':list(conflict_df.index),})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0de75a1",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Save dataset}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eae990",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bh = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b22a4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "dataset.to_csv(save_dir + 'Boreholes.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a52f19d",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579799cf",
   "metadata": {},
   "source": [
    "# Lithologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e3fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Litho'\n",
    "dataset = pd.DataFrame() # for saving object info after last merging\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9038f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb241960",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63078412",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a63f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'database_Memoris3/source_merge/source_Lithologies.csv' # 0\n",
    "file2= work_dir + 'profils_sols_donnees_forages/source_merge/source_Lithologies.csv' # 2\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed312a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID', 'Litho_top', 'Litho_base'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68412a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95fec0c",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae92cc3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'donnees_terrain_2019/source_merge/source_Lithologies.csv' # 1\n",
    "file2= work_dir + 'vUmons_logsFor/source_merge/source_Lithologies.csv' # 3\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d7111",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID', 'Litho_top', 'Litho_base'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26741138",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID', 'Litho_top', 'Litho_base'], dist_max=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820aeda1",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Save dataset}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1abf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_litho = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f820536",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "dataset.to_csv(save_dir + 'Lithologies.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84243cd9",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a5c5f0",
   "metadata": {},
   "source": [
    "# Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d7e364",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Sample'\n",
    "dataset = pd.DataFrame() # for saving object info after last merging\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4323bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdbef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd7db0",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4e297",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'Memoris_seafile/source_merge/source_Samples.csv' # 2\n",
    "file2= work_dir + 'Liste_XY/source_merge/source_Samples.csv' # 1\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e0d66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID', 'ID_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72835bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa4e1c7",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a94c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir +  'Phase_1_Memoris/source_merge/source_Samples.csv' # 3\n",
    "file2= work_dir + 'Phase_2_Memoris/source_merge/source_Samples.csv' # 4\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb1890",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147d0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f48bf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'C16-C21_y':list(conflict_df.index), 'C21-C35_y':list(conflict_df.index), \n",
    "                            'C12-C16_y':list(conflict_df.index), 'Fract_2+_y':list(conflict_df.index), \n",
    "                            'C10-C12_y':list(conflict_df.index), 'HC_tot_C10-C35_y':list(conflict_df.index), \n",
    "                            'Fract_2_y':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283c4975",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e0ac02",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir +  'database_Memoris3/source_merge/source_Samples.csv' # 8\n",
    "file2= work_dir +  'profils_sols_donnees_forages/source_merge/source_Samples.csv' # 10\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d409e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311b1745",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID', 'ID_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43340c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc23b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'Nappe_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eb8999",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403fe8a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir +  'Container_phyto/source_merge/source_Samples.csv' # 0\n",
    "file2= work_dir +  'vUmons_logsFor/source_merge/source_Samples.csv' # 12\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d6ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4dfd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662bfb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdf = gen_id_from_ech(mdf, id_ech_col='ID_ech', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf0d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "col = 'ID_ech'\n",
    "for i in data.index:\n",
    "    v = data.loc[i, col]\n",
    "    if not pd.isnull(v) and re.search('ech', v, re.I):\n",
    "        data.loc[i, 'ID'] = 'F_' + re.sub(' |.','', v,re.I)\n",
    "mdf = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d15b757",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f8dba5",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605743a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir +  'Siterem_Ext_Pilote/source_merge/source_Samples.csv' # 5\n",
    "file2= work_dir +  'Siterem_Pilote/source_merge/source_Samples.csv' # 6\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e7fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257d9eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['ID_ech'] = df1['ID_ech'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2013df53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf34956",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID', 'ID_ech', 'Date_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee9ee89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'C16-C21_x':list(conflict_df.index), 'Type_ech_x':list(conflict_df.index), \n",
    "                            'C12-C16_x':list(conflict_df.index), 'C10-C12_x':list(conflict_df.index), \n",
    "                            'HC_tot_C10-C35_x':list(conflict_df.index),  'C21-C35_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d668700",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1932c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir +  'Siterem_Result_Sol/source_merge/source_Samples.csv' # 7\n",
    "file2= work_dir +  'donnees_terrain_2019/source_merge/source_Samples.csv' # 9\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3, un_val='ID', view=view), dataframe_viewer(df2, rows=3, un_val='ID', view=view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7732520",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['ID'] = df2['ID'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98525bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df2]\n",
    "look_for = ['Date', 'ID']\n",
    "for i, df in enumerate(df_list):\n",
    "    for l in look_for:\n",
    "        for c in df.columns:\n",
    "            if re.search(l, c, re.I): print(i, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ce4ecf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df=data_merger(df1, df2, how=how[1], on=['ID', 'ID_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51266df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mdf\n",
    "dataset, conflict_df=data_merger(dataset, data, how=how[1], on=['ID', 'ID_ech'], dist_max=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a18cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', pass_col='ID', \n",
    "                valid_dict={'Nappe_x':list(conflict_df.index)})\n",
    "\n",
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e4b549",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Save dataset}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b711f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_samp = dataset.copy()\n",
    "dataframe_viewer(dataset, rows=3, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bbeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "dataset.to_csv(save_dir + 'Samples.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df01cefa",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "raw",
   "id": "2bd2eb59",
   "metadata": {},
   "source": [
    "l = []\n",
    "for i in pd.unique(conflict_df.Check_col):\n",
    "    for c in i.split(', '):\n",
    "        l.append(c)\n",
    "print(list(set(l)))\n",
    "\n",
    "dataframe_viewer(conflict_df, rows=20, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fb7a7b8",
   "metadata": {},
   "source": [
    "dataframe_viewer(df[['ID', 'ID_ech']], rows=3, un_val=['ID'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a6ae238",
   "metadata": {},
   "source": [
    "data_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "22761935",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "a, b = 1,2\n",
    "print(files_dict[key][a].replace(work_dir, ''), '\\n', files_dict[key][b].replace(work_dir, ''), '\\n')\n",
    "file1= files_dict[key][a]\n",
    "file2= files_dict[key][b]\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "dataframe_viewer(df1, rows=3), dataframe_viewer(df2, rows=3)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "baf56c85",
   "metadata": {},
   "source": [
    "l = [i for i in conflict_df.index if i not in [18]]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82d75ab4",
   "metadata": {},
   "source": [
    "l = []\n",
    "for i in pd.unique(conflict_df.Check_col):\n",
    "    for c in i.split(', '):\n",
    "        l.append(c)\n",
    "print(list(set(l)))\n",
    "\n",
    "dataframe_viewer(conflict_df, rows=20, un_val=['ID','ID_ech'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0e90d393",
   "metadata": {},
   "source": [
    "coi = ['ID','X','Y','Date_for','Type']\n",
    "col = 'ID'\n",
    "val = \"'537'\"\n",
    "dataframe_viewer(mdf[coi].query(f'{col}=={val}'), rows=3, un_val=['ID'])\n",
    "dataframe_viewer(datase[coi].query(f'{col}=={val}'), rows=3, un_val=['ID'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eae1ebb6",
   "metadata": {},
   "source": [
    "dataframe_viewer(mdf, rows=3, un_val=['ID'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c0196d4",
   "metadata": {},
   "source": [
    "gen_id_from_ech(df1, id_ech_col='ID', suffixes=sufx, prefixes=prefx, capture_regex=id_reg)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3322a91",
   "metadata": {},
   "source": [
    "data = df2\n",
    "for i in data.index:\n",
    "    v = data.loc[i, 'ID']\n",
    "    if re.search('/\\d+', v, re.I):\n",
    "        print(i, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fffb76",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53460d4a",
   "metadata": {},
   "source": [
    "# Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3257a498",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Measure'\n",
    "dataset = pd.DataFrame() # for saving object info after last merging\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf37c55",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094f74b7",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e292e9c9",
   "metadata": {},
   "source": [
    "# Equipements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496be776",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Equip'\n",
    "dataset = pd.DataFrame() # for saving object info after last merging\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d15c81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10000c7d",
   "metadata": {},
   "source": [
    "###  ===================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0591d8",
   "metadata": {},
   "source": [
    "# Unknows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4456490",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Unknow'\n",
    "dataset = pd.DataFrame() # for saving object info after last merging\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd9c698",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files_dict[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043b8ba2",
   "metadata": {},
   "source": [
    "### ================= DATASETS MERGING WITH BOREHOLES ==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfa68a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a1cdbe6",
   "metadata": {},
   "source": [
    "## Querying"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f8391359",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "bh_name = '_'\n",
    "id_col = 'ID_ech'\n",
    "dataframe_viewer(dataset.query(f'{id_col}.str.contains(\"{bh_name}\")', engine='python'))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f0b359fe",
   "metadata": {},
   "source": [
    "id_ = 'FP76'\n",
    "id_col = 'ID_ech'\n",
    "dataframe_viewer(df1.query(f'{id_col}==\"{id_}\"'), rows=10, cols=15, un_val=f'{id_col}', view=view), \n",
    "dataframe_viewer(df2.query(f'{id_col}==\"{id_}\"'), rows=10, cols=15, un_val=f'{id_col}', view=view)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1b240d2",
   "metadata": {},
   "source": [
    "x_min, x_max = 152883, 152885\n",
    "y_min, y_max =  122605, 122608\n",
    "id_col = 'ID_ech'\n",
    "#bh_name = 'F1.' # regex\n",
    "bh_name = None\n",
    "\n",
    "q = dataset.query(f'X >= {x_min} and X <= {x_max} and Y >= {y_min} and Y <= {y_max}')\n",
    "if bh_name is not None:\n",
    "    q = dataset.query(f'{id_col}.str.contains(\"{bh_name}\")', engine='python')\n",
    "#dataframe_viewer(q[coi_1 + coi_2], rows=10, cols=15, un_val='ID', view=view)\n",
    "dataframe_viewer(q, rows=10, cols=15, un_val=id_col, view=view)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e91304b",
   "metadata": {},
   "source": [
    "sql = 'ID_ech==\"F1/2M\"'\n",
    "cols = ['ID_ech', 'Date_prv', 'X', 'Y', 'Z', 'Long_for', 'Ech_top', 'Ech_base', 'Fract_2', 'Fract_2+', 'MS']\n",
    "dataframe_viewer(dataset_1.query(sql)[cols]), dataframe_viewer(dataset_2.query(sql)[cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
