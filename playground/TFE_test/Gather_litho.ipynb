{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finite-killing",
   "metadata": {},
   "source": [
    "# Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loaded-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.io import gdf_viewer, gdf_merger, data_validation, gdf_filter, fix_duplicates\n",
    "import re, os\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import datetime as dtm\n",
    "import matplotlib.pyplot as plt\n",
    "from definitions import ROOT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-pride",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def files_search(work_dir, files_dict, prefix='', skip=None, details=False):   \n",
    "    \n",
    "    if skip is None:\n",
    "        skip = \"we don't want to skip a word\"\n",
    "        \n",
    "    for k in files_dict.keys():\n",
    "        tmp_list = []\n",
    "        for p,d,f in os.walk(work_dir):\n",
    "            for x in f:\n",
    "                add = False\n",
    "                if re.search(prefix,x,re.I) and not re.search(skip,x,re.I):\n",
    "                    add = True\n",
    "                    i = str(f'{p}/{x}')\n",
    "                else:\n",
    "                    add = False\n",
    "                    i=''\n",
    "                    \n",
    "                if re.search(k,i,re.I) and add:\n",
    "                    tmp_list.append(i)\n",
    "        tmp_list.sort()\n",
    "        files_dict.update({k:tmp_list})\n",
    "\n",
    "    for k,v in files_dict.items():\n",
    "        print(k,' \\t: ',len(v))\n",
    "    \n",
    "    if details: # Look filenames\n",
    "        which = files_dict.keys()\n",
    "\n",
    "        for w in which:\n",
    "            print('\\n+++++++++++++++++')\n",
    "            print(f'+  {w.upper()}\\t+ ')\n",
    "            print('+++++++++++++++++')\n",
    "            [print(i, '-', x) for i, x in enumerate(files_dict[w], 0)]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(files, verbose=True): # find another name for this function\n",
    "    \"\"\"\n",
    "    create dataframes from files and test if they contain position informations\n",
    "    files: list of files name\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    dfs = []\n",
    "    for f in files:\n",
    "        cnt += 1\n",
    "        df = pd.read_csv(f, delimiter=',')\n",
    "        dfs.append(df)\n",
    "        \n",
    "        if verbose:\n",
    "            if 'X' in list(df.columns): msg = ' --> Coordinates'\n",
    "            else: msg = ' --> No coordinates'\n",
    "\n",
    "            print(f\"df{cnt} : {msg}\")\n",
    "            \n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b09082c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dataset_overview(d, verbose=False): # check for same datasets in given files\n",
    "    \"\"\"d: dict\n",
    "    \"\"\"\n",
    "    l = len(d)\n",
    "    with_coord = []\n",
    "    no_coord = []\n",
    "    same = []\n",
    "    \n",
    "    for i in range(l-1):\n",
    "        for j in range(i,l):\n",
    "            a, b = create_df([d[i], d[j]], verbose)\n",
    "            if j != i:\n",
    "                if a.equals(b):\n",
    "                    same.append((i,j))\n",
    "            \n",
    "            if 'X' in list(b.columns) and j not in with_coord:\n",
    "                with_coord.append(j)\n",
    "            elif 'X' not in list(b.columns) and j not in no_coord:\n",
    "                no_coord.append(j)\n",
    "    \n",
    "    print(f'Same files:{same}\\nFiles with coordinates:{with_coord}\\nFiles without coordinates:{no_coord}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-noise",
   "metadata": {},
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = ROOT_DIR+'/CF_data/Result_traitem/'\n",
    "save_dir = ROOT_DIR+'/CF_data/Donnees_fusionnees/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create my dictionary structure to retrieve good files (Keynames !!!)\n",
    "files_dict={'Borehole':0,'Piezometer':0,'Piezair':0,'Trench':0,'Litho':0,'Equipm':0,\n",
    "        'Measure':0,'Sample':0,'Analysis':0,'Facility':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-sensitivity",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_search(work_dir, files_dict, prefix='', skip='source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "how=['inner', 'outer', 'left', 'right']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-boards",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = False\n",
    "t = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61554269",
   "metadata": {},
   "source": [
    "# Boreholes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29df246",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = save_dir+'Merged_Boreholes.csv'\n",
    "bh = pd.read_csv(file, delimiter=',')\n",
    "gdf_viewer(bh, rows=3, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc3a492",
   "metadata": {},
   "source": [
    "# Lithologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a9af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "key='Litho'\n",
    "save_file = f'Merged_Lithologies.csv'\n",
    "coi = ['ID','X','Y','Z','Long_for','Description','Litho_top','Litho_base']\n",
    "dataset = pd.DataFrame() # for saving object info after last merging\n",
    "print(len(files_dict[key]), 'files')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-relations",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_dict[key] #files_dict[key][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2213ff0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_overview(files_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15174f2",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2848bb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'database_Memoris3/Drains_Pz_ENEL_Lithology.csv' # 0\n",
    "file2= work_dir + 'database_Memoris3/Result_sol_Lithology.csv' # 2\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "gdf_viewer(df1, rows=3, un_val='ID', view=t), gdf_viewer(df2, rows=3, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'Profondeur':'Long_for'}, inplace=True)\n",
    "df2.rename(columns={'Long':'Long_for', 'Description':'Description2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f81efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['X'] = df2['X'].apply(lambda x: x.replace(',', '.') if isinstance(x, str) else x)\n",
    "df2['Y'] = df2['Y'].apply(lambda x: x.replace(',', '.') if isinstance(x, str) else x)\n",
    "df2['Ep_remb'] = df2['Ep_remb'].apply(lambda x: x.replace(',', '.') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4c05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[['X','Y','Ep_remb']] = df2[['X','Y','Ep_remb']].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['ID','Date_ouv','Long_for','Description','Litho_top','Litho_base']].copy()\n",
    "df2 = df2[['ID','X','Y','Z','Long_for']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e201f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df = gdf_merger(df1, df2, how=how[1], on='ID', dist_max=1., drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd454052",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdf_viewer(mdf, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01e74ac",
   "metadata": {},
   "source": [
    "#### $\\color{blue}{\\textbf{Manage conflicts}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b77bfa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdf_viewer(conflict_df, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5cc1ca7b",
   "metadata": {},
   "source": [
    "data_validation(overall_data=mdf, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_for_x':[136,142],},)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479ddcd1",
   "metadata": {},
   "source": [
    "#### First object dataset save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d915044",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = mdf.copy() #saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44abcbda",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3902c027",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file1= work_dir + 'database_Memoris3/Profils_sol_Lithology.csv' # 1\n",
    "file2= work_dir + 'donnees_terrain_2019/Log_Lithology.csv' # 3\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "gdf_viewer(df1, rows=3, un_val='ID', view=t), gdf_viewer(df2, rows=3, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ccd31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df2.iterrows():\n",
    "    if row['Type'] == 'Forage': \n",
    "        df2.loc[idx, 'Date_ouv']= '2019-10-07'\n",
    "    elif row['Type'] == 'Piezo' or row['Type'] == 'Piezair': \n",
    "        df2.loc[idx, 'Date_ouv']= '2019-12-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6290d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.rename(columns={'Profondeur':'Long_for'}, inplace=True)\n",
    "#df2.rename(columns={'Long':'Long_for', 'Description':'Description2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9dee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['ID','Date_ouv','Long_for','Description','Litho_top','Litho_base']].copy()\n",
    "df2 = df2[['ID','Date_ouv','Description','Litho_top','Litho_base','Zone']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67486e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdf, conflict_df = gdf_merger(df1, df2, how=how[1], on='ID', date_col='Date_ouv', dist_max=None, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e2590f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdf_viewer(mdf, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf63ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pause # problem with dataset merging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a28852",
   "metadata": {},
   "source": [
    "#### Merge with object dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "13f90790",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dataset, conflict_df=gdf_merger(dataset, mdf, how=how[1], on='ID', dist_max=None, \n",
    "                                date_col='Date_ouv', drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0491b83f",
   "metadata": {},
   "source": [
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98890239",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "gdf_viewer(dataset, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab34e9a",
   "metadata": {},
   "source": [
    "#### $\\color{blue}{\\textbf{Manage conflicts}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7a787af4",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "gdf_viewer(conflict_df, rows=10, un_val='ID', view=t) # here boreholes are differents !!!"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e37d5476",
   "metadata": {},
   "source": [
    "data_validation(overall_data=mdf, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_for_x':[136,142],},)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b7b7bc45",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "gdf_viewer(conflict_df, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec014b42",
   "metadata": {},
   "source": [
    "#### $\\color{green}{\\textbf{Read and merge}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b019dbba",
   "metadata": {},
   "source": [
    "file1 = files_dict[key][5]\n",
    "file2 = files_dict[key][6]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8f592374",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "#file1= work_dir + 'database_Memoris3/Profils_sol_Lithology.csv' # 1\n",
    "#file2= work_dir + 'donnees_terrain_2019/Log_Lithology.csv' # 3\n",
    "\n",
    "df1, df2 = create_df([file1, file2])\n",
    "gdf_viewer(df1, rows=3, un_val='ID', view=t), gdf_viewer(df2, rows=3, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "33f15fec",
   "metadata": {},
   "source": [
    "df1.rename(columns={'Profondeur':'Long_for'}, inplace=True)\n",
    "#df2.rename(columns={'Long':'Long_for', 'Description':'Description2'}, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "adfa7a5c",
   "metadata": {},
   "source": [
    "df1 = df1[['ID','Date_ouv','Long_for','Description','Litho_top','Litho_base']].copy()\n",
    "df2 = df2[['ID','Description','Litho_top','Litho_base','Zone']].copy()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ca48c1c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "mdf, conflict_df = gdf_merger(df1, df2, how=how[1], on='ID', dist_max=None, drop_skip_col=['index'])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61b93db0",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "gdf_viewer(mdf, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f12dcd",
   "metadata": {},
   "source": [
    "#### $\\color{blue}{\\textbf{Manage conflicts}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b6afa04",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# here boreholes are differents, must be rename before merging !!!\n",
    "gdf_viewer(conflict_df, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b49f38a",
   "metadata": {},
   "source": [
    "data_validation(overall_data=mdf, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_for_x':[136,142],},)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "344b35c4",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "gdf_viewer(conflict_df, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e6023b",
   "metadata": {},
   "source": [
    "#### Merge with object dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ded9d68",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "dataset, conflict_df=gdf_merger(dataset, mdf, how=how[1], on='ID', dist_max=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2a54c1b7",
   "metadata": {},
   "source": [
    "if 'level_0' in dataset.columns:\n",
    "    if 'index' in dataset.columns:\n",
    "        dataset.drop(columns='index', inplace=True)\n",
    "    dataset.rename(columns={'level_0':'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "182cda07",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "gdf_viewer(dataset, rows=10, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb4009",
   "metadata": {},
   "source": [
    "#### $\\color{blue}{\\textbf{Manage conflicts}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "150aed92",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "conflict_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3e3b2a00",
   "metadata": {},
   "source": [
    "data_validation(overall_data=dataset, conflict_data=conflict_df, index_col='index', \n",
    "                valid_dict={'Long_for_x':[136,142],},)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a07393fd",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "gdf_viewer(dataset, rows=3, un_val='ID', view=t)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d07b8a9c",
   "metadata": {},
   "source": [
    "pause"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc8469",
   "metadata": {},
   "source": [
    "####  $\\color{red}{\\textbf{Save final object dataset}}$"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e85ef45c",
   "metadata": {},
   "source": [
    "if 'index' in dataset.columns:\n",
    "    dataset.drop(columns='index', inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e606fe3",
   "metadata": {},
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "dataset.to_csv(save_dir + save_file, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce7f983c",
   "metadata": {},
   "source": [
    "bh = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde7b1ee",
   "metadata": {},
   "source": [
    "#### -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45de407",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbda1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dataset['X'],dataset['Y'], '.')\n",
    "plt.axis('equal')\n",
    "plt.grid('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "pause"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
